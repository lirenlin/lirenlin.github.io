<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Yet another site</title><link href="/" rel="alternate"></link><link href="/feeds/math.atom.xml" rel="self"></link><id>/</id><updated>2018-12-26T13:07:00+01:00</updated><entry><title>Matrix rank</title><link href="/matrix-rank.html" rel="alternate"></link><updated>2018-12-26T13:07:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-26:matrix-rank.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;直观：「秩」是图像经过矩阵变换之后的空间维度&lt;/li&gt;
&lt;li&gt;定义：「秩」是列空间的维度&lt;/li&gt;
&lt;li&gt;物理意义：From an applied setting, rank of a matrix denotes the information content of
the matrix. The lower the rank, the lower is the "information content".&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我的理解：
&lt;/p&gt;
&lt;div class="math"&gt;$$Ax = b, \quad \textrm {where} \quad A \in \mathbb {R}^{nxn}, x, b \in \mathbb {R}^{n}$$&lt;/div&gt;
&lt;p&gt;given a point (vector)x in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;, apply the transformation, map it into another point b.
As column of C is the combination of columns of A, this indicates point b is
within the columns space of A.
In other words, point b is a point inside the vector space defined by A's columns.&lt;/p&gt;
&lt;p&gt;Rank by definition from &lt;a href="https://en.wikipedia.org/wiki/Rank_(linear_algebra)"&gt;wiki&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;in linear algebra, the rank of a matrix A is the dimension of the vector space
generated (or spanned) by its columns.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Additional if some columns inside A doesn't provide more information(constraint) to the
space. They don't define new dimentions. They are just the combinations (scalar multiply and vector add) 
of other 'essential' columns. The number of the 'essential' columns which defines the
vector space is rank.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/linear_solution.png" alt="Liner solution" title="linear solution" style="max-width:100%;max-height=100%"/&gt;&lt;/p&gt;
&lt;p&gt;b is any point in &lt;span class="math"&gt;\(\mathbb {R}^m\)&lt;/span&gt;. A defines a space with its column vectors.
Of course, if you want this system of equation has a solution, b must be in the
space defined by A. In another way, a given point x will be transformed into a
point in space defined by A. You might also want this process to be reversible,
so that you can recover x given b and system matrix A.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A defines the vector space &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;, any point x in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt; has a unique mapping point b which is in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;A defines the vector space &lt;span class="math"&gt;\(\mathbb {R}^m\)&lt;/span&gt;, a subspace in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;, multiple points in $\mathbb {R}^n will map to the same point in space constrained by A.&lt;/li&gt;
&lt;li&gt;A defines a subspace in &lt;span class="math"&gt;\(\mathbb {R}^m\)&lt;/span&gt;, point b in this subspace has a unique mapping x which is in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;. Point b which is not this subspace, however in &lt;span class="math"&gt;\(\mathbb{R}^m\)&lt;/span&gt;, could not find any mapping points x.&lt;/li&gt;
&lt;li&gt;A defines a subspace in &lt;span class="math"&gt;\(\mathbb {R}^m\)&lt;/span&gt;, point b in this subspace has more than one mapping x which is in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;. Points b which is not this subspace, however in &lt;span class="math"&gt;\(\mathbb{R}^m\)&lt;/span&gt;, could not find any mapping points x.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://math.stackexchange.com/a/21107"&gt;math.stackexchange: Importance of matrix rank&lt;/a&gt;&lt;br /&gt;
&lt;a href="https://www.zhihu.com/question/21605094"&gt;知乎&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>线性方程组</title><link href="/xian-xing-fang-cheng-zu.html" rel="alternate"></link><updated>2018-12-26T10:25:50+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-26:xian-xing-fang-cheng-zu.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In general, a system with fewer equations than unknowns has infinitely many
solutions, but it may have no solution. Such a system is known as an
underdetermined system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In general(not always), a system with more equations than unknowns has no solution. Such a
system is also known as an overdetermined system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In general, a system with the same number of equations and unknowns has a
single unique solution.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;\begin{align}
Ax &amp;amp;= b, \\
A^{-1}Ax &amp;amp;= A^{-1}b, \\
x &amp;amp;= A^{-1}b,
\end{align}&lt;/div&gt;
&lt;p&gt;
如果这个方程有唯一解，变换可逆，A可逆. 这意味着，从b，可以还原应用了变换之前的x。
这个变换是可逆的。&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>矩阵乘法</title><link href="/ju-zhen-cheng-fa.html" rel="alternate"></link><updated>2018-12-25T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-25:ju-zhen-cheng-fa.html</id><summary type="html">&lt;div class="math"&gt;$$C = AB, A \in \mathbb {R}^{m \times n}, b \in \mathbb {R}^{n \times l}, c \in \mathbb {R}^{m \times l}$$&lt;/div&gt;
&lt;p&gt;For example:
&lt;/p&gt;
&lt;div class="math"&gt;$$
A =
\begin{bmatrix}
a_{00} &amp;amp; a_{01} &amp;amp; a_{02}\\
a_{10} &amp;amp; a_{11} &amp;amp; a_{12}\\
a_{20} &amp;amp; a_{21} &amp;amp; a_{22}
\end{bmatrix}
B =
\begin{bmatrix}
b_{00} &amp;amp; b_{01} &amp;amp; b_{02}\\
b_{10} &amp;amp; b_{11} &amp;amp; b_{12}\\
b_{20} &amp;amp; b_{21} &amp;amp; b_{22}
\end{bmatrix}
C =
\begin{bmatrix}
c_{00} &amp;amp; c_{01} &amp;amp; c_{02}\\
c_{10} &amp;amp; c_{11} &amp;amp; c_{12}\\
c_{20} &amp;amp; c_{21} &amp;amp; c_{22}
\end{bmatrix}
$$&lt;/div&gt;
&lt;h1&gt;Componenet wise&lt;/h1&gt;
&lt;div class="math"&gt;$$C_{ij} = \sum_{k=1}^{m} a_{ik} \times b_{kj}$$&lt;/div&gt;
&lt;p&gt;
for i = 1, ..., m and j = 1, ..., l.&lt;/p&gt;
&lt;h1&gt;Row wise&lt;/h1&gt;
&lt;p&gt;Row of C is the combination of rows of B&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{cases}
c_{00} = a_{00} \times b_{00} + a_{01} \times b_{10} + a_{02} \times b_{20} \\
c_{01} = a_{00} \times b_{01} + a_{01} \times b_{11} + a_{02} \times b_{21} \\
c_{03} = a_{00} \times b_{02} + a_{01} \times b_{12} + a_{02} \times b_{22} \\
\end{cases} \rightarrow
\begin{bmatrix}
c_{00} \\ c_{01} \\ c_{02}
\end{bmatrix}^T =
\begin{bmatrix}
b_{00} \\ b_{01} \\ b_{02}
\end{bmatrix} ^T
\times  a_{00} +
\begin{bmatrix}
b_{10} \\ b_{11} \\ b_{12}
\end{bmatrix}^T
\times  a_{01} +
\begin{bmatrix}
b_{20} \\ b_{21} \\ b_{22}
\end{bmatrix}^T
\times  a_{02}
$$&lt;/div&gt;
&lt;h1&gt;Column wise&lt;/h1&gt;
&lt;p&gt;Column of C is the combination of columns of A
&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{cases}
c_{00} = a_{00} \times b_{00} + a_{01} \times b_{10} + a_{02} \times b_{20} \\
c_{10} = a_{10} \times b_{00} + a_{11} \times b_{10} + a_{12} \times b_{20} \\
c_{20} = a_{20} \times b_{00} + a_{21} \times b_{10} + a_{22} \times b_{20} \\
\end{cases} \rightarrow
\begin{bmatrix}
c_{00} \\ c_{10} \\ c_{20}
\end{bmatrix} =
\begin{bmatrix}
a_{00} \\ a_{10} \\ a_{20}
\end{bmatrix}
\times  b_{00} +
\begin{bmatrix}
a_{01} \\ a_{11} \\ a_{21}
\end{bmatrix}
\times  b_{10} +
\begin{bmatrix}
a_{02} \\ a_{12} \\ a_{22}
\end{bmatrix}
\times  b_{20}
$$&lt;/div&gt;
&lt;h1&gt;Matrix wise&lt;/h1&gt;
&lt;p&gt;AB is the sum of col_of(A) * row_of(B)
&lt;/p&gt;
&lt;div class="math"&gt;$$AB = \sum_{i=0}^l {A[:i] \times B[i:]}$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(a[:i] \in \mathbb {R}^{mx1}, B[i:] \in \mathbb {R}^{1xl}\)&lt;/span&gt;&lt;/p&gt;
&lt;h1&gt;Block matrix multiplication&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Block_matrix#Block_matrix_multiplication"&gt;Wiki&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>矩阵分解</title><link href="/ju-zhen-fen-jie.html" rel="alternate"></link><updated>2018-12-25T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-25:ju-zhen-fen-jie.html</id><summary type="html">&lt;h1&gt;Simplify the computation of linear system of equations.&lt;/h1&gt;
&lt;p&gt;Matrix factorization in the context of numerical linear algebra(NLA) generally serves the purpose of rephrasing through a series of easier subproblems a task that may be relatively difficult to solve in its original form.&lt;/p&gt;
&lt;p&gt;For example, given the typical linear system Ax = b for &lt;span class="math"&gt;\(A \in \mathbb {R}^{n × n}\)&lt;/span&gt;, x and b &lt;span class="math"&gt;\(\in \mathbb {R}^n\)&lt;/span&gt; , a factorization of A as LU for L a unit lower triangular matrix (thus, with ones along its main diagonal) and an upper triangular U is a mechanism for characterizing what occurs in Gaussian elimination.&lt;/p&gt;
&lt;p&gt;We replace &lt;span class="math"&gt;\(Ax = b\)&lt;/span&gt; by two (easier to solve) triangular systems:  find y so &lt;span class="math"&gt;\(Ly = b\)&lt;/span&gt; and then find x so &lt;span class="math"&gt;\(Ux = y\)&lt;/span&gt;.The point being made here is that the factorization of A as LU has no real importance in and of itself other than as a computationally convenient means for obtaining a solution to the original linear system.&lt;/p&gt;
&lt;h1&gt;Help to understand the structure of a big data matrix.&lt;/h1&gt;
&lt;p&gt;Typically, a matrix &lt;span class="math"&gt;\(A \in \mathbb {R}^{n × p}\)&lt;/span&gt; represents a data matrix containing numerical observations on n objects (subjects) over p attributes (variables), or possibly &lt;span class="math"&gt;\(B \in \mathbb {R}^{p × p}\)&lt;/span&gt; and the entries are some measure of proximity between attributes, such as the correlation between columns of A.&lt;/p&gt;
&lt;p&gt;The major purpose of a matrix factorization in this context is to obtain some form of lower-rank (and therefore simplified) approximation to A (or possibly to B) for understanding the structure of the data matrix, particularly the relationship within the objects and within the attributes, and how the objects relate to the attributes. If we can further interpret the matrix factorization geometrically and actually present the results spatially through coordinates obtained from the components of the factorization, we will be able to better communicate to others what structure may be present in the original data matrix.&lt;/p&gt;
&lt;p&gt;In any case, matrix factorizations are again directed toward the issue of simplicity, but now the actual components making up a factorization are of prime concern and not solely as a mechanism for solving another problem.&lt;/p&gt;
&lt;h1&gt;Related concepts&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Rank_(linear_algebra)"&gt;Rank (linear algebra)秩&lt;/a&gt;&lt;blockquote&gt;
&lt;p&gt;In linear algebra, the rank of a matrix A is the dimension of the vector space generated (or spanned) by its columns.[1] This corresponds to the maximal number of linearly independent columns of A.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Numerical_stability"&gt;Numerical stability&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Related articles&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://staff.ustc.edu.cn/~ynyang/group-meeting/2014/matrix-factorization/hubert.pdf"&gt;Two Purposes for Matrix Factorization: A Historical Appraisal&lt;/a&gt;&lt;br /&gt;
&lt;a href="https://people.duke.edu/~ccc14/sta-663/LinearAlgebraMatrixDecompWithSolutions.html"&gt;Linear Algebra and Matrix Decompositions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.jiqizhixin.com/articles/0301"&gt;奇异值分解简介：从原理到基础机器学习应用&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>矩阵性质 (From Wiki)</title><link href="/ju-zhen-xing-zhi-from-wiki.html" rel="alternate"></link><updated>2018-12-25T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-25:ju-zhen-xing-zhi-from-wiki.html</id><summary type="html">&lt;h1&gt;Square matrix:&lt;/h1&gt;
&lt;p&gt;In mathematics, a square matrix is a matrix with the same number of rows and columns. An n-by-n matrix is known as a square matrix of order n. Any two square matrices of the same order can be added and multiplied.&lt;/p&gt;
&lt;p&gt;Square matrices are often used to represent simple linear transformations, such as shearing or rotation. For example, if R is a square matrix representing a rotation (rotation matrix) and v is a column vector describing the position of a point in space, the product Rv yields another column vector describing the position of that point after that rotation. If v is a row vector, the same transformation can be obtained using vRT, where RT is the transpose of R.&lt;/p&gt;
&lt;h1&gt;Identity matrix:&lt;/h1&gt;
&lt;p&gt;In linear algebra, the identity matrix, or sometimes ambiguously called a unit matrix, of size n is the n × n square matrix with ones on the main diagonal and zeros elsewhere.  It is denoted by &lt;span class="math"&gt;\(I_n\)&lt;/span&gt;, or simply by I if the size is immaterial or can be trivially determined by the context.&lt;/p&gt;
&lt;h1&gt;Symmetric matrix:&lt;/h1&gt;
&lt;p&gt;In linear algebra, a symmetric matrix is a square matrix that is equal to its transpose. Formally,&lt;/p&gt;
&lt;div class="math"&gt;$$A = A^T$$&lt;/div&gt;
&lt;h1&gt;Diagonal matrx:&lt;/h1&gt;
&lt;p&gt;In linear algebra, a diagonal matrix is a matrix in which the entries outside the main diagnoal are all zero. The term usually refers to square matrices.&lt;/p&gt;
&lt;h1&gt;Triangular matrix&lt;/h1&gt;
&lt;p&gt;In the mathematical discipline of linear algebra, a triangular matrix is a special kind of square matrix. A square matrix is called &lt;strong&gt;lower triangular&lt;/strong&gt; if all the entries above the main diagonal are zero. Similarly, a square matrix is called &lt;strong&gt;upper triangular&lt;/strong&gt; if all the entries below the main diagonal are zero. A triangular matrix is one that is either lower triangular or upper triangular. A matrix that is both upper and lower triangular is called a diagonal matrix.&lt;/p&gt;
&lt;p&gt;Because matrix equations with triangular matrices are easier to solve, they are very important in numerical analysis. By the LU decomposition algorithm, an invertible matrix may be written as the product of a lower triangular matrix L and an upper triangular matrix U if and only if all its leading principal minors are non-zero.&lt;/p&gt;
&lt;h1&gt;Invertible matrix&lt;/h1&gt;
&lt;p&gt;In linear algebra, an n-by-n square matrix A is called invertible (also nonsingular or nondegenerate) if there exists an n-by-n square matrix B such that
&lt;/p&gt;
&lt;div class="math"&gt;$$\mathbf {AB} =\mathbf {BA} =\mathbf {I}$$&lt;/div&gt;
&lt;p&gt;
where In denotes the n-by-n identity matrix and the multiplication used is ordinary matrix multiplication. If this is the case, then the matrix B is uniquely determined by A and is called the inverse of A, denoted by &lt;span class="math"&gt;\(A^{−1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A square matrix that is not invertible is called singular or degenerate. A square matrix is singular if and only if its determinant is 0. Singular matrices are rare in the sense that a square matrix randomly selected from a continuous uniform distribution on its entries will almost never be singular.&lt;/p&gt;
&lt;p&gt;The set of &lt;span class="math"&gt;\(n × n\)&lt;/span&gt; invertible matrices together with the operation of matrix multiplication form a group, the general linear group of degree n.&lt;/p&gt;
&lt;h1&gt;Positive-definite matrix&lt;/h1&gt;
&lt;p&gt;In linear algebra, a symmetric &lt;span class="math"&gt;\(n × n\)&lt;/span&gt; real matrix &lt;span class="math"&gt;\(M\)&lt;/span&gt; is said to be positive definite if the scalar &lt;span class="math"&gt;\(z^{\textsf {T}}Mz\)&lt;/span&gt; is strictly positive for every non-zero column vector &lt;span class="math"&gt;\(z\)&lt;/span&gt; of &lt;span class="math"&gt;\(n\)&lt;/span&gt; real numbers. Here &lt;span class="math"&gt;\(z^{\textsf {T}}\)&lt;/span&gt; denotes the transpose of &lt;span class="math"&gt;\(z\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1&gt;Orthogonal matrix&lt;/h1&gt;
&lt;p&gt;An orthogonal matrix is a square matrix whose columns and rows are orthogonal unit vectors (i.e., orthonormal vectors), i.e.
    &lt;/p&gt;
&lt;div class="math"&gt;$$Q^TQ=QQ^T = I$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(I\)&lt;/span&gt; I is the identity matrix.&lt;br /&gt;
This leads to the equivalent characterization: a matrix Q is orthogonal if its transpose is equal to its inverse:
&lt;/p&gt;
&lt;div class="math"&gt;$$Q^{\mathrm {T} }=Q^{-1}$$&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
An orthogonal matrix Q is necessarily invertible (with inverse &lt;span class="math"&gt;\(Q^−1 = Q^T\)&lt;/span&gt;), unitary (&lt;span class="math"&gt;\(Q^−1 = Q^∗\)&lt;/span&gt;) and therefore normal (&lt;span class="math"&gt;\(Q^∗Q = QQ^∗\)&lt;/span&gt;) in the reals. The determinant of any orthogonal matrix is either +1 or −1. As a linear transformation, an orthogonal matrix preserves the dot product of vectors, and therefore acts as an isometry of Euclidean space, such as a rotation, reflection or rotoreflection. In other words, it is a unitary transformation.&lt;br /&gt;
The set of n × n orthogonal matrices forms a group O(n), known as the orthogonal group. The subgroup SO(n) consisting of orthogonal matrices with determinant +1 is called the special orthogonal group, and each of its elements is a special orthogonal matrix. As a linear transformation, every special orthogonal matrix acts as a rotation. &lt;/p&gt;
&lt;h1&gt;Unitary matrix (酉矩阵)&lt;/h1&gt;
&lt;p&gt;In mathematics, a complex square matrix U is unitary if its conjugate transpose &lt;span class="math"&gt;\(U^*\)&lt;/span&gt; is also its inverse—that is, if
&lt;/p&gt;
&lt;div class="math"&gt;$$U^∗ U = U U^∗ = I$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(I\)&lt;/span&gt; is the identity matrix. &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>计算机求导的四种方式</title><link href="/ji-suan-ji-qiu-dao-de-si-chong-fang-shi.html" rel="alternate"></link><updated>2018-12-21T15:08:08+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-21:ji-suan-ji-qiu-dao-de-si-chong-fang-shi.html</id><summary type="html">&lt;p&gt;计算机求导，有四种方法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人工解析微分法（manual analytical differentiation）&lt;/li&gt;
&lt;li&gt;数值微分法（numerical differentiation）&lt;/li&gt;
&lt;li&gt;符号微分法（symbolic differentiation）&lt;/li&gt;
&lt;li&gt;自动微分法（automatic differentiation）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/differentiation.jpeg" alt="Automatic differentiation in
machine learning: a survey" title="differentiation" style="max-width: 100%; max-height: 100%;"/&gt;&lt;/p&gt;
&lt;p&gt;参考:&lt;br /&gt;
&lt;a href="https://toutiao.io/posts/a5qqmj/preview"&gt;计算机求导的四种方式&lt;/a&gt;&lt;br /&gt;
&lt;a href="https://arxiv.org/abs/1502.05767"&gt;Automatic differentiation in machine learning: a survey&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>line search</title><link href="/line-search.html" rel="alternate"></link><updated>2018-12-19T22:23:31+00:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-19:line-search.html</id><summary type="html">&lt;p&gt;From &lt;a href="https://en.wikipedia.org/wiki/Line_search"&gt;Wiki&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In optimization, the line search strategy is one of two basic iterative 
approaches to find a local minimum &lt;span class="math"&gt;\(\mathbf {x}^{*}\)&lt;/span&gt; of an objective function
&lt;span class="math"&gt;\(\mathbf {f} :\mathbb {R} ^{n} \to \mathbb {R}\)&lt;/span&gt;. The other approach is 
&lt;a href="https://en.wikipedia.org/wiki/Trust_region"&gt;trust region&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The line search approach first finds a descent direction along which the 
objective function &lt;span class="math"&gt;\(f\)&lt;/span&gt; will be reduced and then computes a 
step size that determines how far &lt;span class="math"&gt;\(\mathbf {x}\)&lt;/span&gt; should move along that 
direction. The descent direction can be computed by various methods, such as 
gradient descent, Newton's method and Quasi-Newton method. The step size can be 
determined either exactly or inexactly.&lt;/p&gt;
&lt;p&gt;trust-region methods first choose a step size (the size of the trust region) 
and then a step direction, while line-search methods first choose a step 
direction and then a step size.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在置信域方法中，优化问题构成了一个不等式约束优化问题，此问题使用拉格朗日乘子的方式，将它转换成无约束优化问题. 具体算法案例有Levenberg-Marquardt algorithm.&lt;/p&gt;
&lt;p&gt;gradient descent, 一阶偏导, jacobian matrix&lt;br/&gt;
Newtone method, 二阶偏导, Hessian matrix&lt;br/&gt;
Guass-Newton method, 使用Jacobian matrix近似Hessian matrix &lt;span class="math"&gt;\(\mathbf {H} \approx 2\mathbf {J_r^T} \mathbf{J_r}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Gradient_descent"&gt;Wiki: gradient descent&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://zhuanlan.zhihu.com/p/32709034"&gt;【最优化】一文搞懂最速下降法&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>Gradient梯度</title><link href="/gradientti-du.html" rel="alternate"></link><updated>2018-12-19T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-19:gradientti-du.html</id><summary type="html">&lt;p&gt;The gradient is a vector-valued function, as opposed to a derivative, which is scalar-valued. &lt;/p&gt;
&lt;p&gt;In some applications it is customary to represent the gradient as a row vector or column vector of its components
in a rectangular coordinate system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;muti-variable function&lt;ul&gt;
&lt;li&gt;scalar-valued function &lt;span class="math"&gt;\(f: \mathbb{R}^n \to \mathbb{R}\)&lt;/span&gt;, gradient vector, row matrix or column matrix.&lt;br/&gt;
&lt;span class="math"&gt;\(f(\mathbf{x})\)&lt;/span&gt; where &lt;span class="math"&gt;\(\mathbf(x) = (x1, x2,...,xn)\)&lt;/span&gt;.
&lt;div class="math"&gt;\begin{align*}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
Df(\mathbf{a}) = \left[\pdiff{f}{x_1}(\mathbf{a}) \ \pdiff{f}{x_2}(\mathbf{a}) \ \ldots \ 
\pdiff{f}{x_n}(\mathbf{a})\right].
\end{align*}&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;vector-valued function &lt;span class="math"&gt;\(\boldsymbol{f}: \mathbb{R}^n \to \mathbb{R}^m\)&lt;/span&gt;, mxn matrix. Jacobian matrix.&amp;lt;br&gt;
&lt;div class="math"&gt;\begin{gather*}
\mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}),f_2(\mathbf{x}), \cdots, f_m(\mathbf{x}))
=
\left[\begin{array}{c}
f_1(\mathbf{x})\\f_2(\mathbf{x})\\ \vdots\\ f_m(\mathbf{x})
\end{array}\right].
\end{gather*}&lt;/div&gt;
&lt;div class="math"&gt;\begin{gather*}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
D\mathbf{f}(\mathbf{a})=
\left[
\begin{array}{cccc}
\displaystyle\pdiff{f_1}{x_1}(\mathbf{a})&amp;amp;
\displaystyle\pdiff{f_1}{x_2}(\mathbf{a})&amp;amp;
\ldots &amp;amp;
\displaystyle\pdiff{f_1}{x_n}(\mathbf{a})\\
    \displaystyle\pdiff{f_2}{x_1}(\mathbf{a})&amp;amp;
    \displaystyle\pdiff{f_2}{x_2}(\mathbf{a})&amp;amp;
    \ldots &amp;amp;
    \displaystyle\pdiff{f_2}{x_n}(\mathbf{a})\\
        \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\
        \displaystyle\pdiff{f_m}{x_1}(\mathbf{a})&amp;amp;
        \displaystyle\pdiff{f_m}{x_2}(\mathbf{a})&amp;amp;
\ldots &amp;amp;
\displaystyle\pdiff{f_m}{x_n}(\mathbf{a})
\end{array}
\right].
\end{gather*}&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linear approximation to a function
The gradient of a function f from the Euclidean space &lt;span class="math"&gt;\(\mathbb{R}^n \to \mathbb{R}\)&lt;/span&gt;
at any particular point x0 in &lt;span class="math"&gt;\(\mathbb{R}^n\)&lt;/span&gt; characterizes the best linear
approximation to f at x0. The approximation is as follows:
    &lt;div class="math"&gt;$$f(x) \approx f (x0) + \nabla f(x0) \cdot (x−x0)$$&lt;/div&gt;
for x close to x0, where &lt;span class="math"&gt;\(\nabla f(x0)\)&lt;/span&gt; is the gradient of f computed at x0,
and the dot denotes the dot product on Rn.&lt;br/&gt;
This equation is equivalent to the first two terms in the
&lt;strong&gt;multivariable Taylor series expansion&lt;/strong&gt; of f at x0.&lt;br/&gt;
The approximation is valid only when the function is differentiable, and can be
used with the points which is very close to x0.&lt;br/&gt;
This could be extended to &lt;strong&gt;multivariable linear approximation&lt;/strong&gt; case.&lt;br/&gt;
It describes the &lt;strong&gt;tangent line/plane&lt;/strong&gt; over that point.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://mathinsight.org/linear_approximation_multivariable"&gt;mathinsight: linear approximation multivariable&lt;/a&gt; &lt;br/&gt;
&lt;a href="https://mathinsight.org/derivative_matrix"&gt;mathinsight: derivative matrix&lt;/a&gt; &lt;br/&gt;
&lt;a href="https://en.wikipedia.org/wiki/Gradient"&gt;Wiki: Gradient&lt;/a&gt; &lt;br/&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>旋转矩阵，变化矩阵，旋转向量，欧拉角，四元数</title><link href="/xuan-zhuan-ju-zhen-bian-hua-ju-zhen-xuan-zhuan-xiang-liang-ou-la-jiao-si-yuan-shu.html" rel="alternate"></link><updated>2018-12-19T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-19:xuan-zhuan-ju-zhen-bian-hua-ju-zhen-xuan-zhuan-xiang-liang-ou-la-jiao-si-yuan-shu.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;平滑插值&lt;/li&gt;
&lt;li&gt;紧凑&lt;/li&gt;
&lt;li&gt;无奇异性&lt;/li&gt;
&lt;li&gt;内存和运算速度更优。内存上，一个四元数只占四个浮点数；在四元数相乘时可以直接在这四个数上进行加减乘的基本运算，比旋转向量转换成旋转矩阵相乘后再转换回旋转向量要高效得多（Rodrigues 变换还涉及除法和三角函数等高级运算）。这些在嵌入式平台上是不小的优势。何况，浮点数运算总是会有误差的，运算越多，误差累计越多，所以理论上四元数相乘也有精度上的优势。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/EliminatedAcmer/article/details/81407176"&gt;CSDN总结&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>Bayes and Kalman Filter</title><link href="/bayes-and-kalman-filter.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:bayes-and-kalman-filter.html</id><summary type="html">&lt;p&gt;SLAM位姿与地图估计问题有两种方式，一种是滤波，一种是优化.&lt;br/&gt;
暂时搜集到的一些信息，没有自己整理&lt;/p&gt;
&lt;p&gt;Bayes Filter推导(&lt;span style="color:red"&gt;基于Bayes公式与Markov assumption&lt;/span&gt;)&lt;br/&gt;
&lt;img src="images/bayes-1.png" alt="Bayes" title="bayes" style="width:50%"/&gt;&lt;/p&gt;
&lt;p&gt;第一步用到的Bayes公式：
&lt;/p&gt;
&lt;div class="math"&gt;$$P(x|y,z) = \frac{P(y|x,z)\cdot p(x|z)}{p(y|z)}$$&lt;/div&gt;
&lt;p&gt;
由此得出，贝叶斯滤波器分为两步：&lt;br/&gt;
1. 状态预测，基于状态转移模型：
&lt;/p&gt;
&lt;div class="math"&gt;$$\overline {bel} ({x_t}) = \int {p({x_t}|{u_t},{x_{t - 1}})} \;bel({x_{t - 1}})\;d{x_{t - 1}}$$&lt;/div&gt;
&lt;p&gt;
2. 状态更新，基于新的观测
&lt;/p&gt;
&lt;div class="math"&gt;$$bel({x_t}) = \;\eta \,p({z_t}|{x_t})\,\overline {bel} ({x_t})$$&lt;/div&gt;
&lt;p&gt;在此式中&lt;span class="math"&gt;\(\eta\)&lt;/span&gt;未进一步说明，概率机器人一书中，被称之为&lt;strong&gt;归一化因子&lt;/strong&gt;，具体表现形式如下：
&lt;/p&gt;
&lt;div class="math"&gt;$$\frac{1}{\eta} = \sum{p(z_t|x_t)\overline{bel}(x_t)dx_t}$$&lt;/div&gt;
&lt;p&gt;
因为最后&lt;span class="math"&gt;\(bel(x_t)\)&lt;/span&gt;是一个概率，其所有&lt;span class="math"&gt;\(x_t\)&lt;/span&gt;可能性概率的总和必须为１.&lt;/p&gt;
&lt;p&gt;伪代码流程如下: &lt;br/&gt;
&lt;img src="images/bayes-2.png" alt="Bayes" title="bayes" style="width:50%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style="color:red"&gt;
同时，我们注意，我们的目的是计算&lt;span class="math"&gt;\(x_t\)&lt;/span&gt;的后验概率，如果bel(xt)是任意分布，
我们需要在&lt;span class="math"&gt;\(x_t\)&lt;/span&gt;的所有可能取值点上，计算该取值的概率，这在计算上是难于实现的。
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;相关资料的搜集:&lt;br/&gt;
&lt;a href="/pdfs/slam02-bayes-filter-short.pdf"&gt;Bayes Filter by Cyrill Stachniss&lt;/a&gt;
&lt;br/&gt;
&lt;a href="http://ais.informatik.uni-freiburg.de/teaching/ss10/robotics/slides/10-kalman-filter.pdf"&gt;Introduction to Mobile Robotics - Bayes Filter – Kalman Filter&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://www.cnblogs.com/gaoxiang12/p/5560360.html"&gt;SLAM中的EKF，UKF，PF原理简介&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://blog.csdn.net/qq_30159351/article/details/53395515"&gt;SLAM笔记三——贝叶斯滤波器&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://blog.csdn.net/qinruiyan/article/details/50793114"&gt;SLAM学习笔记2：Kalman Filter(卡尔曼滤波) 与Least Square(最小二乘法) 的比较&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://www.cnblogs.com/ycwang16/p/5995702.html"&gt;细说贝叶斯滤波：Bayes filters&lt;/a&gt;
&lt;br/&gt;
&lt;a href="http://www.cnblogs.com/ycwang16/p/5999034.html"&gt;细说Kalman滤波：The Kalman Filter&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>非线性优化</title><link href="/fei-xian-xing-you-hua.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:fei-xian-xing-you-hua.html</id><summary type="html">&lt;p&gt;From &lt;a href="https://en.wikipedia.org/wiki/Nonlinear_programming"&gt;wiki&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In mathematics, nonlinear programming is the process of solving an optimization
problem where some of the constraints or the objective function are nonlinear.
An optimization problem is one of calculation of the extrema
(maxima, minima or stationary points) of an objective function over a set of
unknown real variables and conditional to the satisfaction of a system of
equalities and inequalities, collectively termed constraints.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="http://blog.sina.com.cn/s/blog_7445c2940102x3x4.html"&gt;到底什么是非线性优化&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>MLE &amp; MAP</title><link href="/mle-map.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:mle-map.html</id><summary type="html">&lt;p&gt;MLE：最大似然概率 给定测量结果，系统模型，寻求系统模型参数让结果跟观测结果最贴近。&lt;/p&gt;
&lt;p&gt;似然函数（也称作似然），是一个关于统计模型参数的函数。也就是这个函数中自变量是统计模型的参数。
&lt;br/&gt;
对于观测结果 x ，在参数集合 θ 上的似然，就是在给定这些参数值的基础上，观察到的结果的概率 P(x|θ) 。
也就是说，似然是关于参数的函数，在参数给定的条件下，对于观察到的 x 的值的条件分布。&lt;/p&gt;
&lt;p&gt;MAP:最大后验概率, 考虑到先验概率的存在 prior probability.
Bayes rule
&lt;/p&gt;
&lt;div class="math"&gt;$$P(\theta|x) = \frac{P(x|\theta) * p(\theta)}{p(x)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$P(x|y,z) = \frac{P(y|x,z)\cdot p(x|z)}{p(y|z)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\hat{\theta} = \mathop{arg\max}_{\theta} P(\theta|x) \propto P(x|\theta) * p(\theta)$$&lt;/div&gt;
&lt;p&gt;
分母可以去掉，与求参数无关&lt;/p&gt;
&lt;p&gt;已知观测结果，寻找参数，使得模型输出最符合观测。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E5%85%A8%E6%A6%82%E7%8E%87%E5%85%AC%E5%BC%8F"&gt;全概率公式&lt;/a&gt;
&lt;br/&gt;
&lt;a href="http://www.cnblogs.com/sylvanas2012/p/5058065.html"&gt;最大似然估计 （MLE） 最大后验概率（MAP）&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://zhuanlan.zhihu.com/p/25768606"&gt;概率与似然&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>数值分析</title><link href="/shu-zhi-fen-xi.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:shu-zhi-fen-xi.html</id><summary type="html">&lt;p&gt;From
&lt;a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90"&gt;Wiki&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;数值分析（英语：numerical analysis），是指在数学分析（区别于离散数学）问题中，对使用数值近似（相对于一般化的符号运算）算法的研究。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;direct method&lt;/p&gt;
&lt;p&gt;iterative method&lt;/p&gt;
&lt;p&gt;Numerical analysis
解析解/闭合解
数值解&lt;/p&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>Variance, gradient, Jacobian and Hessian matrix 记忆</title><link href="/variance-gradient-jacobian-and-hessian-matrix-ji-yi.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:variance-gradient-jacobian-and-hessian-matrix-ji-yi.html</id><summary type="html">&lt;p&gt;Jacobian矩阵　用于一阶梯度下降法&lt;br/&gt;
Hessian矩阵，用于二阶牛顿法&lt;br/&gt;
高斯牛顿法，使用J&lt;sup&gt;T&lt;/sup&gt;J作为牛顿法中二阶Hessian矩阵的近似，　从而省略了计算Ｈ的过程&lt;br/&gt;
&lt;a href="http://jacoxu.com/jacobian%E7%9F%A9%E9%98%B5%E5%92%8Chessian%E7%9F%A9%E9%98%B5/"&gt;下面这个文章介绍了Jacobian与Hessian矩阵的关系用途&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hessian是对称矩阵&lt;br/&gt;
&lt;a href="https://blog.csdn.net/dsbatigol/article/details/12558891"&gt;jacobian, Hassian and gradient关系&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;covariance,协方差：&lt;br/&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$cov(X,Y) = E((X-\mu)(Y-\nu)) = E(X \cdot Y) - \mu\nu$$&lt;/div&gt;
&lt;p&gt;variance, 方差：　二阶矩&lt;br/&gt;
 一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离, &lt;span class="math"&gt;\(\mu=E[X]\)&lt;/span&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$Var(X) = cov(X, X)$$&lt;/div&gt;
&lt;div class="math"&gt;$$Var(X) = E[(X-\mu)^2]$$&lt;/div&gt;
&lt;p&gt;期望：　一阶矩&lt;br/&gt;
&lt;a href="https://zh.wikipedia.org/wiki/%E5%8D%8F%E6%96%B9%E5%B7%AE"&gt;方差Wiki&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>线性规划</title><link href="/xian-xing-gui-hua.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:xian-xing-gui-hua.html</id><summary type="html">&lt;p&gt;线性优化，　线性规划，　linear programming&lt;/p&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry></feed>