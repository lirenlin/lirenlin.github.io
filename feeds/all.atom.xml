<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Yet another site</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2019-02-16T20:20:10+01:00</updated><entry><title>位姿图优化空间平移问题</title><link href="/wei-zi-tu-you-hua-kong-jian-ping-yi-wen-ti.html" rel="alternate"></link><updated>2019-02-16T20:20:10+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-16:wei-zi-tu-you-hua-kong-jian-ping-yi-wen-ti.html</id><summary type="html">&lt;p&gt;A Tutorial on Graph-Based SLAM&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;
中有提到一个细节，&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that the error of a constraint &lt;span class="math"&gt;\(e_{ij}\)&lt;/span&gt; depends only on the relative position
of the connected pose &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; and &lt;span class="math"&gt;\(x_j\)&lt;/span&gt;.  Accordingly, the error &lt;span class="math"&gt;\(F(x)\)&lt;/span&gt; of a
particular configuration of the pose sxis invariant under a rigid transformation
of all the poses. This results in Eq. 15 being under determined. To numerically
solve this system it is therefore common practiceto constrain one of the
increments &lt;span class="math"&gt;\(\Delta x_k\)&lt;/span&gt; to be zero. This can bedone by adding the identity matrix to
thekthdiagonal block &lt;span class="math"&gt;\(H[kk]\)&lt;/span&gt;.  Without loss of generality in Algorithm 1 we
fix the first node &lt;span class="math"&gt;\(x1\)&lt;/span&gt;. An alternative way to fix a particular node
of the pose-graph consists in suppressing the kth block row and the kth block column
of the linear system in Eq. 15.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class="math"&gt;\(e_{ij}\)&lt;/span&gt;约束的误差，只取决于&lt;span class="math"&gt;\(x_i\)&lt;/span&gt;与&lt;span class="math"&gt;\(x_j\)&lt;/span&gt;的相对位置。如果所有的位姿点，统一进行一个刚体
变换，那么目标error function是不变的，系统欠定，有无数解。&lt;/p&gt;
&lt;p&gt;同样更广泛的问题在Visual SLAM Tutorial: Bundle Adjustment&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;中，有专门一章节来描述。&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="http://www2.informatik.uni-freiburg.de/~stachnis/pdf/grisetti10titsmag.pdf"&gt;A Tutorial on Graph-Based SLAM&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;&lt;a href="/pdfs/Visual_SLAM_Tutorial_Bundle_Adjustment.pdf"&gt;Visual SLAM Tutorial: Bundle Adjustment&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="SLAM"></category></entry><entry><title>Badminton</title><link href="/badminton.html" rel="alternate"></link><updated>2019-02-16T09:00:30+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-16:badminton.html</id><summary type="html">&lt;p&gt;Es gibt so viel worter uber badminton. Ich muss mir sie gut merken, um badminto zu beschreiben. Zum Beispiel,&lt;/p&gt;
&lt;p&gt;der Federball
der Aufschlag
die Angabe
die Kraft, kraeftig
die Reaktion
die Mannschaft
das Spielfeld
die Geschwindigkeit
der Score
der Spielstand
die Seite
die Wiederholungen
der Punkt
die Zahl
der Beriech
die Abwehr, von 
der Satz 局
der Fehler
der Boden
der Punkt
ein Punkt gewinnen/erhalten
21 Punkte erreichen&lt;/p&gt;
&lt;p&gt;Mein schlaeger braucht ein neu Besaitung.
kannst du mir helfen, um mein schaeger zu besaiten?
Beseitung machen&lt;/p&gt;
&lt;p&gt;Besaiten
Besaitung, Bespannung
die Besaitunghaete 绑线磅数&lt;/p&gt;
&lt;p&gt;der Vorhand, Unterhand, rueckhandSchlag&lt;/p&gt;
&lt;p&gt;ziemlich muede
voellig erschoepft
beweglich&lt;/p&gt;
&lt;p&gt;abwechseln
alternieren&lt;/p&gt;
&lt;p&gt;weit
aus
an der Linie&lt;/p&gt;
&lt;p&gt;noch 
brauchbar&lt;/p&gt;
&lt;p&gt;gilt als unbespielbar
künstlich Spielball
synthetisch Ball
natuerlich Spielball&lt;/p&gt;</summary><category term="German"></category></entry><entry><title>BA vs Graph SLAM</title><link href="/ba-vs-graph-slam.html" rel="alternate"></link><updated>2019-02-15T13:05:07+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-15:ba-vs-graph-slam.html</id><summary type="html">&lt;p&gt;state vector
error function&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;parameterization for the state vector&lt;ul&gt;
&lt;li&gt;minimum parameterization, 对于分量是分别计算的，在有冗余的时候，例如旋转矩阵R，他们之间的约束没有表示出来，会求得不合理的组合
但是对于 minimum parameterization，可能不存在欧式空间的加法。不连续可导。&lt;/li&gt;
&lt;li&gt;Extended parameterization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class="math"&gt;\([x, y, \theta]\)&lt;/span&gt; or &lt;span class="math"&gt;\(T \to \mathbb SE(3)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is a well known thing that 3D rotations can be parameterized with a
rotation matrix R. A rotation matrix, however has 9 numbers to represent 3 angles. If we would use
the rotation matrices as parameters in our optimization mechanism we would find non-valid solutions,
since the orthogonality constraint is not enforced. Thus, it seems there is no alternative than carrying
on the optimization by using a minimal representation, for instance Euler angles. But we just said that
Euler angles suffer of singularities. Lucky us, the rotations are a manifold. That is, they admit a local
parameterization which is homeomorphic to the vector space Rn . To explain this sentence, think to a
generic rotation R(ρ, θ, ψ). We can easily define a mapping between rotation matrices and Euler angles,
and vice versa:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;if the state variable do not live in Euclidean space&lt;ul&gt;
&lt;li&gt;define a parameterization for the increment&lt;/li&gt;
&lt;li&gt;define &lt;span class="math"&gt;\(\boxplus\)&lt;/span&gt; operator.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;local parameterization of the increments &lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt; if X is not in E&lt;/p&gt;
&lt;p&gt;iteration state vector update
&lt;span class="math"&gt;\(X = X \boxplus \Delta X\)&lt;/span&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="SLAM"></category></entry><entry><title>Graph SLAM总结</title><link href="/graph-slamzong-jie.html" rel="alternate"></link><updated>2019-02-14T16:21:45+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-14:graph-slamzong-jie.html</id><summary type="html">&lt;h2&gt;Vertex&lt;/h2&gt;
&lt;p&gt;图的顶点，代表待优化的变量，具体表示形式取决于参数化(parameterazation)。&lt;/p&gt;
&lt;p&gt;顶点可以是多种形式，例如SLAM问题中的机器人位姿(pose)，或者路标的坐标(三维空间&lt;span class="math"&gt;\([x,y,z]\)&lt;/span&gt;，或者二维空间坐标&lt;span class="math"&gt;\([x,y]\)&lt;/span&gt;)。同时，位姿也可以用不同的参数表达，可以是两个位姿间的变化矩阵&lt;span class="math"&gt;\(T\)&lt;/span&gt;，或者是3DoF下的位置与转角&lt;span class="math"&gt;\([x,y,\theta]\)&lt;/span&gt;。可以融合多种信息，统一求解，非常的灵活。&lt;/p&gt;
&lt;h2&gt;Edge&lt;/h2&gt;
&lt;p&gt;相应的，不同顶点之间，需要合适的边连接起来，表示它们之间的约束与变换。这个需要与顶点的性质统一。&lt;/p&gt;
&lt;p&gt;例如，位姿顶点之间，是通过运动方程的边连接。位姿顶点与路标顶点，是通过观测方程连接。在没有相关信息的时候，也可以通过其他信息推导。例如在没有运动方程信息的时候，可以通过scan to scan match来获取pose之间的估计。但是，总体来说，信息越多，通过融合后的预测结果越可信。&lt;/p&gt;
&lt;p&gt;上述距离中，边为二元边，边的起始和结束，连接两个不同的顶点。边也可以是一元边，例如线性拟合问题，拟合的参数为一个顶点，多个采样点构成一元边，起始于参数顶点，结束于参数顶点，具体例子可以参考，视觉SLAM十四讲中的例子。&lt;/p&gt;
&lt;p&gt;举例，对于二维SLAM问题，定义两种顶点:
机器人pose, &lt;span class="math"&gt;\([x, y, \theta]\)&lt;/span&gt;
路标坐标, &lt;span class="math"&gt;\([x, y]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;运动方程，
&lt;/p&gt;
&lt;div class="math"&gt;$$f(x): \mathbbR^3 \to \mathbbR^3$$&lt;/div&gt;
&lt;p&gt;
观测方程，
&lt;/p&gt;
&lt;div class="math"&gt;$$h(x): \mathbbR^3 \to \mathbbR^2$$&lt;/div&gt;
&lt;p&gt;pose to pose constraint:
&lt;span class="math"&gt;\(T_i = \Delta T_{ij} T_{j}\)&lt;/span&gt;
某个pose处，激光测量，观测到一个空间点，顶点为一个2D pose: &lt;span class="math"&gt;\([x, y, \theta]^T\)&lt;/span&gt; 和一个point: &lt;span class="math"&gt;\([\lambda_x, \lambda_y]^T\)&lt;/span&gt;, 观测数据是Polar坐标， 距离r与角度b
&lt;/p&gt;
&lt;div class="math"&gt;$$[r,b] = []$$&lt;/div&gt;
&lt;h2&gt;误差最小化least square error&lt;/h2&gt;
&lt;p&gt;对于待优化的变量，不管是位姿还是坐标，都是矢量，以向量的形式存储。其误差也是向量形式。但是最小二乘问题的目标函数，要求是一个标量。最直观的方式是取模(norm, 2范数)，也就是”平方“。矩阵形式为&lt;span class="math"&gt;\(e^Te\)&lt;/span&gt;。同时为了表示对于个误差分量都的重视程度(精确度的信任度)不一样，还是用一个信息矩阵&lt;span class="math"&gt;\(\Omega\)&lt;/span&gt;来进行不同的加权，总体的目标函数写成：
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
\min\limits_{x} \sum\limits_{k = 1}^n {{e_k}{{\left( {{x_k},{z_k}} \right)}^T}{\Omega _k}{e_k}\left( {{x_k},{z_k}} \right)}
\end{equation}&lt;/div&gt;
&lt;h3&gt;核函数 robust kernel function&lt;/h3&gt;
&lt;p&gt;在图中，可能会存在错误的边，对应最小二成中某一误差项过于的大，或者根本不合理。类似于观测中的outlier。因为算法目标是整体误差结果最小化，这会导致整体的结果出现偏移。如何有效的剔除outlier，或者最小化它的影响，是算法稳定的一大目标。
核函数的存在就是限制误差的增长。把传统的误差二范数度量，替换成一个在误差大的情况下，增长没有那么快的函数，同时，还必须保证自身的光滑可导行。&lt;/p&gt;
&lt;h2&gt;误差信息矩阵，系统信息矩阵&lt;/h2&gt;
&lt;p&gt;边信息矩阵&lt;span class="math"&gt;\(\Omega\)&lt;/span&gt;，协方差矩阵的逆，最小二乘的权重，相关性越高，协方差越大，该误差权重越小。如果协方差越小，表示这次测量(边，constraint)越准，越值得相信。&lt;/p&gt;
&lt;p&gt;信息矩阵有如下性质：&lt;/p&gt;
&lt;p&gt;1, 对称矩阵 symmetric matrix
2, 对角线上元素为方差，如果各个误差间独立，那么为对角阵。对角阵元素大小表示误差的权重。&lt;/p&gt;
&lt;p&gt;举例：&lt;span class="math"&gt;\(\Omega_{ij}代表i顶点与j顶点之间误差变量的协方差矩阵。如果一个边的对应的误差参数是\)&lt;/span&gt;[\Delta x,\Delta y,\Delta \theta]^T&lt;span class="math"&gt;\(，
那么对应的协方差矩阵\)&lt;/span&gt;\Omega_{ij} \in
\mathbbR^{3x3}&lt;span class="math"&gt;\(，因为是对称矩阵的缘故，只需要6个变量来存储:
$(inf_{xx}, inf_{xy}, inf_{x\theta}, inf_{yy}, inf_{y\theta}, inf_{\theta\theta})\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(e_{ij}(X_i, X_j) \in \mathbb R^{3x1}\)&lt;/span&gt;, &lt;/p&gt;
&lt;p&gt;系统信息矩阵H&lt;/p&gt;
&lt;h3&gt;full SLAM H的求解&lt;/h3&gt;
&lt;h3&gt;online SLAM H的维护更新&lt;/h3&gt;
&lt;h2&gt;矩阵形式的理解&lt;/h2&gt;
&lt;p&gt;最后落实到代码中，需要切实的理解数学中矩阵运算的具体分解步骤&lt;/p&gt;
&lt;h2&gt;相关博文&lt;/h2&gt;
&lt;p&gt;非常感谢相关博主无私的分享他们的理解！&lt;/p&gt;
&lt;h2&gt;从信息矩阵的方式去理解&lt;/h2&gt;
&lt;p&gt;在概率机器人一书中，推导方式是从信息滤波器角度推导的information filter,
而不是从最小二乘。&lt;/p&gt;
&lt;p&gt;在信息矩阵的概念下，GraphSLAM只需要维护information matrix
&lt;span class="math"&gt;\(\Omega\)&lt;/span&gt;与信息向量&lt;span class="math"&gt;\(\xi\)&lt;/span&gt;，状态结果，也就是期望值，可以通过&lt;span class="math"&gt;\(\mu = {\Omega}^{-1} \xi\)&lt;/span&gt;
计算得到。同时，可以对信息矩阵，信息向量尽心消元操作，使的其只包含pose信息。
然后先求得所有位姿信息，然后根据路标与相应的观测到次路标的位姿节点，求解路标信息，
得到地图信息。&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="SLAM"></category></entry><entry><title>Header-only library</title><link href="/header-only-library.html" rel="alternate"></link><updated>2019-02-09T15:51:09+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-09:header-only-library.html</id><summary type="html">&lt;h2&gt;Function definition in the header&lt;/h2&gt;
&lt;p&gt;The preprocessor will literally copy the content of header into the including
file. The &lt;code&gt;ifdef&lt;/code&gt; guard makes sure, for a given file, the same header file is
only included once.&lt;/p&gt;
&lt;p&gt;It is fine that a function is defined in the header. The compiler(in this
sense, it doesn't include the assembler or linker part) won't complains any
thing. The C source file will be compiled into an object with symbol
information. When it comes to the linking stage, if there are multiple object
files have the same symbol definition in their symbol table, the linker will
throw error, something like "multiple definition".&lt;/p&gt;
&lt;p&gt;One way the circumvent this is to add &lt;code&gt;inline&lt;/code&gt; attribute to every function
definition in the header. So that no symbol will be created. The other possible
solution is to add &lt;code&gt;static&lt;/code&gt; attribute to the function definition.&lt;/p&gt;
&lt;h2&gt;Function definition inside class definition&lt;/h2&gt;
&lt;p&gt;A member function that is defined inside its class member list is called an
inline member function.&lt;/p&gt;
&lt;p&gt;Once can also declare the function as &lt;code&gt;inline&lt;/code&gt;, and define it outside of class
definition.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;inline&lt;/code&gt; attribute is merely a hint to the compiler. So it won't always give
the same effect as macro.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The main (only?) use for the inline keyword nowadays it to allow functions to
be defined in the header and not generate multiple definition link errors
(which has nothing to do with inlining really).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Template class&lt;/h2&gt;
&lt;p&gt;template libs must be provided as head-only form. The compiler need to know the
the parameter types as well as the library code at the time.&lt;/p&gt;
&lt;h2&gt;Advantage/Disadvantage of head-only library&lt;/h2&gt;
&lt;p&gt;In theory, the compiler could do better optimization when the definition is
visible to it. But nowadays, the compiler could do optimization across compilation
unit. And because of other complications like linker optimization, hardware
features, the benefit is not always observable.&lt;/p&gt;
&lt;p&gt;It is best to measure the code size and performance change with specific use
case. And code maintainability is also an import aspect to consider.&lt;/p&gt;
&lt;h2&gt;Link&lt;/h2&gt;
&lt;p&gt;https://stackoverflow.com/questions/16679709/defining-member-functions-inside-the-class-definition&lt;/p&gt;
&lt;p&gt;https://en.wikipedia.org/wiki/Header-only&lt;/p&gt;
&lt;p&gt;https://softwareengineering.stackexchange.com/questions/305618/are-header-only-libraries-more-efficient&lt;/p&gt;</summary><category term="Programming"></category></entry><entry><title>lingua.com lernen</title><link href="/linguacom-lernen.html" rel="alternate"></link><updated>2019-02-09T11:19:22+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-09:linguacom-lernen.html</id><summary type="html">&lt;h2&gt;Niveau A1&lt;/h2&gt;
&lt;h3&gt;Juliana in Deutschland&lt;/h3&gt;
&lt;p&gt;verbringen 度过&lt;/p&gt;
&lt;p&gt;wahrscheinlich 可能&lt;/p&gt;
&lt;h3&gt;Vorstellung&lt;/h3&gt;
&lt;p&gt;vorstellung 介绍&lt;/p&gt;
&lt;p&gt;in der Naehe von&lt;/p&gt;
&lt;p&gt;der Teich 池塘&lt;/p&gt;
&lt;p&gt;mit + Dativ&lt;/p&gt;
&lt;p&gt;am see&lt;/p&gt;
&lt;h2&gt;Niveau A2&lt;/h2&gt;
&lt;h3&gt;Am Flughafen&lt;/h3&gt;
&lt;p&gt;ihr, 她(Dat.) 你们 她的，她/他们的，您们的
euer你们的
sie 他们&lt;/p&gt;
&lt;p&gt;am Strand 在沙滩
lassen + 动词不定式，不需要zu
die Angestellten 雇员
beraten 讨论，商讨
auswahlen 选择
abflug 起飞, abfahren, losgehen
der Schalter 窗口 am Schalter
einchecken 办理登机手续
erreichen 抵达，到达 ein Ziel erreichen, 及物动词，ankommen
der Bereich 区域，范围，领域, Wartebereich
leiden 忍受
uebel 不愉快的
fehlen 丢失，缺少，缺乏，缺席
warten auf + Akk.&lt;/p&gt;
&lt;h3&gt;Berufe&lt;/h3&gt;
&lt;p&gt;der Beruf
beibringen 教授，传授
unterricheten
untersuchen 检查，调查，研究，考察
feststellen
verschreiben 开药方
herstellen 生产
mischen
das Getreide 谷物，粮食
zubereiten 准备，烹调
entweder .. oder .. 不是..就是..
der Laden 店铺
der Chirurg 外科医生&lt;/p&gt;
&lt;h3&gt;Der Weg zur Post&lt;/h3&gt;
&lt;p&gt;An der Bushaltestelle
mit + Dative
los gehen
abbiegen 拐弯， rechts abbiegen
einbiegen 拐入, nach links in die Schillerstrasse einbiegen
im Internet, auf xx website
einen Brief abschicken
hoeflich 有礼貌的
ueberqueren&lt;/p&gt;
&lt;h3&gt;Die Farben&lt;/h3&gt;
&lt;p&gt;spannen 张紧，拉紧
bunt 五彩的，花哨的，花斑的
bestehen aus, 由...组成
der Regenbogen, der Bogen, 曲线，弧线，拱形，拱门
farbig, farblos
der Himmel 天空 am Himmel
das Blatt 叶子, 叶片
Meer vs See
hell (Licht)明亮的，浅色的，淡色的，(Stimme)尖锐的
ergeben 产生，得出
die Wolke 云，云雾
der stamm
auffallen 引人瞩目的, 突出的，显眼的
der Vogel 鸟
aehnlich 类似的 Ich hatte einen aehnichen Gedanken wie du.
der Schmuck
edel 高尚的，高贵的，贵重的
lila 淡紫色的&lt;/p&gt;
&lt;h3&gt;Ein Tag in Berlin&lt;/h3&gt;
&lt;p&gt;zuvor 以前，事先，先前
einen Kuchen in zwolf Stucke teilen
ehemalig 以前的，从前的，原先的
verlaufen
nennen 取名，称作, 称之为
die Erinnerung 记忆，回忆，记忆力，纪念
Erinnerung an unsere Schulzeit
die Regierung 政府，执政，掌权，统治, under seiner Regierung
der buerger 公民，国民
das Gesetz 规则，定律，法则，法律，条例
der Reichstag 国会大厦，国会
das Ufer 岸，河岸，海岸 am Ufer&lt;/p&gt;
&lt;h3&gt;Einkauf im Supermarkt&lt;/h3&gt;
&lt;p&gt;aufschreiben 写下来
der Kist 箱子
im Angebot
die Tuete 包装袋，口袋
wiegen
feiern
einige 一些，少许
der Erwachsene 成年人，承认
Ihr durft nur auf den Spielplatz, wenn eine Erwachsene mitkommt.
der Besuch 访问，做客，探望
absagen
daheim 在家
die Muenze 硬币&lt;/p&gt;
&lt;h3&gt;Feste und Feiertage in Deutschland&lt;/h3&gt;
&lt;p&gt;Auf die Strasse
die Einheit 统一，团结，一致
die Kerze 蜡烛
der Kranz 花环，花圈，花冠
an jmdn./dtw. denken 怀念，想念，想到
der Ehrentag 纪念日
ehren 尊重，使感到自豪
verwohnen 溺爱，宠爱，娇惯
stattfinden 举行，发生
begruessen&lt;/p&gt;
&lt;h3&gt;Im Restaurant&lt;/h3&gt;
&lt;p&gt;der Kellner
folgen Sie mir, + Dativ
reservieren einen Tisch fur zwei auf den Namen Muller
koestlich 美味的，可口的
furchtabar
in bar bezahlen 现金付账&lt;/p&gt;
&lt;h3&gt;In der Schule&lt;/h3&gt;
&lt;p&gt;die Schule
die Ferien 假期
sogar 就连...也...，连...都...
zu guter Letzt
ziehen, zog, hatist gezogen
Vor drei Monaten sind sie zusammen nach Berlin gezogen.
der Tag, im Mittwoch&lt;/p&gt;
&lt;h3&gt;Länder und Nationalitäten&lt;/h3&gt;
&lt;h3&gt;Lebensmittel einkaufen&lt;/h3&gt;
&lt;h3&gt;Mein Tag&lt;/h3&gt;
&lt;h3&gt;Meine Familie&lt;/h3&gt;
&lt;h3&gt;Meine Stadt&lt;/h3&gt;
&lt;h3&gt;Meine Woche&lt;/h3&gt;
&lt;h3&gt;Neu in der Stadt&lt;/h3&gt;
&lt;h3&gt;Pläne für die Freizeit&lt;/h3&gt;
&lt;h3&gt;Tagesablauf&lt;/h3&gt;
&lt;h3&gt;Tom unterwegs&lt;/h3&gt;
&lt;h3&gt;Urlaub in den Bergen&lt;/h3&gt;
&lt;h3&gt;Verkehrsmittel&lt;/h3&gt;
&lt;h3&gt;Wandern in der Natur&lt;/h3&gt;
&lt;h3&gt;Weihnachten&lt;/h3&gt;
&lt;h2&gt;Niveau B1&lt;/h2&gt;
&lt;h3&gt;Berlin&lt;/h3&gt;
&lt;h3&gt;Bewerbung&lt;/h3&gt;
&lt;h3&gt;Das Wetter&lt;/h3&gt;
&lt;h3&gt;Der Körper&lt;/h3&gt;
&lt;h3&gt;Die vier Jahreszeiten&lt;/h3&gt;
&lt;h3&gt;Ein Tag in Frankfurt am Main&lt;/h3&gt;
&lt;h3&gt;Ein Tag in Hamburg&lt;/h3&gt;
&lt;h3&gt;Ein Tag in Heidelberg&lt;/h3&gt;
&lt;h3&gt;Ein Tag in Köln&lt;/h3&gt;
&lt;h3&gt;Ein Tag in München&lt;/h3&gt;
&lt;h3&gt;Ein verhexter Tag (Brief)&lt;/h3&gt;
&lt;h3&gt;Freizeitgestaltung&lt;/h3&gt;
&lt;h3&gt;Gesundheit: Beim Arzt&lt;/h3&gt;
&lt;h3&gt;Kleidung&lt;/h3&gt;
&lt;h3&gt;Mein Leben&lt;/h3&gt;
&lt;h3&gt;Sport&lt;/h3&gt;
&lt;h2&gt;Niveau B2&lt;/h2&gt;
&lt;h3&gt;Ein Tag in Genf&lt;/h3&gt;
&lt;h3&gt;Ein Tag in Salzburg&lt;/h3&gt;
&lt;h3&gt;Ein Tag in Wien&lt;/h3&gt;
&lt;h3&gt;Ein Tag in Zürich&lt;/h3&gt;
&lt;h3&gt;Feste und Brauchtum in Deutschland&lt;/h3&gt;
&lt;h3&gt;Johann Wolfgang von Goethe&lt;/h3&gt;
&lt;h3&gt;Mein bester Freund&lt;/h3&gt;
&lt;h3&gt;Ostern&lt;/h3&gt;</summary><category term="German"></category></entry><entry><title>Apollo代码结构</title><link href="/apollodai-ma-jie-gou.html" rel="alternate"></link><updated>2019-02-07T20:14:27+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-07:apollodai-ma-jie-gou.html</id><summary type="html">&lt;p&gt;https://blog.csdn.net/tianzy16/article/details/83988402&lt;/p&gt;</summary><category term="SLAM"></category></entry><entry><title>Cartographer源码</title><link href="/cartographeryuan-ma.html" rel="alternate"></link><updated>2019-02-07T20:13:11+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-07:cartographeryuan-ma.html</id><summary type="html">&lt;p&gt;https://zhuanlan.zhihu.com/p/48010119&lt;/p&gt;
&lt;p&gt;https://blog.csdn.net/MyArrow/article/details/80605118
https://blog.csdn.net/u012209790/article/details/82629422&lt;/p&gt;</summary><category term="SLAM"></category></entry><entry><title>机器人局部蔽障</title><link href="/ji-qi-ren-ju-bu-bi-zhang.html" rel="alternate"></link><updated>2019-02-07T18:48:59+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-07:ji-qi-ren-ju-bu-bi-zhang.html</id><summary type="html">&lt;h2&gt;动态窗口法(Dynamic window approach)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;根据运动模型，机器人参数，生成一个合理的搜索空间(search space）&lt;/li&gt;
&lt;li&gt;根据评价函数，选取最后方案&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;动态窗口法主要是在速度(v,w)空间(线速度，角速度)中，采样多种速度可能性，并模拟
在一个固定时间sim_period内，机器人的轨迹，得到多组轨迹以后，对轨迹进行评价，
选取最优轨迹对应的速度来驱动机器人。
如何选取可行的二维速度空间，并且使之尽可能小，这样需要模拟的可能路径就少。
在DWA中，这个窗口的确定是根据机器人的加减速性能(kinematic constraint)&lt;/p&gt;
&lt;p&gt;(程序每隔0.25秒运行一次，sim_period = 0.25s, 计算出在此时刻，根据不同的速度采样，sim_period以后各自不同的轨迹，选取其中最符合最优标准的速度，转换成机器人控制，完成一次的控制。然后等待下一个sim_period再进行同样的循环操作)&lt;/p&gt;
&lt;p&gt;具体解释，可参考：机器人局部避障的动态窗口法(dynamic window approach)&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2&gt;动态窗口法缺点&lt;/h2&gt;
&lt;p&gt;http://ais.informatik.uni-freiburg.de/teaching/ss10/robotics/slides/16-pathplanning.pdf&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;https://blog.csdn.net/heyijia0327/article/details/44983551&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="SLAM"></category></entry><entry><title>ICP</title><link href="/icp.html" rel="alternate"></link><updated>2019-02-07T17:54:55+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-07:icp.html</id><summary type="html">&lt;p&gt;Iterative Closest Point Algorithm主要由两部分组成&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data Association&lt;ul&gt;
&lt;li&gt;Closest-Point Matching&lt;br /&gt;
Kd-trees&lt;/li&gt;
&lt;li&gt;Normal Shooting&lt;br /&gt;
Slightly better convergence results than closest point for smooth structures,
worse for noisy or complex structures&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Error Metric:&lt;ul&gt;
&lt;li&gt;point to point&lt;br /&gt;
  SVD解法&lt;/li&gt;
&lt;li&gt;point to plane&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;br /&gt;
Each iteratrion generally slower than the point-to-point versin, however, often
significantly better convergence rates.&lt;br /&gt;
solved using standard linear least-squares problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;基于k-d tree的ICP算法计算分析&lt;/h2&gt;
&lt;p&gt;使用k-d tree来加速整个过程的计算。总体计算花销分为两方面:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span style="color:red"&gt; 从参考点云建立k-d树需要花销 &lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span style="color:red"&gt; k-d tree 查找的花销，其中主要是三个步骤，DFS查找，
ball-within-bounds test和backtracking. &lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span style="color:red"&gt; 同时，因为使用了kd-tree数据结构，那么tree的平衡性，
会对整个查找复杂度有很大影响 &lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在SLAM中，得到t时刻与t+1时刻的两幅环境的稀疏扫描点云，需要point
registreation来计算两个时刻间，机器人的位姿(pose)变换(rotation + translation)。
这当中包含一次k-d tree的简历，与许多次的ICP迭代，每次迭代，都需要对每一个query
point进行k-d tree的查找。&lt;/p&gt;
&lt;p&gt;有很多的优化方法，让r-d tree的建立，查找操作都更加快速。这些优化对于点云的拓扑结构
有一些假设。这些假设，在机器人应用场景下，不一定成立。大多时候，场景通过机器人的
传感器稀疏采样的。&lt;/p&gt;
&lt;h3&gt;cached k-d tree search for ICP algorithms&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/h3&gt;
&lt;p&gt;在论文中，作者有如下评论&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span style="color:red"&gt;
However, these state of the art ICP variants all assume that the input data is
given as a mesh.  In many application scenarios a mesh is not available, e.g.,
3D data in robotics. Here, measurements contain in addition to Gaussian noise so
called salt-and-pepper noise. Furthermore, in robotics the scenes are often
sparsely sampled by the sensor. For these two reasons, simple meshing methods
based on the topology of the acquired points cannot be applied and roboticists
stick to using the raw point clouds. In this case the point-to-point metric,
cf. Eq. (1), and closest point search have to be used.
&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以传统的point-to-point error metric, k-d tree based closed point
search还是主流。目前我还没有阅读其他论文，所以无法评论作者观点是否正确。但是如果
真的这样，就只能在机器人场景下，，使用比较传统的方式。但是，r-d
tree的构建，查找还是可以利用硬件特性，例如GPU进行加速。&lt;/p&gt;
&lt;p&gt;在这篇论文中，作者改进了backtracking的思路，减少DFS搜索次数，同时使得backtracking
操作大致constant time。这是利用ICP的迭代算法特性，因为如果整个过程收敛，越到后面，
变换矩阵会越来越小，通过记录上一个iteration，查询点在r-d
tree中大致的位置，可以在当前iteration中大致估计，也会在差不多的位置。所以，不同于从
root开始重新查找一遍，这次从上一次的leaf node开始，反向查找。&lt;/p&gt;
&lt;p&gt;作者给出了性能比较，整体性能提升很明显。在这里，bucket size对性能也有影响。
通常对于k-d tree的讲解资料中，bucket size是1。在作者给出的性能对比中，cached
kd-tree在bucket size为1的时候提升最大。同时值得注意的是，bucket size
为1的时候，整体性能是最差的。所以为了寻求绝对性能的最大，还是要尝试不同的bucket
size。&lt;/p&gt;
&lt;p&gt;在文中，作者同时提到&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span style="color:red"&gt;
The overall performance of the ICP algorithm depends
both on the search time and on the construction time
of the tree. However, the construction time of the trees
seems to be negligible.
&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在他的测量中，kd-tree的建立花销对整体性能影响不大，这也需要自己实际去测量。&lt;/p&gt;
&lt;p&gt;cached kd-tree需要一块内存在缓存上一迭代的结构，同时因为需要回溯的缘故，
每一个树节点需要保存一个父节点的指针。所以它会有额外的存储花销&lt;span class="math"&gt;\(O(N_d) +
O(N_m)\)&lt;/span&gt;, &lt;span class="math"&gt;\(N_m\)&lt;/span&gt;为reference data cloud point点数，&lt;span class="math"&gt;\(N_d\)&lt;/span&gt;为待匹配点云点数。&lt;/p&gt;
&lt;h3&gt;kd-tree construction optimization&lt;/h3&gt;
&lt;p&gt;普通情况下，需要寻找以当前划分坐标轴为衡量标准的所有点的中位数(median)，在naive
的算法里, median-finding algorithm复杂度为&lt;span class="math"&gt;\(O(n)\)&lt;/span&gt;，使用排序的方法的话，
可以优化到&lt;span class="math"&gt;\(nO(log\;n)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;具体可参考&lt;a href="https://en.wikipedia.org/wiki/K-d_tree#Complexity"&gt;wiki, ICP Complexity&lt;/a&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;http://ais.informatik.uni-freiburg.de/teaching/ss10/robotics/slides/17-icp.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;&lt;a href="/pdfs/Cachedk-d_tree_search_for_ICP_algorithms.pdf"&gt;Cached k-d tree search for ICP algorithms&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;https://www.comp.nus.edu.sg/~lowkl/publications/lowk_point-to-plane_icp_techrep.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>Robust regression</title><link href="/robust-regression.html" rel="alternate"></link><updated>2019-02-01T01:06:33+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-02-01:robust-regression.html</id><summary type="html">&lt;p&gt;最小二乘法对于outlier比较敏感&lt;/p&gt;
&lt;p&gt;对于高斯噪声，最大似然等同于最小二乘
https://www.jianshu.com/p/d0ea25071c57&lt;/p&gt;
&lt;p&gt;So for least squares to have a useful statistical interpretation, the Wi should 
be chosen to approximate the inverse measurement covariance of z i.
Even for non-Gaussian noise with this mean and covariance, the Gauss-Markov
theorem [37, 11] states that if the models zi (x) are linear, least squares
gives the Best Linear Unbiased Estimator (BLUE), where ‘best’ means minimum
variance.&lt;/p&gt;
&lt;p&gt;Least square with covariance as weight matrix??&lt;/p&gt;
&lt;h2&gt;robust regression&lt;/h2&gt;
&lt;p&gt;loss function&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>SLAM</title><link href="/slam.html" rel="alternate"></link><updated>2019-01-29T16:27:32+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-29:slam.html</id><summary type="html">&lt;h2&gt;纯激光SLAM地图构建&lt;/h2&gt;
&lt;p&gt;如果平台只有激光测距的传感器，那个这个系统只有观测方程，没有运动方程。&lt;/p&gt;
&lt;p&gt;在卡尔曼滤波中，步骤分为预测与更新，没有了运动方程，这里只能有一步。由于没有额外
的信息来消除误差，在运动/观测过程中的误差不会被消除，只会一直积累。&lt;/p&gt;
&lt;p&gt;这需要依赖后端的图优化来一次性优化所有地图的信息，这里回环检测就非常重要，它添加额外的非常
重要的信息。也就是在图优化的术语中，添加了一个非常强的约束。&lt;/p&gt;
&lt;p&gt;对于运动的估计，利用点云匹配的方法求出，也就是位移与旋转。常用的方法有ICP。在这里，
算法的稳定性尤为重要，因为这是唯一的估计运动的来源。由于，相邻的测量数据里只有部
分信息重合，需要避免误匹配。同时，计算量会很大，效率很重要。&lt;/p&gt;
&lt;p&gt;scan to scan
scan to map
map to map&lt;/p&gt;
&lt;h2&gt;landmark extraction from laser scan&lt;/h2&gt;
&lt;p&gt;也称作环境feature extraction?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spike landmarks, 对于环境中类似于脱离背景的人，因为其筛选标准，会错误判断为路标&lt;/li&gt;
&lt;li&gt;RANSAC, use line extraction, 对于环境中移动的人，有一定的稳定特性。但是对于块状移动物体，例如汽车，肯能也会错误的识别为路标&lt;/li&gt;
&lt;li&gt;scan mathing, 不提取特征，直接比较相邻时刻的laser scans, 计算量问题，稳定性问题，data point reduce, data align问题。后续有看到feature-based laser scan mathing 文章。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;KF-SLAM, online SLAM&lt;/h2&gt;
&lt;p&gt;&lt;figure&gt;
&lt;img src="images/slam04_ekf_state.png" alt="EKF state" title="EKF state" style="max-width:80%;max-height:80%"/&gt;
&lt;figcaption&gt; Figure. EKF state representation&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;img src="images/slam08_kf_complexity.png" alt="EKF complexity" title="EKF complexity" style="max-width:80%;max-height:80%"/&gt;
&lt;figcaption&gt; Figure. EKF complexity&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;/figcaption&gt;
&lt;/figure&gt;
因为图1中状态的表示与路标数成比例，协方差矩阵(信息矩阵)的大小是路标数量的二阶形式。在卡尔曼滤波过程中，一直需要维护更新这个矩阵。&lt;/p&gt;
&lt;h3&gt;EKF&lt;/h3&gt;
&lt;h3&gt;UKF&lt;/h3&gt;
&lt;h3&gt;SEIF&lt;/h3&gt;
&lt;h2&gt;拥有反馈的SLAM系统&lt;/h2&gt;
&lt;p&gt;在这个系统中，有多种传感器，融合所有传感器的信(sensor fusion)，可以修正一定的误差&lt;/p&gt;
&lt;h2&gt;Online SLAM vs Full SLAM&lt;/h2&gt;
&lt;p&gt;在没有回环检测的时候，卡尔曼滤波与图优化的优劣，strip状的路径
卡尔曼滤波计算更小，数据存储越小？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前端&lt;ol&gt;
&lt;li&gt;特征点提取&lt;/li&gt;
&lt;li&gt;特征匹配，计算相对运动矩阵，估计位姿，估计路标坐标&lt;/li&gt;
&lt;li&gt;回环检测&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;后端&lt;ol&gt;
&lt;li&gt;优化，更新位姿，路标&lt;/li&gt;
&lt;li&gt;parameterization: 优化方法求导，四元数
iterative non-linear optimization: LM, Gauss-Newton etc.
solve symstem of linear euqation: 计算
matrix decomposition: 计算
matrix sparseness: 问题的结构，优化计算
numeric stability(condition number):
Marginalization: 消原，或者局部更新，window
outlier: &lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;http://ais.informatik.uni-freiburg.de/teaching/ws12/mapping/pdf/slam04-ekf-slam.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;http://ais.informatik.uni-freiburg.de/teaching/ws12/mapping/pdf/slam08-kf-wrapup.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="SLAM"></category></entry><entry><title>智能家具设计</title><link href="/zhi-neng-jia-ju-she-ji.html" rel="alternate"></link><updated>2019-01-29T14:54:31+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-29:zhi-neng-jia-ju-she-ji.html</id><summary type="html">&lt;p&gt;无线控制开关，使用继电器(relay)
bistable(latching) relay可以在没有控制信号的时候保持状态&lt;/p&gt;
&lt;p&gt;RF控制，需要直接对着
蓝牙控制, 需要控制mcu
网络控制, 需要控制mcu&lt;/p&gt;</summary><category term="Home"></category></entry><entry><title>卡尔曼滤波，最大似然，最小二乘</title><link href="/qia-er-man-lu-bo-zui-da-si-ran-zui-xiao-er-cheng.html" rel="alternate"></link><updated>2019-01-28T23:33:07+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-28:qia-er-man-lu-bo-zui-da-si-ran-zui-xiao-er-cheng.html</id><summary type="html">&lt;p&gt;最小二乘估计：不考虑数据的统计特性，如期望，方差等，直接用最小二乘法得到最优估计。
最小二乘估计只保证测量值与估计值的平方和最小，不保证估计误差的方差最小。最小二乘估计不需要随机变量V的任何统计信息。&lt;/p&gt;
&lt;p&gt;测量误差（测量）服从高斯分布的情况下， 最小二乘法等价于极大似然估计。(负对数)&lt;/p&gt;
&lt;p&gt;卡尔曼误差高斯分布后验概率推导
http://www.cnblogs.com/ycwang16/p/5999034.html&lt;/p&gt;
&lt;p&gt;卡尔曼最小均方差推导
卡尔曼滤波就是递推最小二乘法的一种特殊情况，卡尔曼滤波也是去通过最小化方差来求得最优的估计值。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/ethan_guo/article/details/80568254"&gt;最大似然估计,最小二乘估计,卡尔曼滤波,三者的相互关系&lt;/a&gt;
&lt;a href="https://blog.csdn.net/qinruiyan/article/details/50793114"&gt;SLAM学习笔记2：Kalman Filter(卡尔曼滤波) 与Least Square(最小二乘法) 的比较&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>Hessian</title><link href="/hessian.html" rel="alternate"></link><updated>2019-01-27T15:13:19+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-27:hessian.html</id><summary type="html">&lt;h1&gt;Hessian&lt;/h1&gt;
&lt;h1&gt;Hessian positive semidefinite&lt;/h1&gt;
&lt;h1&gt;Hessian ill conditioned, eigen value&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;convergence rate&lt;/li&gt;
&lt;li&gt;numeric statibility&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;https://www.zhihu.com/question/56977045
这里有一个知乎问答 &lt;a href="https://www.zhihu.com/question/24623031"&gt;Hessian 矩阵的特征值有什么含义&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Hessian approximation&lt;/h1&gt;
&lt;p&gt;高斯牛顿&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>Quadratic forms</title><link href="/quadratic-forms.html" rel="alternate"></link><updated>2019-01-27T13:47:50+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-27:quadratic-forms.html</id><summary type="html">&lt;p&gt;最近在凸优化&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;一书中，steepest descent相关章节看到quadratic norm(9.4)，
gradient descent与steepest descent的却别就在于不同范数(norm)的选取&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$\Delta_{nsd}=argmin_v(\nabla f(x)^Tv\mid \|v\|&amp;lt;=1)$$&lt;/div&gt;
i.e.  , as the direction in the unit ball of ‖·‖ that extends farthest in the
direction &lt;span class="math"&gt;\(-\nabla f(x)\)&lt;/span&gt;&lt;br /&gt;
Steepest descent for quadratic norm&lt;br /&gt;
We consider the quadratic norm
&lt;div class="math"&gt;$$\Vert z \Vert_{P} = (z^T P z)^{1/2} = \Vert P^{1/2}z\Vert_{2}$$&lt;/div&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不太清楚它的形式，找到如下资料&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="images/quadratic_forms_1.png" alt="quadratic forms" title="" style="max-width:80%; max-height:80%"/&gt;
&lt;img src="images/quadratic_forms_2.png" alt="quadratic forms" title="" style="max-width:80%; max-height:80%"/&gt;
&lt;img src="images/quadratic_forms_3.png" alt="quadratic forms" title="" style="max-width:80%; max-height:80%"/&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;http://stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;https://see.stanford.edu/materials/lsoeldsee263/15-symm.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/Timingspace/article/details/5096356://blog.csdn.net/Timingspace/article/details/50963564"&gt;梯度下降法和最速下降法的细微差别&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>Geometric Operations</title><link href="/geometric-operations.html" rel="alternate"></link><updated>2019-01-26T17:49:37+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-26:geometric-operations.html</id><summary type="html">&lt;h1&gt;Translation&lt;/h1&gt;
&lt;h1&gt;Rotation&lt;/h1&gt;
&lt;h1&gt;Affine transformation&lt;/h1&gt;
&lt;p&gt;线性变换+平移, 6 DOF&lt;/p&gt;
&lt;h1&gt;Rigid transformation (Euclidean transform, SE(3))&lt;/h1&gt;
&lt;p&gt;Any Euclidean transformation is an affine transformation. But not the other way
around, for example, Reflections, Shear transformation.&lt;/p&gt;
&lt;p&gt;6 Degrees Of Freedom
Transformation matrix = rotation + translation.&lt;/p&gt;
&lt;h1&gt;仿射函数与线性函数区别&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;A linear function fixes the origin, whereas an affine function need not do so.
An affine function is the composition of a linear function with a translation,
so while the linear part fixes the origin, the translation can map it
somewhere else.&lt;/p&gt;
&lt;p&gt;Linear functions between vector spaces preserve the vector space structure
(so in particular they must fix the origin). While affine functions don't
preserve the origin, they do preserve some of the other geometry of the
space, such as the collection of straight lines.&lt;/p&gt;
&lt;p&gt;If you choose bases for vector spaces V
and W of dimensions m and n respectively, and consider functions f:V→W, then
f is linear if f(v)=Av for some n×m matrix A and f is affine if f(v)=Av+b
for some matrix A and vector b, where coordinate representations are used
with respect to the bases chosen.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="Math"></category></entry><entry><title>Leventberg-Marquardt Algorithm</title><link href="/leventberg-marquardt-algorithm.html" rel="alternate"></link><updated>2019-01-25T12:31:55+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-25:leventberg-marquardt-algorithm.html</id><summary type="html">&lt;p&gt;最近想弄懂LM算法，看了一些介绍。 虽然不重要，但是对于它到底是使用line search和trust region算法感到困惑。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Levenberg (1944) and later Marquardt (1963) suggested to use a
damped Gauss-Newton method, cf Section 2.4.  The step &lt;span class="math"&gt;\(h_{lm}\)&lt;/span&gt; is defined by the
following modification to (3.9),&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;
&lt;div class="math"&gt;$$(J^TJ + \lambda I)h_{lm} = -g \;with\; g = J^Tf \;and\; \lambda \geqslant 0$$&lt;/div&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以，最初LM算法的提出是以一种damped Gauss-Newton的方式， 而没有使用trust
region的概念。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The above algorithm has the disadv antage that if the value of &lt;span class="math"&gt;\(lambda\)&lt;/span&gt; is large,
the calculated Hessian matrix is not used at all.  We can deri ve some advantage
out of the second deri vative even in such cases by scaling each component of
the gradient according to the curv ature.  This should result in lar ger movement
along the directions where the gradient is smaller so that the classic
“error valley” problem does not occur any more.  This crucial insight was
provided by Marquardt.  He replaced the identity matrix in (7) with the diagonal
of the Hessian resulting in the Levenberg-Marquardt update rule.  &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;
&lt;div class="math"&gt;$$(H + \lambda diag[H])h_{lm} = -g \;with\; g = J^Tf \;and\; \lambda \geqslant 0$$&lt;/div&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;同时它是一个基于经验(heuristic)的算法, 是从gradient
descent和Gauss-Newton算法总观察改进而来。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gradient descent一阶算法简单, 快速，但是有各种收敛问题,
  确定的方向，但是更新步长没有根据梯度变化而调整。&lt;/li&gt;
&lt;li&gt;同时牛顿法为二阶，使用second derivative。从几何上说，牛顿法就是用一个二次曲面
去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，
通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的
最优下降路径。由于精确的Hessian矩阵求解计算量大，可以使用: &lt;span class="math"&gt;\(H \approx J^TJ\)&lt;/span&gt;
近似Hessian矩阵，这就是Gauss-Newton算法。但是高斯牛顿算法有一个问题在于，对于初始点比较敏感。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结合二者的优缺点，提出的LM算法，根据&lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;的值相对大小，
LM算法体现出梯度下降或者高斯牛顿算法的特征，同时根据误差计算，调整damping factor
&lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;大小。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;但是，这个经验公式在实际问题中，却非常有效。因为它跟基于trust region的高斯牛顿
法得到的迭代公式完全一样。所以有了优化的理论根据！&lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;LM算法基本流程&lt;/h1&gt;
&lt;h1&gt;基于信赖域的Gauss-Newton法推导&lt;/h1&gt;
&lt;h2&gt;non-linear least squares problem&lt;/h2&gt;
&lt;p&gt;总是把对不同函数的求导弄混，这里重写写一遍，加深理解。
&lt;/p&gt;
&lt;div class="math"&gt;$$\newcommand{\xv}{\mathbf{x}}
\xv^{*} = argmin_{\xv}\{F(\xv)\}$$&lt;/div&gt;
&lt;p&gt;
where
&lt;/p&gt;
&lt;div class="math"&gt;$$\newcommand{\xv}{\mathbf{x}} \newcommand{\fv}{\mathbf{f}}
F(\xv)=\frac{1}{2}\sum_{i=1}^{m}(f_{i}(x))^2\;=\;
\frac{1}{2}\Vert \fv(\xv) \Vert^2\;=\;
\frac{1}{2}\fv(\xv)^{T}\fv(\xv)$$&lt;/div&gt;
&lt;p&gt;根据泰勒展开：
&lt;/p&gt;
&lt;div class="math"&gt;$$\newcommand{\xv}{\mathbf{x}} \newcommand{\hv}{\mathbf{h}}
\newcommand{\fv}{\mathbf{f}}
\fv(\xv+\hv) \;=\; \fv(\xv) + \mathbf{J}(\xv)\hv + O(\Vert \hv \Vert )^2 $$&lt;/div&gt;
&lt;p&gt;
这里&lt;span class="math"&gt;\(\mathbf{J}\)&lt;/span&gt;为&lt;span class="math"&gt;\(\mathbf{f}(\mathbf{x})\)&lt;/span&gt;的Jacobian矩阵(不是&lt;span class="math"&gt;\(F(\mathbf{x})\)&lt;/span&gt;)。
&lt;/p&gt;
&lt;div class="math"&gt;$$\newcommand{\xv}{\mathbf{x}} \newcommand{\fv}{\mathbf{f}}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
\pdiff{F}{x_j}(\xv) \;=\; \sum_{i=1}^{m}f_{i}(\xv)\pdiff{f_i}{x_j}(\xv) \\
F^{'}(\xv) \;=\; J(\xv)^{T}\fv(\xv)$$&lt;/div&gt;
&lt;p&gt;对&lt;span class="math"&gt;\(\mathbf{f}\)&lt;/span&gt;泰勒展开
&lt;/p&gt;
&lt;div class="math"&gt;$$\newcommand{\xv}{\mathbf{x}} \newcommand{\hv}{\mathbf{h}}
\newcommand{\fv}{\mathbf{f}} \newcommand{\jv}{\mathbf{J}}
\fv(\xv + \hv) \;=\; \ell(\hv) \approx \fv(\xv) + \mathbf{J}(\xv)\hv \\
F(\xv+\hv) \;=\; L(\hv) \;=\; \frac{1}{2}\ell(\hv)^{T}\ell(\hv) \\
=\; \frac{1}{2}{\fv}^T\fv + {\hv}^T\jv\fv + \frac{1}{2}{\hv}^T{\jv}^T\hv \\
=\; F(\xv) + {\hv}^T{\jv}^T\fv + \frac{1}{2}\hv^T{\jv}^T\jv\hv
=\; F(\xv) + {\fv}^T{\jv}\hv + \frac{1}{2}\hv^T{\jv}^T\jv\hv
$$&lt;/div&gt;
&lt;p&gt;
&lt;span class="math"&gt;\(L\)&lt;/span&gt;的gradient与Hessian为:
&lt;/p&gt;
&lt;div class="math"&gt;$$\newcommand{\xv}{\mathbf{x}} \newcommand{\hv}{\mathbf{h}}
\newcommand{\fv}{\mathbf{f}} \newcommand{\jv}{\mathbf{J}}
L^{'} \;=\; \jv^T\fv + \jv^T\jv\hv, ;\ L^{''} \;=\; \jv^T\jv$$&lt;/div&gt;
&lt;p&gt;
对于高斯牛顿法，求&lt;span class="math"&gt;\(\mathbf{h}_{gn}\)&lt;/span&gt;使得&lt;span class="math"&gt;\(L(\mathbf{h})\)&lt;/span&gt;最小：
&lt;/p&gt;
&lt;div class="math"&gt;$$\newcommand{\hv}{\mathbf{h}}
\newcommand{\jv}{\mathbf{J}}
\newcommand{\fv}{\mathbf{f}}
\hv_{gn} \;=\; argmin_{\hv}{L(\hv)} \\
L^{'}(\hv) \;=\; 0 \\
({\jv}^T\jv)\hv_{gn} \;=\; -{\jv}^T\fv
$$&lt;/div&gt;
&lt;h2&gt;基于信赖域的Gauss-Newton法推导&lt;/h2&gt;
&lt;div class="math"&gt;$$L({\Delta x_k}) = F(x_k + \Delta x_k) \approx f(x_k) + J_{x_k}{\Delta x_k} + \frac{1}{2}{\Delta x_k}H_{x_k}{\Delta x_k}$$&lt;/div&gt;
&lt;p&gt;
求解子问题：
&lt;/p&gt;
&lt;div class="math"&gt;$$argmin_{\Delta x_k} L({\Delta x_k}), \; s.t. \Vert D\Delta x_k \Vert^2 \leq \mu \; (1)$$&lt;/div&gt;
&lt;p&gt;
信赖域法的核心问题是一个不等式约束问题，可以通过Lagrange将它转换成一个无约束问题。
&lt;/p&gt;
&lt;div class="math"&gt;$$argmin_{\Delta x_k} L({\Delta x_k}) \;+\; \frac{\lambda}{2}\Vert D\Delta x_k \Vert^2\; (2)$$&lt;/div&gt;
&lt;p&gt;
&lt;span class="math"&gt;\(\lambda\)&lt;/span&gt;为Lagrange乘子。展开得：
&lt;/p&gt;
&lt;div class="math"&gt;$$(H + \lambda D^TD)\Delta x_k \;=\; -g \;with\; g = J^Tf$$&lt;/div&gt;
&lt;p&gt;
当去D为单位矩阵I时，得到的更新求解公式与之前的经验公式一样。
&lt;a href="http://pages.mtu.edu/~msgocken/ma5630spring2003/lectures/tr/tr/node2.html"&gt;The trust region subproblem&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;注意点&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(lambda\)&lt;/span&gt;取值要使得&lt;span class="math"&gt;\((\mathbf{J}^T\mathbf{J} + \lambda I)\)&lt;/span&gt;为正定矩阵positive
definit, 这样&lt;span class="math"&gt;\(\Delta x_k\)&lt;/span&gt;才是&lt;span class="math"&gt;\(L\)&lt;/span&gt;的minimizer.&lt;/li&gt;
&lt;li&gt;关于D的选取，有的选取为单位矩阵，有的选取为Hessian矩阵对角元素&lt;/li&gt;
&lt;li&gt;$(H + \lambda diag H) 的condition number可能会很大&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;。或者因为精度问题，导致H对
角线上元素为0. 对这个表达式进行矩阵分解求解方程的时候，需要注意算法的stability.
(可能考虑使用QR decomposition&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里有个一LM的算法实现，注意上面提到的两点
https://gist.github.com/lirenlin/ce6159058348efa1a9f7c8d621c1e768&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="orbit.dtu.dk/files/2721358/imm3215.pdf"&gt;methods for non-linear least squares problems&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;&lt;a href="http://ananth.in/docs/lmtut.pdf"&gt;The Levenberg-Marquardt Algorithm &lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;https://sites.math.washington.edu/~reu/papers/2009/mark/REU%20Final%20Paper.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;https://mathoverflow.net/questions/106277/levenberg-marquadt-near-the-minima-for-non-zero-residual-problems://mathoverflow.net/questions/106277/levenberg-marquadt-near-the-minima-for-non-zero-residual-problems/ &amp;#160;&lt;a class="footnote-backref" href="#fnref:4" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>floating point</title><link href="/floating-point.html" rel="alternate"></link><updated>2019-01-23T17:16:15+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-23:floating-point.html</id><summary type="html">&lt;h1&gt;Floating point&lt;/h1&gt;
&lt;p&gt;In computing, floating-point arithmetic (FP) is arithmetic using formulaic
representation of real numbers as an approximation so as to support a trade-off
between range and precision. For this reason, floating-point computation is
often found in systems which include very small and very large real numbers,
which require fast processing times. A number is, in general, represented
approximately to a fixed number of significant digits (the significand)
and scaled using an exponent in some fixed base; the base for the scaling
is normally two, ten, or sixteen. A number that can be represented exactly
is of the following form:
&lt;/p&gt;
&lt;div class="math"&gt;$$significand \times base^{exponent}$$&lt;/div&gt;
&lt;p&gt;The term floating point refers to the fact that a number's radix point (decimal
point, or, more commonly in computers, binary point) can "float"; that is, it
can be placed anywhere relative to the significant digits of the number. This
position is indicated as the exponent component, and thus the floating-point
representation can be thought of as a kind of scientific notation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;IEEE 16-bit binary float&lt;br /&gt;
1 sign bit: s&lt;br /&gt;
5 bit for exponent: u.
11 bits for significand: m, (one bit is implicit, 10 bits are explicitly stored.)
bias: 15&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IEEE 32-bit binary float&lt;br /&gt;
1 sign bit: s&lt;br /&gt;
8 bit for exponent: u&lt;br /&gt;
24 bits for significand: m, (one bit is implicit, 23 bits are explicitly
                 stored.)
bias: 127&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IEEE 64-bit binary float&lt;br /&gt;
1 sign bit: s&lt;br /&gt;
11 for exponent: u&lt;br /&gt;
53 bits for significand: m, (one bit is implicit, 52 bit are explicitly stored)
bias: 1023  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IEEE 128-bit binary float&lt;br /&gt;
1 sign bit: s&lt;br /&gt;
15 for exponent: u&lt;br /&gt;
113 bits for significand: m, (one bit is implicit, 112 bit are explicitly stored)
bias: 16383  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some combinations of exponent and significant pattern are preserved for
specially number, e.g. 0, infinity, NaN.
&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*}
e &amp;amp;= u - bias\\
significant &amp;amp;= 1(implicit) + m_1*2^{-1} + m_2*2^{-2} + ... m_m2^{-m}\\
val &amp;amp;= significant * 2 ^ {e}\\
\end{align*}&lt;/div&gt;
&lt;p&gt;For example, for number 216:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;float32_mem&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;216&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;float32_mem&lt;/span&gt;
&lt;span class="mi"&gt;1129840640&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;float32_mem&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s1"&gt;&amp;#39;0b1000011010110000000000000000000&amp;#39;&lt;/span&gt;
&lt;span class="c1"&gt;#sign bit(31-bit): 0  &lt;/span&gt;
&lt;span class="c1"&gt;#exponent bit pattern(30-23bit): 0b10000110 (134)&lt;/span&gt;
&lt;span class="c1"&gt;#significand bit pattern(22-0bit): 0b10110000000000000000000&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mb"&gt;0b10000110&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;127&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
&lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**-&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt;
&lt;span class="mf"&gt;1.6875&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;
&lt;span class="mf"&gt;216.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Another example with rounding error:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;float32_mem&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16777216&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;float32_mem&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s1"&gt;&amp;#39;0b1001011100000000000000000000000&amp;#39;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mb"&gt;0b10010111&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;127&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;
&lt;span class="mf"&gt;16777216.0&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;float32_mem&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16777217&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;float32_mem&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="s1"&gt;&amp;#39;0b1001011100000000000000000000000&amp;#39;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mb"&gt;0b10010111&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;127&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;
&lt;span class="mf"&gt;16777216.0&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**-&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;significant&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;
&lt;span class="mf"&gt;16777218.0&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;
&lt;span class="mi"&gt;24&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;ULP, unit in th last place&lt;/h1&gt;
&lt;p&gt;given a normalized representation in float point
&lt;/p&gt;
&lt;div class="math"&gt;$$d_1.d_2...d_p \times \beta^e$$&lt;/div&gt;
&lt;p&gt;
&lt;span class="math"&gt;\(d_1\)&lt;/span&gt; is not zero. the ULP value is defined as:
&lt;/p&gt;
&lt;div class="math"&gt;$$ulp(e, p) \to \beta^{e-(p-1)}$$&lt;/div&gt;
&lt;p&gt;
For example:
&lt;/p&gt;
&lt;div class="math"&gt;$$1.625 * 10^{-4}; \; \beta=10, e = -4, p = 4$$&lt;/div&gt;
&lt;div class="math"&gt;$$ulp(10, 3) = 1 * 10^{-(p-1)} * 10^e = 10^{e-(p-1)} = 10^{-7}$$&lt;/div&gt;
&lt;p&gt;In general, if the floating-point number &lt;span class="math"&gt;\(d.d...d ×\beta^{e}\)&lt;/span&gt; is used to represent z,
then it is in error by &lt;span class="math"&gt;\(|d.d...d - (z/\beta^{e})|\beta^{p-1}\)&lt;/span&gt; units in the last place&lt;/p&gt;
&lt;h1&gt;&lt;a href="https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html"&gt;What Every Computer Scientist Should Know About Floating-Point Arithmetic&lt;/a&gt;&lt;/h1&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Programming"></category></entry><entry><title>Numerical stability</title><link href="/numerical-stability.html" rel="alternate"></link><updated>2019-01-23T14:27:51+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-23:numerical-stability.html</id><summary type="html">&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Numerical_stability"&gt;Wiki: numerical stability&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html"&gt;What Every Computer Scientist Should Know About Floating-Point Arithmetic&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>cholesky decomposition</title><link href="/cholesky-decomposition.html" rel="alternate"></link><updated>2019-01-22T16:48:47+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-22:cholesky-decomposition.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Linear least squares, the solution is to solve this system of linear
equations: &lt;span class="math"&gt;\(A^TAx = TX = A^Tb\)&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Non-linear least squares problem via iterative method&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gauss-Newton Method, solve &lt;span class="math"&gt;\((J_x^T J_x)\Delta = T\Delta = -J_x^Tf(x)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Levenberg-Marquardt Algorithm, solve &lt;span class="math"&gt;\((J_x^T J_x + \lambda D)\Delta = T\delta = -J_x^Tf(x)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在上面所有的T都是symmetric矩阵，可以使用Cholesky decomposition来解决。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少计算量, 即使有额外的中间步骤需要计算&lt;/li&gt;
&lt;li&gt;the amount of fill-in which occours when computing a matrix decomposition of a sparse matrix&lt;/li&gt;
&lt;li&gt;stable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cholesky decomposition &lt;span class="math"&gt;\(A = LL^T\)&lt;/span&gt;. This is stable even without
pivoting, and hence extremely simple to implement.
It is the standard decomposition method for almost all unconstrained optimization
problems including bundle adjustment, as the Hessian is positive definite near
a non-degenerate cost minimum (and in the Gauss-Newton approximation, almost
everywhere else, too). If A is symmetric but only positive semidefinite,
diagonally pivoted Cholesky decomposition can be used.&lt;/p&gt;
&lt;p&gt;Another notable method is that based on QR decomposition, which is up to a
factor of two slower than the normal equations, but much less sensitive to
ill-conditioning in J.&lt;/p&gt;
&lt;p&gt;The triangular factor L and a solution to a corresponding linear system may not
be accurate enough because of machine arithmetic. In order to refine the
solution, a number of iterative methods (for example, the conjugate
 gradient method) can be employed using the &lt;span class="math"&gt;\(LL^T\)&lt;/span&gt; decomposition as a
preconditioner.  The memory saving is the main reason to use an incomplete or
inaccurate decomposition as a preconditioner.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;https://algowiki-project.org/en/Cholesky_method&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>ill-conditioned Matrices</title><link href="/ill-conditioned-matrices.html" rel="alternate"></link><updated>2019-01-21T14:50:04+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-21:ill-conditioned-matrices.html</id><summary type="html">&lt;h1&gt;What is an ill-conditioned matrix?&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h1&gt;
&lt;p&gt;A matrix can represent a mapping from one space to another space. The
conditioning number of a matrix gives us the ratio of how crazy this mapping
can be. The conditioning number is the ratio of the largest singular value to
the smallest singular value.&lt;/p&gt;
&lt;p&gt;A matrix is ill-conditioned if the conditioning number is very high. What this
means is that calculations using this matrix are prone to introduce numerical
errors that can overwhelm your calculation. Computers cannot hold an infinite
amount of information. Numbers in a floating point representation can only hold
so much precision.&lt;/p&gt;
&lt;p&gt;For example if 𝐴 is ill-conditioned and I try to solve 𝐴𝑥=𝑏
using Gauss-Jordan elimination I will quickly pick up numerical errors, and
then those numerical errors are used on the next step which creates even larger
errors, which are used on the next step and so on.&lt;/p&gt;
&lt;p&gt;So what do you do when you have an ill-conditioned matrix? You reformulate
your problem by doing something called preconditioning. This allows you to work
in a space where your transformations aren’t as badly behaved and errors can be
kept under control.&lt;/p&gt;
&lt;h1&gt;Poorly conditioned Hessian matrix&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/h1&gt;
&lt;p&gt;Condition number of a matrix is the ratio of the largest singular value to the
smallest singular value. A matrix is ill-conditioned if the condition number is
very high, usually indicating that (i) the lowest singular value is orders of
magnitude smaller than the highest one, and (ii) columns/rows of the matrix are
heavily correlated with each other leading to redundancies and a matrix that is
pretending to be of a higher rank than it truly is.&lt;/p&gt;
&lt;p&gt;Hessian encodes the second derivatives of a function with respect to all pairs
of variables. So, if there are n inputs to a function, the gradient is 𝑛
-dimensional and the Hessian is 𝑛x𝑛-dimensional. In machine learning, the inputs
are usually the features and the function is usually a loss function we are
trying to minimize. When the Hessian is ill-conditioned, it means the basins of
the loss function have contours that are very long “ellipsoids” rather than being close to “circular”.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/ic-1.gif" alt="01" title="01" style="max-width:80%;max-height:80%"/&gt;&lt;/p&gt;
&lt;p&gt;This causes problems for first-order optimization methods like gradient descent
(𝑤=𝑤−𝜂∇𝑤) which need to follow a very zigzag path to the minimum. The first
figure below shows the gradient directions at various points on a straight line
through the parameter space. Notice how the directions away from the center are
nearly orthogonal to the useful direction of descent. The second figure shows
the zigzag path gradient descent has to take if the Hessian is ill-conditioned,
the function contours are stretched out, and the gradients often point to directions
that might not be the best way to descend to the minimum.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/ic-2.png" alt="02" title="02" style="max-width:80%;max-height:80%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="images/ic-3.png" alt="03" title="03" style="max-width:80%;max-height:80%"/&gt;&lt;/p&gt;
&lt;p&gt;You would think that second-order optimization would solve this problem. It sort
of does if the Hessian is not too ill-conditioned. However, a poorly conditioned
Hessian is problematic because a typical second-order optimization requires
inversion of a Hessian: 𝑤=𝑤−𝜂𝐻−1∇𝑤 (First-order optimization methods therefore
assume 𝐻=𝐼, the identity matrix i.e. the problem is ideally conditioned for
gradient descent-like methods.) Inverse of 𝐻with SVD decomposition 𝐻=𝑈Σ𝑉𝑇 is
given as 𝐻−1=𝑈Σ−1𝑉𝑇. Here Σ is a diagonal matrix with singular values on the
diagonal. Note, if the Hessian is ill-conditioned, the inverse can be numerically
unstable since the smallest singular values blow up on inversion. A singular
value of 10−6 appears as 106 in Σ−1. Thus, the more ill-conditioned the Hessian
is, the more numerically unstable its inverse. Any noise in computing the Hessian
such as that introduced by using stochastic versions of descent updates or using
minibatches amplifies tremendously when the Hessian is inverted. Methods likes
L-BFGS get around this by maintaining a low-rank approximation of the (inverse)
Hessian which is better suited for ill-conditioned problems as well as saves
computation and space required to implement second-order optimization.&lt;/p&gt;
&lt;p&gt;这里有一个知乎问答 &lt;a href="https://www.zhihu.com/question/24623031"&gt;Hessian 矩阵的特征值有什么含义&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个答案给出了一些有背景的回答：https://www.zhihu.com/question/24623031/answer/118562562
steepest descent里面，可以使用Hessian范数，来求更新步长方向，也就是牛顿法。Hessian特征值差异大，所定义的空间椭圆空间长轴短轴比例越失调，相反，如果是一个球星空间，则各个方向一致, 这个时候收敛更快。&lt;/p&gt;
&lt;h1&gt;&lt;a href="https://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/04LinearAlgebra/illconditioned/"&gt;uwaterloo: Numerical Analysis: ill conditioned matrices&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Numerical_stability"&gt;Wiki: numerical stability&lt;/a&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;https://www.quora.com/What-is-an-ill-conditioned-matrix&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;https://www.quora.com/What-does-it-mean-to-have-a-poorly-conditioned-Hessian-matrix&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="Math"></category></entry><entry><title>一阶二阶优化方法</title><link href="/yi-jie-er-jie-you-hua-fang-fa.html" rel="alternate"></link><updated>2019-01-21T11:15:42+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-21:yi-jie-er-jie-you-hua-fang-fa.html</id><summary type="html">&lt;p&gt;1, 计算量, Hessian矩阵
2, 收敛迭代次数, 更少的迭代次数，但是每次计算量更大
3, 问题数值精度
4, 数值稳定性, 算法更复杂&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>ill-conditioned problem</title><link href="/ill-conditioned-problem.html" rel="alternate"></link><updated>2019-01-18T15:09:54+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-18:ill-conditioned-problem.html</id><summary type="html">&lt;p&gt;在SLAM，BA中，经常提到ill conditioned problems，需要转换矩阵形式，提供reliable,
robust and efficient的系统结果。而这些在系统行为又在相关应用中尤为重要，
所以需要细心的学习。&lt;/p&gt;
&lt;p&gt;文章中建议到:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;unless you are familiar with these issues, it is advisable to use profession-
ally designed methods
但是至少我们要知道这个事情的存在，与相关考虑的必要性。&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="Math"></category></entry><entry><title>约束优化</title><link href="/yue-shu-you-hua.html" rel="alternate"></link><updated>2019-01-16T12:19:15+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-16:yue-shu-you-hua.html</id><summary type="html">&lt;p&gt;&lt;a href="https://blog.csdn.net/touristman5/article/details/57418552"&gt;等式约束，不等式约束问题&lt;/a&gt;
&lt;a href="https://en.wikipedia.org/wiki/Constrained_optimization"&gt;wiki: constrained optimization&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>Lattice</title><link href="/lattice.html" rel="alternate"></link><updated>2019-01-16T12:08:46+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-16:lattice.html</id><summary type="html">&lt;p&gt;&lt;a href="/pdfs/E-DFA-using-lattices-small.pdf"&gt;DFA using lattices&lt;/a&gt;
&lt;a href="/pdfs/static2.pdf"&gt;Lattice Theory Control Flow Graphs Control Flow Graphs Dataflow Analysis Dataflow Analysis&lt;/a&gt;&lt;/p&gt;</summary><category term="Compile"></category></entry><entry><title>范数Norm</title><link href="/fan-shu-norm.html" rel="alternate"></link><updated>2019-01-15T15:47:30+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-15:fan-shu-norm.html</id><summary type="html">&lt;h1&gt;向量范数(norm)&lt;/h1&gt;
&lt;p&gt;From wiki:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In linear algebra, functional analysis, and related areas of mathematics,
a norm is a function that assigns a strictly positive length or size to
each vector in a vector space—except for the zero vector, which is
assigned a length of zero.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;矩阵范数&lt;/h1&gt;
&lt;p&gt;From wiki:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In mathematics, a matrix norm is a vector norm in a vector space whose elements
(vectors) are matrices (of given dimensions).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以从函数、几何与矩阵的角度去理解范数。&lt;/p&gt;
&lt;p&gt;我们都知道，函数与几何图形往往是有对应关系的，这个很好想象，特别是在三维以下的空间内，函数是几何图像的数学概括，而几何图像是函数的高度形象化，比如一个函数对应几何空间上若干点组成的图形。
但当函数与几何超出三维空间时，就难以获得较好的想象，于是就有了映射的概念，映射表达的就是一个集合通过某种关系转为另外一个集合。通常数学书是先说映射，然后再讨论函数，这是因为函数是映射的一个特例。
为了更好的在数学上表达这种映射关系，（这里特指线性关系）于是就引进了矩阵。这里的矩阵就是表征上述空间映射的线性关系。而通过向量来表示上述映射中所说的这个集合，而我们通常所说的基，就是这个集合的最一般关系。于是，我们可以这样理解，一个集合（向量），通过一种映射关系（矩阵），得到另外一个集合（另外一个向量）。
那么向量的范数表示这个原有集合的大小。
矩阵的范数表示这个变化过程的大小的一个度量。
简单说：0范数表示向量中非零元素的个数（即为其稀疏度）。1范数表示为，绝对值之和。而2范数则指模。&lt;/p&gt;
&lt;p&gt;具体向量范数与矩阵范数参见
&lt;a href="https://www.zhihu.com/question/20473040"&gt;知乎：0 范数、1 范数、2 范数有什么区别？&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://mathworld.wolfram.com/VectorNorm.html"&gt;mathworld: Vector Norm&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>简单BA代码分析</title><link href="/jian-dan-badai-ma-fen-xi.html" rel="alternate"></link><updated>2019-01-15T08:36:12+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-15:jian-dan-badai-ma-fen-xi.html</id><summary type="html">&lt;p&gt;简单代码分析，帮助自己从概念到代码的理解。代码使用Eigen, ceres solver第三方软件库。&lt;/p&gt;
&lt;h1&gt;问题假设&lt;/h1&gt;
&lt;p&gt;输入：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(P^{c}_{ij}\)&lt;/span&gt;: 路标(point)j在i相机位姿下，在相机坐标下的观测坐标&lt;span class="math"&gt;\([Px^{c} Py^{c}]^T\)&lt;/span&gt;(观测数据)&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(T_{i} = [rotation matrix, translation]\in \mathbb {R}^{6}\)&lt;/span&gt; 或者&lt;span class="math"&gt;\(T = [Quaternion, translation] \in \mathbb {R}^{7}\)&lt;/span&gt; 相机位姿(pose)初始估计 (前端计算数据)&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(P^{w}_{j} = [Px^{w} Py^{w} Pz^{w}]\)&lt;/span&gt;路标(point)在世界坐标系下的初始估计值(前端计算数据)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;输出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;经过调整后相机的位姿(pose)&lt;/li&gt;
&lt;li&gt;与调整后的路标在世界坐标系下的坐标。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;$$ \overline {P^{c}_{ij}} = h(T_{i}, P^{w}_{ij})$$&lt;/div&gt;
&lt;p&gt;
给定相机位姿，路标世界坐标，计算投影坐标&lt;span class="math"&gt;\(h : SE(3) × \mathbb {R}^{3} \to \mathbb {R}^{2}\)&lt;/span&gt;
因为投影为平面，所以只有二维，世界坐标维三维。&lt;/p&gt;
&lt;p&gt;cost function, reprojection error:
&lt;/p&gt;
&lt;div class="math"&gt;$$ e = \sum_{i} {\sum_{j} {\Vert(h(T_{i}, P^{w}_{ij}) - P^{c}_{ij})\Vert^2}}$$&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(h\)&lt;/span&gt;这里可以分为两步
&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*}
P^{w'} &amp;amp;= f(T, P^{w}) = TP^{w} = RP^{w} + t: \mathbb {R}^3 \to \mathbb {R}^3 \\
\overline {P^{c}} &amp;amp;= g(P^{w'}) = [\frac {Px^{w'}}{Pz^{w'}} \frac{Py^{w'}}{Pz^{w'}}]^T: \mathbb {R}^3 \to \mathbb {R}^2 \\
\overline {P^{c}} &amp;amp;= g(f(T, P^{w}))
\end{align*}&lt;/div&gt;
&lt;p&gt;非线性最小二乘优化，迭代方法，需要求得对于优化标量偏导Jacobian矩阵,
  以及迭代更新计算。这里，优化的变量为位姿&lt;span class="math"&gt;\(T \in \mathbb {R}^6\)&lt;/span&gt;与&lt;span class="math"&gt;\(P^{w} \in
  \mathbb {R}^3\)&lt;/span&gt;&lt;/p&gt;
&lt;h1&gt;cost function Jabian矩阵推导&lt;/h1&gt;
&lt;p&gt;根据求导chain rule:
&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
1)\; \pdiff{h}{P^{w}} &amp;amp;= \pdiff{g(P^{w'})}{f}\pdiff{f}{P^{w}}\\
2)\; \pdiff{h}{T} &amp;amp;= \pdiff{g(P^{w'})}{f}\pdiff{f}{T}\\
\end{align*}&lt;/div&gt;
&lt;div class="math"&gt;\begin{gather*}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
\pdiff{g(P^{w'})}{f} &amp;amp;= 
\left[
  \begin{array}{ccc}
  \frac {1}{Pz^{w'}} &amp;amp; 0 &amp;amp; \frac {Px^{w'}}{(Pz^{w'})^2} \\
  0 &amp;amp; \frac {1}{Pz^{w'}} &amp;amp; \frac {Py^{w'}}{(Pz^{w'})^2} \\
  \end{array}
\right] = \frac {1}{Pz^{w'}}
\left[
  \begin{array}{ccc}
  1 &amp;amp; 0 &amp;amp; \frac {Px^{w'}}{Pz^{w'}} \\
  0 &amp;amp; 1 &amp;amp; \frac {Py^{w'}}{Pz^{w'}} \\
  \end{array}
\right]
\end{gather*}&lt;/div&gt;
&lt;p&gt;这里2)的导数在SE(3)空间无法计算，因为没有定义的加法，因此使用lie group与lie
algebra计算。
&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
\pdiff{f}{T} \to \pdiff{TP}{\delta\xi}
&amp;amp;= \lim_{\delta\xi \to 0}{\frac {exp(\delta\xi^{\wedge})exp(\xi^{\wedge})P -exp(\xi^{\wedge})P}{\delta\xi}} \\
&amp;amp;\approx \lim_{\delta\xi \to 0}{\frac {(I + \delta\xi^{\wedge})exp(\xi^{\wedge})P -exp(\xi^{\wedge})P}{\delta\xi}} \\
&amp;amp;= \lim_{\delta\xi \to 0}{\frac {\delta\xi^{\wedge}exp(\xi^{\wedge})P}{\delta\xi}} \\
&amp;amp;= \lim_{\delta\xi \to 0}{\frac
      {\left [\begin{array}{cc} \delta\varphi^{\wedge} &amp;amp; \delta\rho \\ 0^T &amp;amp; 0 \\ \end{array} \right] \left[ \begin{array}{c} RP + t \\ 1 \end{array} \right]}
      {\delta\xi}} \\
&amp;amp;= \lim_{\delta\xi \to 0}{\frac
      {\left[ \begin{array}{c} \delta\varphi^{\wedge}(RP + t) + \delta\rho \\ 0 \end{array} \right]}
      {\delta\xi}}
\end{align*}&lt;/div&gt;
&lt;p&gt;T对应的李代数为&lt;span class="math"&gt;\(\delta\xi = [\delta\varphi \; \delta\rho]^T\)&lt;/span&gt;, 对他们按顺序求导得到
&lt;/p&gt;
&lt;div class="math"&gt;\begin{align*}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
\pdiff{f}{T} \to \pdiff{TP}{\delta\xi}
&amp;amp;= \lim_{\delta\xi \to 0}{\frac
      {\left[ \begin{array}{c} \delta\varphi^{\wedge}P^{w'} + \delta\rho \\ 0 \end{array} \right]}
      {\delta\xi}} \\
&amp;amp;= \lim_{\delta\xi \to 0}{\frac
      {\left[ \begin{array}{c} -{P^{w'}}^{\wedge}\delta\varphi + \delta\rho \\ 0 \end{array} \right]}
      {\delta\xi}} \\
&amp;amp;= \left[ \begin{array}{cc} -{P^{w'}}^{\wedge} &amp;amp; I \\ 0^T &amp;amp; 0^T \end{array} \right]
\end{align*}&lt;/div&gt;
&lt;p&gt;推导过程与这里想吻合，具体计算可以参考这里代码.&lt;/p&gt;
&lt;p&gt;&lt;a href="/pdfs/Visual_SLAM_Tutorial_Bundle_Adjustment.pdf"&gt;Visual SLAM Tutorial: Bundle Adjustment&lt;/a&gt;&lt;br /&gt;
&lt;a href="https://github.com/lirenlin/ba_demo_ceres"&gt;github source code fork&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;优化参量更新&lt;/h1&gt;
&lt;p&gt;注意这里对李代数求导，对于原参数的更新，必须返回到SE(3)。
&lt;/p&gt;
&lt;div class="math"&gt;$$X = X + \Delta X$$&lt;/div&gt;
&lt;p&gt;
这里&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;是用Jacobian矩阵求得。因为位姿相关部分是用李代数求得，所以&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;位姿更新部分也是李代数，
在更新T参数时，需要变换到SE(3)下。对于路标位置，可以直接更新。
这个使用ceres solver里面的LocalParameterization实现，重载plus成员函数。&lt;/p&gt;
&lt;p&gt;从李代数到Transform matrix的转换在《视觉slam十四讲》李代数章节讲的很清楚。&lt;/p&gt;
&lt;p&gt;so(3)李代数实际上由旋转向量组成，所以转换遵循Angle-Aix, Rotation matrix, Quaternion变换关系。&lt;/p&gt;
&lt;h1&gt;代码备注&lt;/h1&gt;
&lt;p&gt;Eigen库里面有大量的运算符重载，例如四元数表示的旋转可以直接与三维坐标想成得到旋转后的向量。
在数学上是不行的。&lt;/p&gt;
&lt;h1&gt;继续学习&lt;/h1&gt;
&lt;p&gt;李群，李代数的数学意义，manifold tangent space目前还是不清楚。&lt;/p&gt;
&lt;h1&gt;参考资料&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;《视觉slam十四讲》  &lt;/li&gt;
&lt;li&gt;&lt;a href="/pdfs/Visual_SLAM_Tutorial_Bundle_Adjustment.pdf"&gt;Visual SLAM Tutorial: Bundle Adjustment&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/lirenlin/ba_demo_ceres"&gt;github source code fork&lt;/a&gt;  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/sVjy9kr-8qc9W9VN78JoDQ"&gt;李代数讲解&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="BundleAdjustment"></category></entry><entry><title>Eigen</title><link href="/eigen.html" rel="alternate"></link><updated>2019-01-14T15:34:46+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-14:eigen.html</id><summary type="html">&lt;p&gt;Operator *在Eigen中被重载，可以直接使用一个四元数乘以一个向量来计算来旋转后的向量。
例如：
https://stackoverflow.com/questions/50507665/eigen-rotate-a-vector3d-with-a-quaternion&lt;/p&gt;</summary><category term="Eigen"></category></entry><entry><title>Local parameterization</title><link href="/local-parameterization.html" rel="alternate"></link><updated>2019-01-13T22:04:03+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-13:local-parameterization.html</id><summary type="html">&lt;p&gt;Parameterization
使用一个表达方式去表达同一个系统的状态/参数.&lt;/p&gt;
&lt;h2&gt;Ceres Local Parameterization&lt;/h2&gt;
&lt;p&gt;In many cases, some parameters lie on a manifold other than Euclidean space, e.g.,
rotation matrices. In such cases, the user can specify the geometry of the local 
tangent space by specifying a LocalParameterization object.&lt;/p&gt;
&lt;p&gt;https://groups.google.com/forum/#!topic/ceres-solver/7HfF6DnCv7o&lt;/p&gt;
&lt;h2&gt;参数化&lt;/h2&gt;
&lt;p&gt;在迭代优化方法中，例如高斯牛顿，每一次迭代有如下 变量更新:
&lt;/p&gt;
&lt;div class="math"&gt;$$ X = X + \Delta X$$&lt;/div&gt;
&lt;p&gt;
如果X的参数空间没有定义加法，例如旋转矩阵R, 变换矩阵T，或者简单的旋转向量。这就涉及到两个问题，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何定义局部参数来表示&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;，也就是所谓的local parameterization。&lt;/li&gt;
&lt;li&gt;定义&lt;span class="math"&gt;\(\boxplus\)&lt;/span&gt;运算符，用来更新变量。 &lt;span class="math"&gt;\( X = X \boxplus \Delta X\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;状态变量&lt;span class="math"&gt;\(X\)&lt;/span&gt;参数化&lt;/h3&gt;
&lt;p&gt;X的参数化与&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;的参数化会不一样。它们有各自的要求。
对于待估计状态参数X，因为需要直接用于计算误差，所以X的表示方式，如果可以有利于计算的表达，
可以减少计算的复杂度。例如位姿的变化，可以表示直接成旋转矩阵乘法。如果是其他的compact的旋转表示方法，
需要每次进行变化，然后应用在坐标上。通常对于最小二乘法，有很多项误差需要计算，
转换本身就这会是一个非常大的运算花销。&lt;/p&gt;
&lt;p&gt;同时X的参数会取决于误差函数的定义, 不同的误差函数，会使用参数的不同形式进行计算。
总之，X的参数化，要尽量的减少它在计算误差时的计算量。&lt;/p&gt;
&lt;h3&gt;更新变量&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;参数化&lt;/h3&gt;
&lt;p&gt;另一方面，&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;的参数化，有不同的要求。&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;的参数话，要求&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;其所在的解空间平滑可导数。&lt;br /&gt;
&lt;strong&gt;这个性质对于优化方法的收敛速度非常重要。平滑可导，无奇异，使的在寻找增量的时候可以按照最优
的方向寻找。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;最小化代表信息。&lt;ol&gt;
&lt;li&gt;因为&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;是优化方法求导的目标，其维度越小，Jacobian matrix的
列越少，相应计算越少。&lt;/li&gt;
&lt;li&gt;有时候利用冗余的信息代表参数，可以简化计算，但是内部参数之间有一定的
约束关系。如果这个约束关系在优化求解过程当中没有表示出来，很可能产生不合理的解。
例如三维旋转矩阵有9个维度。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;计算数值稳定性&lt;/h3&gt;
&lt;p&gt;在计算过程当中，有很多信息累加的过程，每个累加，都会有数值计算的误差，这些误差会不断积累。
最后会造成数值的不稳定。&lt;/p&gt;
&lt;p&gt;例如用四元数表示旋转。如果用角度来参数化，那么每次需要求解正弦余弦值，然后不断累计乘法。得到最后旋转的叠加。
相反，在四元数参数化中，旋转角度的累积是加法，最后只需要做一次转换，然后求得的最终旋转后的结果。整个过程数值
计算更稳定，也能减少很多的计算量。&lt;/p&gt;
&lt;h2&gt;&lt;span class="math"&gt;\(\boxplus\)&lt;/span&gt; 用途&lt;/h2&gt;
&lt;p&gt;在上面提到的，&lt;span class="math"&gt;\(\boxplus\)&lt;/span&gt;运算符，供优化框架使用，来实现迭代过程中状态变量的更新。
它用来连接&lt;span class="math"&gt;\(X\)&lt;/span&gt;与&lt;span class="math"&gt;\(\Delta X\)&lt;/span&gt;两个不同的参数化空间。&lt;/p&gt;
&lt;p&gt;这个运算符还有另一个功能，自动求导框架需要使用此运算符来对参数求导。当然你可以提供手动解析求导方式。&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Ceres"></category></entry><entry><title>First order function</title><link href="/first-order-function.html" rel="alternate"></link><updated>2019-01-13T13:18:22+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-13:first-order-function.html</id><summary type="html">&lt;p&gt;ihttps://en.wikipedia.org/wiki/First-class_function&lt;/p&gt;</summary><category term="Programming"></category></entry><entry><title>Pseudo Inverse</title><link href="/pseudo-inverse.html" rel="alternate"></link><updated>2019-01-11T18:03:09+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-11:pseudo-inverse.html</id><summary type="html">&lt;p&gt;In mathematics, and in particular linear algebra, a pseudoinverse A+ of a matrix
A is a generalization of the inverse matrix. The most widely known type of
matrix pseudoinverse is the Moore–Penrose inverse, which was independently
described by E. H. Moore in 1920, Arne Bjerhammar in 1951, and Roger Penrose in
1955. Earlier, Erik Ivar Fredholm had introduced the concept of a pseudoinverse
of integral operators in 1903. When referring to a matrix, the term
pseudoinverse, without further specification, is often used to indicate the
Moore–Penrose inverse. The term generalized inverse is sometimes used as a
synonym for pseudoinverse.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A common use of the pseudoinverse is to compute a 'best fit' (least squares)
solution to a system of linear equations that lacks a unique solution
(see below under § Applications). Another use is to find the minimum
(Euclidean) norm solution to a system of linear equations with multiple
solutions. The pseudoinverse facilitates the statement and proof of results in
linear algebra.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The pseudoinverse is defined and unique for all matrices whose entries are real
or complex numbers. It can be computed using the singular value decomposition. &lt;/p&gt;
&lt;p&gt;https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>线性变换的理解</title><link href="/xian-xing-bian-huan-de-li-jie.html" rel="alternate"></link><updated>2019-01-10T23:13:22+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-10:xian-xing-bian-huan-de-li-jie.html</id><summary type="html">&lt;p&gt;给定一个向量x
[数值] = [坐标] x [坐标系统基]&lt;/p&gt;
&lt;p&gt;linear transformation可以理解成坐标系统的改变.
例如将x变换到以[v1, v2, ... vn]为basis的系统下，&lt;/p&gt;
&lt;div class="math"&gt;\begin{aligned}
X &amp;amp;= c_{1}v_{1} + c_{2}v_{2} + ... c_{n}v_{n} \\
X &amp;amp;= [v_{1} v_{2} ... v_{n}] [c_{1} c_{2} ...]^{T} \\
X &amp;amp;= WC  (1)\\
C &amp;amp;= W^{-1}X (2)
\end{aligned}&lt;/div&gt;
&lt;p&gt;(2) 为变换，C为X变换后，在新的坐标系下的坐标. &lt;span class="math"&gt;\(W^{-1]\)&lt;/span&gt;为变换矩阵。
(1) 为逆变换，在给定C后，恢复在原始坐标系下的数据&lt;/p&gt;
&lt;p&gt;所以对于一个好的变换矩阵，需要有下面两个特征&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;快速的矩阵乘法与求逆，这样才可以快速进行运算。例如使用傅里叶变化矩阵的快速傅里叶变换与Wavelet变换矩阵&lt;/li&gt;
&lt;li&gt;好的压缩特性，尽量少的坐标轴包含尽量多的信息。这样可以忽略不重要的信息，进行降维，实现压缩&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=vGkn-3NFGck&amp;amp;t=1709s"&gt;Lec 31 | MIT 18.06 Linear Algebra, Spring 2005&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>SVD</title><link href="/svd.html" rel="alternate"></link><updated>2019-01-10T16:21:16+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-10:svd.html</id><summary type="html">&lt;h1&gt;特征值分解&lt;/h1&gt;
&lt;p&gt;要求: 方阵
线性代数中，特征分解（Eigendecomposition），又称谱分解（Spectral decomposition）
是将矩阵分解为由其特征值和特征向量表示的矩阵之积的方法。
需要注意只有对可对角化矩阵才可以施以特征分解.&lt;/p&gt;
&lt;p&gt;令 A 是一个 N×N 的方阵，且有 N 个线性无关的特征向量 &lt;span class="math"&gt;\(q_{i}\,\,(i=1,\dots ,N)\)&lt;/span&gt;。
这样， A 可以被分解为
&lt;/p&gt;
&lt;div class="math"&gt;$$\mathbf {A} =\mathbf {Q} \mathbf {\Lambda } \mathbf {Q} ^{-1}$$&lt;/div&gt;
&lt;p&gt;
其中 Q 是N×N方阵，且其第 i列为 A 的特征向量 &lt;span class="math"&gt;\(q_{i}\)&lt;/span&gt;。 Λ 是对角矩阵，
其对角线上的元素为对应的特征值，也即 &lt;span class="math"&gt;\(\Lambda_{ii}=\lambda_{i}\)&lt;/span&gt;。这里需要注意
只有可对角化矩阵才可以作特征分解。 比如
&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}1&amp;amp;1\\0&amp;amp;1\\\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;
不能被对角化，也就不能特征分解。&lt;/p&gt;
&lt;p&gt;一般来说，特征向量 &lt;span class="math"&gt;\( q_{i}\,\,(i=1,\dots ,N)\)&lt;/span&gt; 一般被单位化（但这不是必须的）。
未被单位化的特征向量组 &lt;span class="math"&gt;\( v_{i}\,\,(i=1,\dots ,N)\)&lt;/span&gt;, 也可以作为 Q 的列向量。
这一事实可以这样理解： Q 中向量的长度都被&lt;span class="math"&gt;\(Q^{−1}\)&lt;/span&gt;抵消了。&lt;/p&gt;
&lt;h1&gt;谱分解&lt;/h1&gt;
&lt;p&gt;要求: 正规矩阵&lt;/p&gt;
&lt;h1&gt;奇异值分解Singular Value Decomposition&lt;/h1&gt;
&lt;h2&gt;定义&lt;/h2&gt;
&lt;p&gt;奇异值分解是一个能适用于任意的矩阵的一种分解的方法
SVD 分解说的是：假设 M 是一个 m×n 的矩阵，其中的元素全部属于数域 𝕂
（实数域 ℝ 或复数域 ℂ）。那么，存在 m×m 的酉矩阵 U 和 n×n 的酉矩阵 V
使得
&lt;/p&gt;
&lt;div class="math"&gt;$$\mathbf M = \mathbf U\mathbf\Sigma\mathbf V^{\mathsf H}$$&lt;/div&gt;
&lt;p&gt;
其中 &lt;span class="math"&gt;\(\Sigma\)&lt;/span&gt; 是 m×n 的非负实数对角矩阵；并且&lt;span class="math"&gt;\(\Sigma\)&lt;/span&gt; 对角线上的元素
&lt;span class="math"&gt;\(\Sigma_{i,i}\)&lt;/span&gt; 是 M 的奇异值。
一般来说，我们偏好将这些奇异值按从大到小的顺序排列，这样一来 Σ 就由 M 唯一确定了。
另一方面，因为 U 和 V 都是酉矩阵，所以 U 和 V 的列向量分别张成 𝕂m 和 𝕂n 的一组标
准正交基。我们将 U 的列向量记作 u⃗ i,1⩽i⩽m；将 V 的列向量记作 v⃗ j,1⩽j⩽n；同时，
将 Σ 对角线上的第 i 个元素记作 σk,1⩽k⩽min(m,n)。那么，SVD 分解实际可以将矩阵 M
写作一个求和形式
&lt;/p&gt;
&lt;div class="math"&gt;$$\mathbf M = \sum_{i = 1}^{\min(m, n)}\Sigma_i\vec u_i\vec v_i^{\mathsf T}$$&lt;/div&gt;
&lt;h2&gt;SVD计算&lt;/h2&gt;
&lt;h2&gt;SVD分解几何解释&lt;/h2&gt;
&lt;div class="math"&gt;$$\mathbf M = \mathbf U\mathbf\Sigma\mathbf V^{\mathsf H}$$&lt;/div&gt;
&lt;p&gt;
旋转, 缩放, 旋转&lt;/p&gt;
&lt;p&gt;U 和 V 都是旋转矩阵 (标准正交基)&lt;/p&gt;
&lt;h2&gt;SVD应用&lt;/h2&gt;
&lt;p&gt;SVD分解至少有两方面作用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分析了解原矩阵的主要特征和携带的信息（取若干最大的奇异值），这引出了主成分分析（PCA）；&lt;/li&gt;
&lt;li&gt;丢弃忽略原矩阵的次要特征和携带的次要信息（丢弃若干较小的奇异值），这引出了信息有损压缩、矩阵低秩近似等话题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;奇异向量的现实意义&lt;/h2&gt;
&lt;p&gt;SVD也可以得到协方差矩阵XTX最大的d个特征向量张成的矩阵，但是SVD有个好处，有一些SVD的实现算法可以不求先求出协方差矩阵XTX，也能求出我们的右奇异矩阵V&lt;/p&gt;
&lt;h1&gt;参考整理来源&lt;/h1&gt;
&lt;p&gt;https://www.zhihu.com/question/22237507&lt;br /&gt;
https://liam.page/2017/11/22/SVD-for-Human-Beings/&lt;br /&gt;
https://www.cnblogs.com/pinard/p/6251584.html  &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>"美"的矩阵</title><link href="/mei-de-ju-zhen.html" rel="alternate"></link><updated>2019-01-09T16:56:43+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-09:mei-de-ju-zhen.html</id><summary type="html">&lt;p&gt;"美"的矩阵形式&lt;/p&gt;
&lt;h1&gt;identity matrix 单位矩阵&lt;/h1&gt;
&lt;h1&gt;Unitary matrix 酉矩阵&lt;/h1&gt;
&lt;h1&gt;Normal matrix 正规矩阵&lt;/h1&gt;
&lt;h1&gt;Orthogonal matrix&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h1&gt;
&lt;p&gt;An orthogonal matrix is a square matrix whose columns and rows are orthogonal
unit vectors (i.e., orthonormal vectors), i.e.
&lt;/p&gt;
&lt;div class="math"&gt;$$Q^{T} Q = Q Q^{T} = I$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(I\)&lt;/span&gt; is the identity matrix.
This leads to the equivalent characterization: a matrix Q is orthogonal if
its transpose is equal to its inverse:
&lt;/p&gt;
&lt;div class="math"&gt;$$Q^{T} = Q^{−1}. $$&lt;/div&gt;
&lt;p&gt;An orthogonal matrix Q is necessarily invertible (with inverse &lt;span class="math"&gt;\(Q^{−1} = Q^{T}\)&lt;/span&gt;),
unitary (&lt;span class="math"&gt;\(Q^{−1} = Q^{∗}\)&lt;/span&gt;) and therefore normal (&lt;span class="math"&gt;\(Q^{∗}Q = QQ^{∗}\)&lt;/span&gt;) in the reals.
The determinant of any orthogonal matrix is either +1 or −1. As a linear
transformation, an orthogonal matrix preserves the dot product of vectors, and
therefore acts as an isometry of Euclidean space, such as a rotation, reflection
or rotoreflection. In other words, it is a unitary transformation.&lt;/p&gt;
&lt;p&gt;The set of n × n orthogonal matrices forms a group &lt;span class="math"&gt;\(O(n)\)&lt;/span&gt;, known as
the orthogonal group. The subgroup &lt;span class="math"&gt;\(SO(n)\)&lt;/span&gt; consisting of orthogonal
matrices with determinant +1 is called the special orthogonal
group, and each of its elements is a special orthogonal matrix. As
a linear transformation, every special orthogonal matrix acts as a
rotation.&lt;/p&gt;
&lt;h2&gt;Decompositions&lt;/h2&gt;
&lt;p&gt;A number of important matrix decompositions (Golub &amp;amp; Van Loan 1996) involve
orthogonal matrices, including especially:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;QR decomposition&lt;br /&gt;
    M = QR, Q orthogonal, R upper triangular&lt;/li&gt;
&lt;li&gt;Singular value decomposition&lt;br /&gt;
    M = UΣVT, U and V orthogonal, Σ diagonal matrix&lt;/li&gt;
&lt;li&gt;Eigendecomposition of a symmetric matrix (decomposition according to the spectral theorem)&lt;br /&gt;
    S = QΛQT, S symmetric, Q orthogonal, Λ diagonal&lt;/li&gt;
&lt;li&gt;Polar decomposition&lt;br /&gt;
    M = QS, Q orthogonal, S symmetric non-negative definite&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;diagonal matrix&lt;/h1&gt;
&lt;h2&gt;diagonal matrix with eigenvalue&lt;/h2&gt;
&lt;h1&gt;orthonormal matrix&lt;/h1&gt;
&lt;h1&gt;symmetric matrix:&lt;/h1&gt;
&lt;p&gt;A symmetric matrix is a square matrix that is equal to its transpose. Formally,
&lt;/p&gt;
&lt;div class="math"&gt;$$A^{T} = A$$&lt;/div&gt;
&lt;p&gt;
A nxn symmetric matrix A not only has a nice structure, but it also satisfies
the following (can be diagonaized, S = QΛQT, S symmetric, Q orthogonal, Λ diagonal):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A has exactly n (not necessarily distinct) eigenvalues&lt;/li&gt;
&lt;li&gt;There exists a set of n eigenvectors, one for each eigenvalue, that are mututally orthogonal.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, the situation encountered with the matrix D in the example above cannot
happen with a symmetric matrix: A symmetric matrix has n eigenvalues and there
exist n linearly independent eigenvectors (because of orthogonality) even if
the eigenvalues are not distinct.&lt;/p&gt;
&lt;p&gt;Proof of eigenvalue properties of the real symmetric matrix&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;矩阵的相似变换可以把一个比较丑的矩阵变成一个比较美的矩阵，而保证这两个矩阵都是描述了同一个线性变换。至于什么样的矩阵是“美”的，什么样的是“丑”的，我们说对角阵是美的。在线性代数中，我们会看到，如果把复杂的矩阵变换成对角矩阵，作用完了之后再变换回来，这种转换很有用处，比如求解矩阵的n次幂！而学了矩阵论之后你会发现，矩阵的n次幂是工程中非常常见的运算。这里顺便说一句，将矩阵对角化在控制工程和机械振动领域具有将复杂方程解耦的妙用！总而言之，相似变换是为了简化计算！&lt;/p&gt;
&lt;p&gt;从另一个角度理解矩阵就是：矩阵主对角线上的元素表示自身和自身的关系，其他位置的元素aij表示i位置和j位置元素之间的相互关系。那么好，特征值问题其实就是选取了一组很好的基，就把矩阵 i位置和j位置元素之间的相互关系消除了。而且因为是相似变换，并没有改变矩阵本身的特性。因此矩阵对角化才如此的重要！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;similar matrix:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;have same eigenvalues&lt;/li&gt;
&lt;li&gt;matrices represent the same thing in different basis&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;projection matrix:&lt;/h1&gt;
&lt;p&gt;In linear algebra and functional analysis, a projection is a linear
transformation P from a vector space to itself such that &lt;span class="math"&gt;\(P^2 = P\)&lt;/span&gt;. That is,
whenever P is applied twice to any value, it gives the same
result as if it were applied once (idempotent). It leaves its
image unchanged.[1] Though abstract, this definition of
"projection" formalizes and generalizes the idea of graphical
projection. One can also consider the effect of a projection on
a geometrical object by examining the effect of the projection
on points in the object.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;https://en.wikipedia.org/wiki/Orthogonal_matrix &amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;http://farside.ph.utexas.edu/teaching/336k/Newton/node66.html&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>Positive definite matrix</title><link href="/positive-definite-matrix.html" rel="alternate"></link><updated>2019-01-09T16:03:03+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-09:positive-definite-matrix.html</id><summary type="html">&lt;h1&gt;Definition&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h1&gt;
&lt;p&gt;In linear algebra, a &lt;strong&gt;symmetric&lt;/strong&gt; &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; real matrix &lt;span class="math"&gt;\(M\)&lt;/span&gt; is said to be
positive definite if the scalar &lt;span class="math"&gt;\(z^{T}Mz\)&lt;/span&gt; is strictly positive for every
non-zero column vector &lt;span class="math"&gt;\(z\)&lt;/span&gt; of &lt;span class="math"&gt;\(n\)&lt;/span&gt; real numbers. Here &lt;span class="math"&gt;\(z^{\textsf {T}}\)&lt;/span&gt; denotes
the transpose of &lt;span class="math"&gt;\(z\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;More generally, an &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; Hermitian matrix &lt;span class="math"&gt;\(M\)&lt;/span&gt; is said to be positive
definite if the scalar &lt;span class="math"&gt;\(z^{*}Mz\)&lt;/span&gt; is strictly positive for every non-zero column
vector &lt;span class="math"&gt;\(z\)&lt;/span&gt; of &lt;span class="math"&gt;\(n\)&lt;/span&gt; complex numbers. Here &lt;span class="math"&gt;\(z^{*}\)&lt;/span&gt; denotes the conjugate transpose
of &lt;span class="math"&gt;\(z\)&lt;/span&gt;. Note that &lt;span class="math"&gt;\(z^{∗} M z\)&lt;/span&gt; is automatically real since &lt;span class="math"&gt;\(M\)&lt;/span&gt; is Hermitian.&lt;/p&gt;
&lt;h1&gt;与Diagonalization, eigenvalues和eigenvectorg关系&lt;/h1&gt;
&lt;h1&gt;Quadratic forms, convexity, optimization&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h1&gt;
&lt;p&gt;The (purely) quadratic form associated with a real &lt;span class="math"&gt;\(n\times n\)&lt;/span&gt; matrix M is the
function &lt;span class="math"&gt;\(Q : \mathbb {R}^n \to \mathbb R\)&lt;/span&gt; such that &lt;span class="math"&gt;\(Q(x)=x^{T}Mx\)&lt;/span&gt; for all
&lt;span class="math"&gt;\(x\)&lt;/span&gt;. &lt;span class="math"&gt;\(M\)&lt;/span&gt; can be assumed symmetric by replacing it with  &lt;span class="math"&gt;\(1/2(M+M^{T})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A symmetric matrix &lt;span class="math"&gt;\(M\)&lt;/span&gt; is positive definite if and only if its quadratic form
is a strictly &lt;strong&gt;convex&lt;/strong&gt; function.&lt;/p&gt;
&lt;p&gt;More generally, any quadratic function from &lt;span class="math"&gt;\(\mathbb {R}^{n}\)&lt;/span&gt; to &lt;span class="math"&gt;\(\mathbb {R}\)&lt;/span&gt;
can be written as &lt;span class="math"&gt;\( x^{T}Mx+x^{T}b+c\)&lt;/span&gt; where &lt;span class="math"&gt;\(M\)&lt;/span&gt; is a symmetric &lt;span class="math"&gt;\(n\times n\)&lt;/span&gt;
matrix, &lt;span class="math"&gt;\(b\)&lt;/span&gt; is a real &lt;span class="math"&gt;\(n\)&lt;/span&gt;-vector, and &lt;span class="math"&gt;\(c\)&lt;/span&gt; a real constant. This quadratic
function is strictly convex, and hence has a unique finite global minimum, if
and only if &lt;span class="math"&gt;\(M\)&lt;/span&gt; is positive definite. For this reason, positive definite
matrices play an important role in optimization problems.&lt;/p&gt;
&lt;h1&gt;Additional information:&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://stats.stackexchange.com/questions/224005/why-are-symmetric-positive-definite-spd-matrices-so-important"&gt;StackExchange: Why are symmetric positive definite (SPD) matrices so important?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://setosa.io/ev/eigenvectors-and-eigenvalues/"&gt;Eigenvectors and Eigenvalues: Explained Visually&lt;/a&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;https://en.wikipedia.org/wiki/Definiteness_of_a_matrix&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="Optimization"></category></entry><entry><title>EigenValue EigenVector</title><link href="/eigenvalue-eigenvector.html" rel="alternate"></link><updated>2019-01-06T17:22:56+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-06:eigenvalue-eigenvector.html</id><summary type="html">&lt;p&gt;我们知道，矩阵乘法对应了一个变换，是把任意一个向量变成另一个方向或长度都大多不同的新向量。在这个变换的过程中，原向量主要发生旋转、伸缩的变化。如果矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，伸缩的比例就是特征值。&lt;/p&gt;
&lt;p&gt;特征值eigenvalue和特征向量eigenvector的一大应用是用于大量数据的降维
压缩，简化计算
相似矩阵&lt;/p&gt;
&lt;p&gt;https://zhuanlan.zhihu.com/p/31003468&lt;/p&gt;
&lt;p&gt;http://setosa.io/ev/eigenvectors-and-eigenvalues/&lt;/p&gt;
&lt;p&gt;https://www.zhihu.com/question/21874816&lt;/p&gt;
&lt;p&gt;http://mlwiki.org/index.php/Eigendecomposition&lt;/p&gt;
&lt;p&gt;https://blog.csdn.net/dongtinghong/article/details/14216139&lt;/p&gt;
&lt;p&gt;https://stats.stackexchange.com/questions/224005/why-are-symmetric-positive-definite-spd-matrices-so-important&lt;/p&gt;
&lt;p&gt;Still, it is important to know what determinants are, and their basic properties. In 18.06, we mainly use determinants as a conceptual tool to help us understand eigenvalues via the characteristic polynomial — although, again, this is not a practical computational tool for eigenvalues, which are nowadays computed by very different methods.&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>Singular matrix</title><link href="/singular-matrix.html" rel="alternate"></link><updated>2019-01-05T12:26:08+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-05:singular-matrix.html</id><summary type="html">&lt;p&gt;Singular Matrix or Noninvertible Matrix&lt;/p&gt;
&lt;p&gt;A square matrix which does not have an inverse. A matrix is singular if and only if its determinant is zero.&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>Normal Equation</title><link href="/normal-equation.html" rel="alternate"></link><updated>2019-01-04T18:08:16+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-04:normal-equation.html</id><summary type="html">&lt;p&gt;从MIT公开课Linear Algebra从了解到，这里做了很好的总结.
在线性方程组条件下，Normal equation解法与梯度下降法一样，梯度下降法一次迭代就可以稳定。可以证明，与正规方程解法意义相同。同时，正规方程解法具有几何意义.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/u013802188/article/details/40181601"&gt;CSDN:正规方程组(The normal equations)&lt;/a&gt;
&lt;a href="http://mlwiki.org/index.php/Normal_Equation"&gt;ML Wiki: Normal equation&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>Interpolation</title><link href="/interpolation.html" rel="alternate"></link><updated>2019-01-03T23:32:10+01:00</updated><author><name>Nekoo</name></author><id>tag:,2019-01-03:interpolation.html</id><summary type="html">&lt;p&gt;In the mathematical field of numerical analysis, interpolation is a method of
constructing new data points within the range of a discrete set of known data
points.&lt;/p&gt;
&lt;p&gt;In engineering and science, one often has a number of data points, obtained by
sampling or experimentation, which represent the values of a function for a
limited number of values of the independent variable. It is often required to
interpolate, i.e., estimate the value of that function for an intermediate
value of the independent variable.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;linear interpolation.
Linear interpolation is quick and easy, but&lt;ul&gt;
&lt;li&gt;It is not very precise.&lt;/li&gt;
&lt;li&gt;The interpolant is not differentiable at the point &lt;span class="math"&gt;\(x_k\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Polynomial interpolation
Overcomes most of the problems of linear interpolation. (error, differentiable)
However, polynomial interpolation also has some disadvantages.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Calculating the interpolating polynomial is computationally expensive
compared to linear interpolation.&lt;/li&gt;
&lt;li&gt;polynomial interpolation may exhibit oscillatory artifacts,
  especially at the end points (see Runge's phenomenon).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Spline interpolation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;smaller error than linear interpolation&lt;/li&gt;
&lt;li&gt;interpolant is smoother.&lt;/li&gt;
&lt;li&gt;the interpolant is easier to evaluate than the high-degree polynomials used
in polynomial interpolation&lt;/li&gt;
&lt;li&gt;However, the global nature of the basis functions leads to
ill-conditioning. This is completely mitigated by using splines of compact
support, such as are implemented in Boost.Math and discussed in Kress.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A simple (well behaved) differentiable interpolation is the Cubic
Hermite Spline&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Interpolation#Polynomial_interpolation"&gt;Wiki: Interpolation&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>Matrix rank</title><link href="/matrix-rank.html" rel="alternate"></link><updated>2018-12-26T13:07:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-26:matrix-rank.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;直观：「秩」是图像经过矩阵变换之后的空间维度&lt;/li&gt;
&lt;li&gt;定义：「秩」是列空间的维度&lt;/li&gt;
&lt;li&gt;物理意义：From an applied setting, rank of a matrix denotes the information content of
the matrix. The lower the rank, the lower is the "information content".&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我的理解：
&lt;/p&gt;
&lt;div class="math"&gt;$$Ax = b, \quad \textrm {where} \quad A \in \mathbb {R}^{nxn}, x, b \in \mathbb {R}^{n}$$&lt;/div&gt;
&lt;p&gt;given a point (vector)x in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;, apply the transformation, map it into another point b.
As column of C is the combination of columns of A, this indicates point b is
within the columns space of A.
In other words, point b is a point inside the vector space defined by A's columns.&lt;/p&gt;
&lt;p&gt;Rank by definition from &lt;a href="https://en.wikipedia.org/wiki/Rank_(linear_algebra)"&gt;wiki&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;in linear algebra, the rank of a matrix A is the dimension of the vector space
generated (or spanned) by its columns.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Additional if some columns inside A doesn't provide more information(constraint) to the
space. They don't define new dimentions. They are just the combinations (scalar multiply and vector add) 
of other 'essential' columns. The number of the 'essential' columns which defines the
vector space is rank.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/linear_solution.png" alt="Liner solution" title="linear solution" style="max-width:100%;max-height=100%"/&gt;&lt;/p&gt;
&lt;p&gt;b is any point in &lt;span class="math"&gt;\(\mathbb {R}^m\)&lt;/span&gt;. A defines a space with its column vectors.
Of course, if you want this system of equation has a solution, b must be in the
space defined by A. In another way, a given point x will be transformed into a
point in space defined by A. You might also want this process to be reversible,
so that you can recover x given b and system matrix A.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A defines the vector space &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;, any point x in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt; has a unique mapping point b which is in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;A defines the vector space &lt;span class="math"&gt;\(\mathbb {R}^m\)&lt;/span&gt;, a subspace in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;, multiple points in $\mathbb {R}^n will map to the same point in space constrained by A.&lt;/li&gt;
&lt;li&gt;A defines a subspace in &lt;span class="math"&gt;\(\mathbb {R}^m\)&lt;/span&gt;, point b in this subspace has a unique mapping x which is in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;. Point b which is not this subspace, however in &lt;span class="math"&gt;\(\mathbb{R}^m\)&lt;/span&gt;, could not find any mapping points x.&lt;/li&gt;
&lt;li&gt;A defines a subspace in &lt;span class="math"&gt;\(\mathbb {R}^m\)&lt;/span&gt;, point b in this subspace has more than one mapping x which is in &lt;span class="math"&gt;\(\mathbb {R}^n\)&lt;/span&gt;. Points b which is not this subspace, however in &lt;span class="math"&gt;\(\mathbb{R}^m\)&lt;/span&gt;, could not find any mapping points x.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://math.stackexchange.com/a/21107"&gt;math.stackexchange: Importance of matrix rank&lt;/a&gt;&lt;br /&gt;
&lt;a href="https://www.zhihu.com/question/21605094"&gt;知乎&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>线性方程组</title><link href="/xian-xing-fang-cheng-zu.html" rel="alternate"></link><updated>2018-12-26T10:25:50+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-26:xian-xing-fang-cheng-zu.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In general, a system with fewer equations than unknowns has infinitely many
solutions, but it may have no solution. Such a system is known as an
underdetermined system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In general(not always), a system with more equations than unknowns has no solution. Such a
system is also known as an overdetermined system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In general, a system with the same number of equations and unknowns has a
single unique solution.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="math"&gt;\begin{align}
Ax &amp;amp;= b, \\
A^{-1}Ax &amp;amp;= A^{-1}b, \\
x &amp;amp;= A^{-1}b,
\end{align}&lt;/div&gt;
&lt;p&gt;
如果这个方程有唯一解，变换可逆，A可逆. 这意味着，从b，可以还原应用了变换之前的x。
这个变换是可逆的。&lt;/p&gt;
&lt;p&gt;通常有两个形式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方程组个数大于变量数，无确定解，但是找到一个近似系统描述, 常见为拟合&lt;/li&gt;
&lt;li&gt;方程组有无数解，在满足一定条件的约束下，给定一个目标函数，使其最大或者最小, 优化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;线性 or 非线性系统？&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>Vim: Operation on search matches using gn</title><link href="/vim-operation-on-search-matches-using-gn.html" rel="alternate"></link><updated>2018-12-26T10:08:53+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-26:vim-operation-on-search-matches-using-gn.html</id><summary type="html">&lt;p&gt;The gn command (introduced in Vim 7.4) makes it easy to operate on regions of
text that match the current search pattern. It’s especially useful when used
with a regex that matches text regions of variable length.&lt;/p&gt;
&lt;p&gt;Here’s what Vim’s documentation has to say about the gn command (:help gn):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Search forward for the last used search pattern, like with n, and start
Visual mode to select the match. If the cursor is on the match, visually
selects it. If an operator is pending, operates on the match.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里有三个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Search forward for the last used search pattern.&lt;/li&gt;
&lt;li&gt;Visually select it. (so that operator could apply to the pattern immediately)&lt;/li&gt;
&lt;li&gt;Apply pending operator.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一般的查找下一个(n)，只是做了第一步，如果你的查找是多个单词或者一个区域，例如 "this
is"，正常的查找下一个不会选择全部，而是将光标移动到匹配的开始，也就是在"this"， 
如果你要一起修改"this is", 需要再次选择"this is"，然后替换。&lt;/p&gt;
&lt;p&gt;在没有知道这个命令之前，我都是使用q来record多个操作到寄存器。然后重复的应用到下一个匹配的搜索。&lt;/p&gt;
&lt;p&gt;'gn'在Operator-pending mode下，可以将所有的操作融合为一个步骤，
这样就可以使用vim的'.'dot指令进行重复，简便很多。例如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;his is    &lt;span class="c1"&gt;#search block &amp;quot;this is&amp;quot;&lt;/span&gt;
:cgn these are  &lt;span class="c1"&gt;#next match pattern, and change it into &amp;quot;these are&amp;quot;&lt;/span&gt;
.       &lt;span class="c1"&gt;#apply the same modification to the next match&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Reference:&lt;br /&gt;
&lt;a href="http://vimcasts.org/episodes/operating-on-search-matches-using-gn/"&gt;Operating on search matches using gn&lt;/a&gt;&lt;/p&gt;</summary><category term="Vim"></category></entry><entry><title>矩阵乘法</title><link href="/ju-zhen-cheng-fa.html" rel="alternate"></link><updated>2018-12-25T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-25:ju-zhen-cheng-fa.html</id><summary type="html">&lt;div class="math"&gt;$$C = AB, A \in \mathbb {R}^{m \times n}, b \in \mathbb {R}^{n \times l}, c \in \mathbb {R}^{m \times l}$$&lt;/div&gt;
&lt;p&gt;For example:
&lt;/p&gt;
&lt;div class="math"&gt;$$
A =
\begin{bmatrix}
a_{00} &amp;amp; a_{01} &amp;amp; a_{02}\\
a_{10} &amp;amp; a_{11} &amp;amp; a_{12}\\
a_{20} &amp;amp; a_{21} &amp;amp; a_{22}
\end{bmatrix}
B =
\begin{bmatrix}
b_{00} &amp;amp; b_{01} &amp;amp; b_{02}\\
b_{10} &amp;amp; b_{11} &amp;amp; b_{12}\\
b_{20} &amp;amp; b_{21} &amp;amp; b_{22}
\end{bmatrix}
C =
\begin{bmatrix}
c_{00} &amp;amp; c_{01} &amp;amp; c_{02}\\
c_{10} &amp;amp; c_{11} &amp;amp; c_{12}\\
c_{20} &amp;amp; c_{21} &amp;amp; c_{22}
\end{bmatrix}
$$&lt;/div&gt;
&lt;h1&gt;Componenet wise&lt;/h1&gt;
&lt;div class="math"&gt;$$C_{ij} = \sum_{k=1}^{m} a_{ik} \times b_{kj}$$&lt;/div&gt;
&lt;p&gt;
for i = 1, ..., m and j = 1, ..., l.&lt;/p&gt;
&lt;h1&gt;Row wise&lt;/h1&gt;
&lt;p&gt;Row of C is the combination of rows of B&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{cases}
c_{00} = a_{00} \times b_{00} + a_{01} \times b_{10} + a_{02} \times b_{20} \\
c_{01} = a_{00} \times b_{01} + a_{01} \times b_{11} + a_{02} \times b_{21} \\
c_{03} = a_{00} \times b_{02} + a_{01} \times b_{12} + a_{02} \times b_{22} \\
\end{cases} \rightarrow
\begin{bmatrix}
c_{00} \\ c_{01} \\ c_{02}
\end{bmatrix}^T =
\begin{bmatrix}
b_{00} \\ b_{01} \\ b_{02}
\end{bmatrix} ^T
\times  a_{00} +
\begin{bmatrix}
b_{10} \\ b_{11} \\ b_{12}
\end{bmatrix}^T
\times  a_{01} +
\begin{bmatrix}
b_{20} \\ b_{21} \\ b_{22}
\end{bmatrix}^T
\times  a_{02}
$$&lt;/div&gt;
&lt;h1&gt;Column wise&lt;/h1&gt;
&lt;p&gt;Column of C is the combination of columns of A
&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{cases}
c_{00} = a_{00} \times b_{00} + a_{01} \times b_{10} + a_{02} \times b_{20} \\
c_{10} = a_{10} \times b_{00} + a_{11} \times b_{10} + a_{12} \times b_{20} \\
c_{20} = a_{20} \times b_{00} + a_{21} \times b_{10} + a_{22} \times b_{20} \\
\end{cases} \rightarrow
\begin{bmatrix}
c_{00} \\ c_{10} \\ c_{20}
\end{bmatrix} =
\begin{bmatrix}
a_{00} \\ a_{10} \\ a_{20}
\end{bmatrix}
\times  b_{00} +
\begin{bmatrix}
a_{01} \\ a_{11} \\ a_{21}
\end{bmatrix}
\times  b_{10} +
\begin{bmatrix}
a_{02} \\ a_{12} \\ a_{22}
\end{bmatrix}
\times  b_{20}
$$&lt;/div&gt;
&lt;h1&gt;Matrix wise&lt;/h1&gt;
&lt;p&gt;AB is the sum of col_of(A) * row_of(B)
&lt;/p&gt;
&lt;div class="math"&gt;$$AB = \sum_{i=0}^l {A[:i] \times B[i:]}$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(a[:i] \in \mathbb {R}^{mx1}, B[i:] \in \mathbb {R}^{1xl}\)&lt;/span&gt;&lt;/p&gt;
&lt;h1&gt;Block matrix multiplication&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Block_matrix#Block_matrix_multiplication"&gt;Wiki&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>矩阵分解</title><link href="/ju-zhen-fen-jie.html" rel="alternate"></link><updated>2018-12-25T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-25:ju-zhen-fen-jie.html</id><summary type="html">&lt;h1&gt;Simplify the computation of linear system of equations.&lt;/h1&gt;
&lt;p&gt;Matrix factorization in the context of numerical linear algebra(NLA) generally serves the purpose of rephrasing through a series of easier subproblems a task that may be relatively difficult to solve in its original form.&lt;/p&gt;
&lt;p&gt;For example, given the typical linear system Ax = b for &lt;span class="math"&gt;\(A \in \mathbb {R}^{n × n}\)&lt;/span&gt;, x and b &lt;span class="math"&gt;\(\in \mathbb {R}^n\)&lt;/span&gt; , a factorization of A as LU for L a unit lower triangular matrix (thus, with ones along its main diagonal) and an upper triangular U is a mechanism for characterizing what occurs in Gaussian elimination.&lt;/p&gt;
&lt;p&gt;We replace &lt;span class="math"&gt;\(Ax = b\)&lt;/span&gt; by two (easier to solve) triangular systems:  find y so &lt;span class="math"&gt;\(Ly = b\)&lt;/span&gt; and then find x so &lt;span class="math"&gt;\(Ux = y\)&lt;/span&gt;.The point being made here is that the factorization of A as LU has no real importance in and of itself other than as a computationally convenient means for obtaining a solution to the original linear system.&lt;/p&gt;
&lt;h1&gt;Help to understand the structure of a big data matrix.&lt;/h1&gt;
&lt;p&gt;Typically, a matrix &lt;span class="math"&gt;\(A \in \mathbb {R}^{n × p}\)&lt;/span&gt; represents a data matrix containing numerical observations on n objects (subjects) over p attributes (variables), or possibly &lt;span class="math"&gt;\(B \in \mathbb {R}^{p × p}\)&lt;/span&gt; and the entries are some measure of proximity between attributes, such as the correlation between columns of A.&lt;/p&gt;
&lt;p&gt;The major purpose of a matrix factorization in this context is to obtain some form of lower-rank (and therefore simplified) approximation to A (or possibly to B) for understanding the structure of the data matrix, particularly the relationship within the objects and within the attributes, and how the objects relate to the attributes. If we can further interpret the matrix factorization geometrically and actually present the results spatially through coordinates obtained from the components of the factorization, we will be able to better communicate to others what structure may be present in the original data matrix.&lt;/p&gt;
&lt;p&gt;In any case, matrix factorizations are again directed toward the issue of simplicity, but now the actual components making up a factorization are of prime concern and not solely as a mechanism for solving another problem.&lt;/p&gt;
&lt;h1&gt;Related concepts&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Rank_(linear_algebra)"&gt;Rank (linear algebra)秩&lt;/a&gt;&lt;blockquote&gt;
&lt;p&gt;In linear algebra, the rank of a matrix A is the dimension of the vector space generated (or spanned) by its columns.[1] This corresponds to the maximal number of linearly independent columns of A.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Numerical_stability"&gt;Numerical stability&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Related articles&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://staff.ustc.edu.cn/~ynyang/group-meeting/2014/matrix-factorization/hubert.pdf"&gt;Two Purposes for Matrix Factorization: A Historical Appraisal&lt;/a&gt;&lt;br /&gt;
&lt;a href="https://people.duke.edu/~ccc14/sta-663/LinearAlgebraMatrixDecompWithSolutions.html"&gt;Linear Algebra and Matrix Decompositions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.jiqizhixin.com/articles/0301"&gt;奇异值分解简介：从原理到基础机器学习应用&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>矩阵性质 (From Wiki)</title><link href="/ju-zhen-xing-zhi-from-wiki.html" rel="alternate"></link><updated>2018-12-25T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-25:ju-zhen-xing-zhi-from-wiki.html</id><summary type="html">&lt;h1&gt;Square matrix:&lt;/h1&gt;
&lt;p&gt;In mathematics, a square matrix is a matrix with the same number of rows and columns. An n-by-n matrix is known as a square matrix of order n. Any two square matrices of the same order can be added and multiplied.&lt;/p&gt;
&lt;p&gt;Square matrices are often used to represent simple linear transformations, such as shearing or rotation. For example, if R is a square matrix representing a rotation (rotation matrix) and v is a column vector describing the position of a point in space, the product Rv yields another column vector describing the position of that point after that rotation. If v is a row vector, the same transformation can be obtained using vRT, where RT is the transpose of R.&lt;/p&gt;
&lt;h1&gt;Identity matrix:&lt;/h1&gt;
&lt;p&gt;In linear algebra, the identity matrix, or sometimes ambiguously called a unit matrix, of size n is the n × n square matrix with ones on the main diagonal and zeros elsewhere.  It is denoted by &lt;span class="math"&gt;\(I_n\)&lt;/span&gt;, or simply by I if the size is immaterial or can be trivially determined by the context.&lt;/p&gt;
&lt;h1&gt;Symmetric matrix:&lt;/h1&gt;
&lt;p&gt;In linear algebra, a symmetric matrix is a square matrix that is equal to its transpose. Formally,&lt;/p&gt;
&lt;div class="math"&gt;$$A = A^T$$&lt;/div&gt;
&lt;h1&gt;Diagonal matrx:&lt;/h1&gt;
&lt;p&gt;In linear algebra, a diagonal matrix is a matrix in which the entries outside the main diagnoal are all zero. The term usually refers to square matrices.&lt;/p&gt;
&lt;h1&gt;Triangular matrix&lt;/h1&gt;
&lt;p&gt;In the mathematical discipline of linear algebra, a triangular matrix is a special kind of square matrix. A square matrix is called &lt;strong&gt;lower triangular&lt;/strong&gt; if all the entries above the main diagonal are zero. Similarly, a square matrix is called &lt;strong&gt;upper triangular&lt;/strong&gt; if all the entries below the main diagonal are zero. A triangular matrix is one that is either lower triangular or upper triangular. A matrix that is both upper and lower triangular is called a diagonal matrix.&lt;/p&gt;
&lt;p&gt;Because matrix equations with triangular matrices are easier to solve, they are very important in numerical analysis. By the LU decomposition algorithm, an invertible matrix may be written as the product of a lower triangular matrix L and an upper triangular matrix U if and only if all its leading principal minors are non-zero.&lt;/p&gt;
&lt;h1&gt;Invertible matrix&lt;/h1&gt;
&lt;p&gt;In linear algebra, an n-by-n square matrix A is called invertible (also nonsingular or nondegenerate) if there exists an n-by-n square matrix B such that
&lt;/p&gt;
&lt;div class="math"&gt;$$\mathbf {AB} =\mathbf {BA} =\mathbf {I}$$&lt;/div&gt;
&lt;p&gt;
where In denotes the n-by-n identity matrix and the multiplication used is ordinary matrix multiplication. If this is the case, then the matrix B is uniquely determined by A and is called the inverse of A, denoted by &lt;span class="math"&gt;\(A^{−1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A square matrix that is not invertible is called singular or degenerate. A square matrix is singular if and only if its determinant is 0. Singular matrices are rare in the sense that a square matrix randomly selected from a continuous uniform distribution on its entries will almost never be singular.&lt;/p&gt;
&lt;p&gt;The set of &lt;span class="math"&gt;\(n × n\)&lt;/span&gt; invertible matrices together with the operation of matrix multiplication form a group, the general linear group of degree n.&lt;/p&gt;
&lt;h1&gt;Positive-definite matrix&lt;/h1&gt;
&lt;p&gt;In linear algebra, a symmetric &lt;span class="math"&gt;\(n × n\)&lt;/span&gt; real matrix &lt;span class="math"&gt;\(M\)&lt;/span&gt; is said to be positive definite if the scalar &lt;span class="math"&gt;\(z^{\textsf {T}}Mz\)&lt;/span&gt; is strictly positive for every non-zero column vector &lt;span class="math"&gt;\(z\)&lt;/span&gt; of &lt;span class="math"&gt;\(n\)&lt;/span&gt; real numbers. Here &lt;span class="math"&gt;\(z^{\textsf {T}}\)&lt;/span&gt; denotes the transpose of &lt;span class="math"&gt;\(z\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1&gt;Orthogonal matrix&lt;/h1&gt;
&lt;p&gt;An orthogonal matrix is a square matrix whose columns and rows are orthogonal unit vectors (i.e., orthonormal vectors), i.e.
    &lt;/p&gt;
&lt;div class="math"&gt;$$Q^TQ=QQ^T = I$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(I\)&lt;/span&gt; I is the identity matrix.&lt;br /&gt;
This leads to the equivalent characterization: a matrix Q is orthogonal if its transpose is equal to its inverse:
&lt;/p&gt;
&lt;div class="math"&gt;$$Q^{\mathrm {T} }=Q^{-1}$$&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
An orthogonal matrix Q is necessarily invertible (with inverse &lt;span class="math"&gt;\(Q^−1 = Q^T\)&lt;/span&gt;), unitary (&lt;span class="math"&gt;\(Q^−1 = Q^∗\)&lt;/span&gt;) and therefore normal (&lt;span class="math"&gt;\(Q^∗Q = QQ^∗\)&lt;/span&gt;) in the reals. The determinant of any orthogonal matrix is either +1 or −1. As a linear transformation, an orthogonal matrix preserves the dot product of vectors, and therefore acts as an isometry of Euclidean space, such as a rotation, reflection or rotoreflection. In other words, it is a unitary transformation.&lt;br /&gt;
The set of n × n orthogonal matrices forms a group O(n), known as the orthogonal group. The subgroup SO(n) consisting of orthogonal matrices with determinant +1 is called the special orthogonal group, and each of its elements is a special orthogonal matrix. As a linear transformation, every special orthogonal matrix acts as a rotation. &lt;/p&gt;
&lt;h1&gt;Unitary matrix (酉矩阵)&lt;/h1&gt;
&lt;p&gt;In mathematics, a complex square matrix U is unitary if its conjugate transpose &lt;span class="math"&gt;\(U^*\)&lt;/span&gt; is also its inverse—that is, if
&lt;/p&gt;
&lt;div class="math"&gt;$$U^∗ U = U U^∗ = I$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(I\)&lt;/span&gt; is the identity matrix. &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category></entry><entry><title>情态动词 der Modalverb</title><link href="/qing-tai-dong-ci-der-modalverb.html" rel="alternate"></link><updated>2018-12-22T12:39:19+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-22:qing-tai-dong-ci-der-modalverb.html</id><summary type="html">&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;ich&lt;/th&gt;
&lt;th&gt;du&lt;/th&gt;
&lt;th&gt;er/sie/es&lt;/th&gt;
&lt;th&gt;wir&lt;/th&gt;
&lt;th&gt;ihr&lt;/th&gt;
&lt;th&gt;sie/Sie&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;durfen&lt;/td&gt;
&lt;td&gt;darf&lt;/td&gt;
&lt;td&gt;darfst&lt;/td&gt;
&lt;td&gt;darf&lt;/td&gt;
&lt;td&gt;durfen&lt;/td&gt;
&lt;td&gt;durft&lt;/td&gt;
&lt;td&gt;durfen&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;konnen&lt;/td&gt;
&lt;td&gt;kann&lt;/td&gt;
&lt;td&gt;kannst&lt;/td&gt;
&lt;td&gt;kann&lt;/td&gt;
&lt;td&gt;konnen&lt;/td&gt;
&lt;td&gt;konnt&lt;/td&gt;
&lt;td&gt;konnen&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mogen&lt;/td&gt;
&lt;td&gt;mochte&lt;/td&gt;
&lt;td&gt;mochtest&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mussen&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sollen&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;wollen&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;sein
现在时: bin, bist, ist, sind, seid, sind
过去时: war, warst, war, waren, wart, waren&lt;/p&gt;
&lt;p&gt;haben
现在时: habe, hast, hat, haben, habt, haben
过去时: hatte, hattest, hatte, hatten, hattet, hatten&lt;/p&gt;
&lt;p&gt;werden
现在时: werde, wirst, wird, werden, werdet, werden&lt;/p&gt;</summary><category term="German"></category></entry><entry><title>计算机求导的四种方式</title><link href="/ji-suan-ji-qiu-dao-de-si-chong-fang-shi.html" rel="alternate"></link><updated>2018-12-21T15:08:08+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-21:ji-suan-ji-qiu-dao-de-si-chong-fang-shi.html</id><summary type="html">&lt;p&gt;计算机求导，有四种方法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人工解析微分法（manual analytical differentiation）&lt;/li&gt;
&lt;li&gt;数值微分法（numerical differentiation）&lt;/li&gt;
&lt;li&gt;符号微分法（symbolic differentiation）&lt;/li&gt;
&lt;li&gt;自动微分法（automatic differentiation）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/differentiation.jpeg" alt="Automatic differentiation in
machine learning: a survey" title="differentiation" style="max-width: 100%; max-height: 100%;"/&gt;&lt;/p&gt;
&lt;p&gt;参考:&lt;br /&gt;
&lt;a href="http://ceres-solver.org/derivatives.html"&gt;Ceres Derivatives&lt;/a&gt;&lt;br /&gt;
&lt;a href="https://toutiao.io/posts/a5qqmj/preview"&gt;计算机求导的四种方式&lt;/a&gt;&lt;br /&gt;
&lt;a href="https://arxiv.org/abs/1502.05767"&gt;Automatic differentiation in machine learning: a survey&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category></entry><entry><title>常用介词</title><link href="/chang-yong-jie-ci.html" rel="alternate"></link><updated>2018-12-20T18:31:31+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-20:chang-yong-jie-ci.html</id><summary type="html">&lt;p&gt;dagegen&lt;/p&gt;
&lt;p&gt;只接第三格(Dat.)的介词
aus, von, bei, zu, mit, ab, nach, site&lt;/p&gt;</summary><category term="German"></category></entry><entry><title>常用名词</title><link href="/chang-yong-ming-ci.html" rel="alternate"></link><updated>2018-12-20T18:31:31+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-20:chang-yong-ming-ci.html</id><summary type="html">&lt;p&gt;Zuhause
Arbeit
Ferien
Aussicht
Koffer&lt;/p&gt;
&lt;p&gt;der Bekannte&lt;/p&gt;
&lt;p&gt;Gurken&lt;/p&gt;
&lt;p&gt;der Vorschalg&lt;/p&gt;</summary><category term="German"></category></entry><entry><title>常用形容词</title><link href="/chang-yong-xing-rong-ci.html" rel="alternate"></link><updated>2018-12-20T18:30:50+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-20:chang-yong-xing-rong-ci.html</id><summary type="html">&lt;p&gt;gluecklich
schoen
sauer
bekannt
allein&lt;/p&gt;</summary><category term="German"></category></entry><entry><title>常用动词</title><link href="/chang-yong-dong-ci.html" rel="alternate"></link><updated>2018-12-20T18:22:54+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-20:chang-yong-dong-ci.html</id><summary type="html">&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;日常常用动词总结&lt;br /&gt;
machen
heissen
stehen
stellen
setzen
legen
wohnen
bleiben
kommen
gehen
fahren
verstehen
sehen
aussehen
abbiegen
finden
hassen
hoeren
zuhoeren
arbeiten
erreichen
lernen
wissen
sagen
bedeuten
wuenchen
sich ueber/auf etw freuen
schenken
gucken
streiten
bekennen
treffen
gefaellen
fragen
es gibt
helfen
ankommen&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;情态动词  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;助动词&lt;br /&gt;
haben
sein&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="German"></category></entry><entry><title>德语例句</title><link href="/de-yu-li-ju.html" rel="alternate"></link><updated>2018-12-20T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-20:de-yu-li-ju.html</id><summary type="html">&lt;h1&gt;例句&lt;/h1&gt;
&lt;p&gt;Sie hasst es, frueh aufstehen zu muessen.&lt;br /&gt;
Sie hasste es, laut zu sprechen.&lt;br /&gt;
Er war mal guter Sportler(曾经)&lt;br /&gt;
Er ist zufrieden, trotzdem hat er nicht viel Geld. (仍然,尽管)&lt;br /&gt;
Die Trote sieht lecker aus (aussehen)&lt;br /&gt;
Schmecket dir die paella?&lt;br /&gt;
Ich kann mir kein Auto leisten (买得起, sich etwas leisten)&lt;br /&gt;
Am Ende habe ich die pruefung bestanden.&lt;br /&gt;
Ich muss es mir noch ueberlegen.&lt;/p&gt;
&lt;p&gt;Was kostet das Fleisch?&lt;br /&gt;
Wie viel kostet das Fleish?&lt;br /&gt;
Wie teuer ist das Fleish?&lt;/p&gt;
&lt;p&gt;wie spaet ist es?/wie viel Uhr ist es?&lt;/p&gt;
&lt;p&gt;Das ist der Rotwein, der auf der Speisekarte steht.
Der Rotwein, der aus diser Region kommt, schmeckt besonders gut.&lt;/p&gt;
&lt;p&gt;sich (Dat.) j-n/etw. vorstellen&lt;br /&gt;
sich (Akk.) vorstellen, 自我介绍  &lt;/p&gt;
&lt;p&gt;die Kneipe &lt;strong&gt;an der Ecke&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;das ist alles andere als schone. 这一点也不好看&lt;/p&gt;
&lt;p&gt;Wieder ist ein Jahr vergangen&lt;/p&gt;
&lt;p&gt;Das Bett stellst du am besten an die Wand gegenuber dem Fenster.&lt;/p&gt;
&lt;p&gt;Zu dieser Zeit ist er schon in ganz Europa bekannt.&lt;/p&gt;
&lt;p&gt;Wegen der Krankheit des Vaters blieb er zu Hause. (Dat.)&lt;/p&gt;
&lt;h1&gt;与时间相关介词&lt;/h1&gt;
&lt;p&gt;im Jahr&lt;br /&gt;
im Dezember&lt;br /&gt;
im August&lt;br /&gt;
im Ausland&lt;br /&gt;
am Freitag, Feiertag&lt;br /&gt;
am Abend&lt;br /&gt;
um 6 Uhr  &lt;/p&gt;
&lt;h1&gt;简写&lt;/h1&gt;
&lt;p&gt;j-n: jemanden, akkusativ&lt;br /&gt;
j-m: jemandem, dativ&lt;/p&gt;
&lt;h1&gt;德语疑问词&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;wer(N), wem(D), wen(A), wessen(G)&lt;br /&gt;
Wer is dein Sohn?&lt;br /&gt;
Mit wem spielen Sie Fussball?&lt;br /&gt;
Wen libst du?&lt;br /&gt;
Wessen Auto is das?  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;wie lange/lang/viel/hoch/gross/oft/breit/alt/spaet  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;wann, seit wann, bis wann (wenn为连词)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;warum, wieso(非正式)&lt;br /&gt;
Wieso kommt ihr heute so spat?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;welch&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;wo, woher, wohin&lt;/li&gt;
&lt;li&gt;was&lt;/li&gt;
&lt;li&gt;was fuer: 什么样的&lt;br /&gt;
was fur eine Uhr mocheten Sie?&lt;/li&gt;
&lt;/ul&gt;</summary><category term="German"></category></entry><entry><title>德语连词</title><link href="/de-yu-lian-ci.html" rel="alternate"></link><updated>2018-12-20T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-20:de-yu-lian-ci.html</id><summary type="html">&lt;p&gt;zwar...aber&lt;br /&gt;
- sentance with its own subject and verb&lt;br /&gt;
Tarek kommt zwar aus der Türkei, aber er spricht meistens Deutsch.
- clause with common subject and/or verb&lt;br /&gt;
Deutschland war für Yara zwar fremd, aber interessant.&lt;/p&gt;
&lt;p&gt;um...zu
可分动词，zu放在中间.&lt;br /&gt;
Ich brauche eine grosse Tasche, um die leeren Flaschen wegzubringen.&lt;br /&gt;
um...zu必须主句，从句有相同的主语，如果不是可以使用damit&lt;br /&gt;
Wir kaufen einen Saugroboter, damit die Wohnung schneller sauber wird.  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;relative clause 关系从句&lt;br /&gt;
Der Koch is der Mann, der im Restaurant fuer Gaeste kocht.&lt;/li&gt;
&lt;li&gt;final clause 目的从句&lt;/li&gt;
&lt;li&gt;Verbs with a dative and an accusative object&lt;br /&gt;
Ich schenke dir ein Woerterbuch.&lt;/li&gt;
&lt;li&gt;dass从句&lt;br /&gt;
Nico sagt, dass er das Studium hasst&lt;/li&gt;
&lt;li&gt;ob从句&lt;br /&gt;
Koennen Sie mir sagen, ob Sie ein Smartphone haben.&lt;/li&gt;
&lt;li&gt;als从句&lt;br /&gt;
Als Nico am Flughafen angekommen ist, war er allein.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;wenn从句&lt;br /&gt;
Komm vorbei, wenn du Lust hast!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;als&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表示比较, Er ist aelter als ich&lt;/li&gt;
&lt;li&gt;连词, Ich als guter Freund rate es dir.&lt;/li&gt;
&lt;li&gt;当...时候，时间从句, Gerade als ich gehen wollte, klingelt das Telephon.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="German"></category></entry><entry><title>人称物主代词</title><link href="/ren-cheng-wu-zhu-dai-ci.html" rel="alternate"></link><updated>2018-12-20T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-20:ren-cheng-wu-zhu-dai-ci.html</id><summary type="html">&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Singular&lt;/th&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;th align="left"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Nom.&lt;/td&gt;
&lt;td align="left"&gt;ich&lt;/td&gt;
&lt;td align="left"&gt;du&lt;/td&gt;
&lt;td align="left"&gt;er&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Akk.&lt;/td&gt;
&lt;td align="left"&gt;mich&lt;/td&gt;
&lt;td align="left"&gt;dich&lt;/td&gt;
&lt;td align="left"&gt;ihn&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Dat.&lt;/td&gt;
&lt;td align="left"&gt;mir&lt;/td&gt;
&lt;td align="left"&gt;dir&lt;/td&gt;
&lt;td align="left"&gt;ihm&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Gen.&lt;/td&gt;
&lt;td align="left"&gt;mein&lt;/td&gt;
&lt;td align="left"&gt;dein&lt;/td&gt;
&lt;td align="left"&gt;sein&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Plura&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Nom.&lt;/td&gt;
&lt;td&gt;wir&lt;/td&gt;
&lt;td&gt;ihr&lt;/td&gt;
&lt;td&gt;sie&lt;/td&gt;
&lt;td&gt;Sie&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Akk.&lt;/td&gt;
&lt;td&gt;uns&lt;/td&gt;
&lt;td&gt;euch&lt;/td&gt;
&lt;td&gt;sie&lt;/td&gt;
&lt;td&gt;Sie&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dat.&lt;/td&gt;
&lt;td&gt;uns&lt;/td&gt;
&lt;td&gt;euch&lt;/td&gt;
&lt;td&gt;ihnen&lt;/td&gt;
&lt;td&gt;ihnen&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gen.&lt;/td&gt;
&lt;td&gt;unser&lt;/td&gt;
&lt;td&gt;euer&lt;/td&gt;
&lt;td&gt;ihr&lt;/td&gt;
&lt;td&gt;Ihr&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Personal pronouns&lt;/th&gt;
&lt;th align="left"&gt;Akk. reflexivpron.&lt;/th&gt;
&lt;th align="left"&gt;Dat. reflexivpron&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ich&lt;/td&gt;
&lt;td align="left"&gt;mich&lt;/td&gt;
&lt;td align="left"&gt;mir&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;du&lt;/td&gt;
&lt;td align="left"&gt;dich&lt;/td&gt;
&lt;td align="left"&gt;dir&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;er/sie/es&lt;/td&gt;
&lt;td align="left"&gt;sich&lt;/td&gt;
&lt;td align="left"&gt;sich&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;wir&lt;/td&gt;
&lt;td align="left"&gt;uns&lt;/td&gt;
&lt;td align="left"&gt;uns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ihr&lt;/td&gt;
&lt;td align="left"&gt;euch&lt;/td&gt;
&lt;td align="left"&gt;euch&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;sie/Sie&lt;/td&gt;
&lt;td align="left"&gt;sich&lt;/td&gt;
&lt;td align="left"&gt;sich&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;question word&lt;/th&gt;
&lt;th&gt;example&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Nom.&lt;/td&gt;
&lt;td&gt;Wer?&lt;/td&gt;
&lt;td&gt;Wer is das?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Akk.&lt;/td&gt;
&lt;td&gt;Wen?&lt;/td&gt;
&lt;td&gt;Wen triffst du spaeter?&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dat.&lt;/td&gt;
&lt;td&gt;Wem?&lt;/td&gt;
&lt;td&gt;Wem gehoert das? Mit wem telefonniert du?&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;You have already learned that reflexive pronouns mostly occur in the accusative. However, they can also be in the dative if there is another accusative object in the sentence.&lt;/p&gt;
&lt;p&gt;Ich ziehe mich an.
Ich ziehe mir den Mantel an.&lt;/p&gt;</summary><category term="German"></category></entry><entry><title>line search</title><link href="/line-search.html" rel="alternate"></link><updated>2018-12-19T22:23:31+00:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-19:line-search.html</id><summary type="html">&lt;p&gt;From &lt;a href="https://en.wikipedia.org/wiki/Line_search"&gt;Wiki&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In optimization, the line search strategy is one of two basic iterative 
approaches to find a local minimum &lt;span class="math"&gt;\(\mathbf {x}^{*}\)&lt;/span&gt; of an objective function
&lt;span class="math"&gt;\(\mathbf {f} :\mathbb {R} ^{n} \to \mathbb {R}\)&lt;/span&gt;. The other approach is 
&lt;a href="https://en.wikipedia.org/wiki/Trust_region"&gt;trust region&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The line search approach first finds a descent direction along which the 
objective function &lt;span class="math"&gt;\(f\)&lt;/span&gt; will be reduced and then computes a 
step size that determines how far &lt;span class="math"&gt;\(\mathbf {x}\)&lt;/span&gt; should move along that 
direction. The descent direction can be computed by various methods, such as 
gradient descent, Newton's method and Quasi-Newton method. The step size can be 
determined either exactly or inexactly.&lt;/p&gt;
&lt;p&gt;trust-region methods first choose a step size (the size of the trust region) 
and then a step direction, while line-search methods first choose a step 
direction and then a step size.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在置信域方法中，优化问题构成了一个不等式约束优化问题，此问题使用拉格朗日乘子的方式，将它转换成无约束优化问题. 具体算法案例有Levenberg-Marquardt algorithm.&lt;/p&gt;
&lt;p&gt;gradient descent, 一阶偏导, jacobian matrix&lt;br/&gt;
Newtone method, 二阶偏导, Hessian matrix&lt;br/&gt;
Guass-Newton method, 使用Jacobian matrix近似Hessian matrix &lt;span class="math"&gt;\(\mathbf {H} \approx 2\mathbf {J_r^T} \mathbf{J_r}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Gradient_descent"&gt;Wiki: gradient descent&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://zhuanlan.zhihu.com/p/32709034"&gt;【最优化】一文搞懂最速下降法&lt;/a&gt;
&lt;a href="https://zhuanlan.zhihu.com/p/33413665"&gt;知乎：非线性优化&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>Gradient梯度</title><link href="/gradientti-du.html" rel="alternate"></link><updated>2018-12-19T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-19:gradientti-du.html</id><summary type="html">&lt;p&gt;The gradient is a vector-valued function, as opposed to a derivative, which is scalar-valued. &lt;/p&gt;
&lt;p&gt;In some applications it is customary to represent the gradient as a row vector or column vector of its components
in a rectangular coordinate system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;muti-variable function&lt;ul&gt;
&lt;li&gt;scalar-valued function &lt;span class="math"&gt;\(f: \mathbb{R}^n \to \mathbb{R}\)&lt;/span&gt;, gradient vector, row matrix or column matrix.&lt;br/&gt;
&lt;span class="math"&gt;\(f(\mathbf{x})\)&lt;/span&gt; where &lt;span class="math"&gt;\(\mathbf(x) = (x1, x2,...,xn)\)&lt;/span&gt;.
&lt;div class="math"&gt;\begin{align*}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
Df(\mathbf{a}) = \left[\pdiff{f}{x_1}(\mathbf{a}) \ \pdiff{f}{x_2}(\mathbf{a}) \ \ldots \ 
\pdiff{f}{x_n}(\mathbf{a})\right].
\end{align*}&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;vector-valued function &lt;span class="math"&gt;\(\boldsymbol{f}: \mathbb{R}^n \to \mathbb{R}^m\)&lt;/span&gt;, mxn matrix. Jacobian matrix.&amp;lt;br&gt;
&lt;div class="math"&gt;\begin{gather*}
\mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}),f_2(\mathbf{x}), \cdots, f_m(\mathbf{x}))
=
\left[\begin{array}{c}
f_1(\mathbf{x})\\f_2(\mathbf{x})\\ \vdots\\ f_m(\mathbf{x})
\end{array}\right].
\end{gather*}&lt;/div&gt;
&lt;div class="math"&gt;\begin{gather*}
\def\pdiff#1#2{\frac{\partial #1}{\partial #2}}
D\mathbf{f}(\mathbf{a})=
\left[
\begin{array}{cccc}
\displaystyle\pdiff{f_1}{x_1}(\mathbf{a})&amp;amp;
\displaystyle\pdiff{f_1}{x_2}(\mathbf{a})&amp;amp;
\ldots &amp;amp;
\displaystyle\pdiff{f_1}{x_n}(\mathbf{a})\\
    \displaystyle\pdiff{f_2}{x_1}(\mathbf{a})&amp;amp;
    \displaystyle\pdiff{f_2}{x_2}(\mathbf{a})&amp;amp;
    \ldots &amp;amp;
    \displaystyle\pdiff{f_2}{x_n}(\mathbf{a})\\
        \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots\\
        \displaystyle\pdiff{f_m}{x_1}(\mathbf{a})&amp;amp;
        \displaystyle\pdiff{f_m}{x_2}(\mathbf{a})&amp;amp;
\ldots &amp;amp;
\displaystyle\pdiff{f_m}{x_n}(\mathbf{a})
\end{array}
\right].
\end{gather*}&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linear approximation to a function
The gradient of a function f from the Euclidean space &lt;span class="math"&gt;\(\mathbb{R}^n \to \mathbb{R}\)&lt;/span&gt;
at any particular point x0 in &lt;span class="math"&gt;\(\mathbb{R}^n\)&lt;/span&gt; characterizes the best linear
approximation to f at x0. The approximation is as follows:
    &lt;div class="math"&gt;$$f(x) \approx f (x0) + \nabla f(x0) \cdot (x−x0)$$&lt;/div&gt;
for x close to x0, where &lt;span class="math"&gt;\(\nabla f(x0)\)&lt;/span&gt; is the gradient of f computed at x0,
and the dot denotes the dot product on Rn.&lt;br/&gt;
This equation is equivalent to the first two terms in the
&lt;strong&gt;multivariable Taylor series expansion&lt;/strong&gt; of f at x0.&lt;br/&gt;
The approximation is valid only when the function is differentiable, and can be
used with the points which is very close to x0.&lt;br/&gt;
This could be extended to &lt;strong&gt;multivariable linear approximation&lt;/strong&gt; case.&lt;br/&gt;
It describes the &lt;strong&gt;tangent line/plane&lt;/strong&gt; over that point.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://mathinsight.org/linear_approximation_multivariable"&gt;mathinsight: linear approximation multivariable&lt;/a&gt; &lt;br/&gt;
&lt;a href="https://mathinsight.org/derivative_matrix"&gt;mathinsight: derivative matrix&lt;/a&gt; &lt;br/&gt;
&lt;a href="https://en.wikipedia.org/wiki/Gradient"&gt;Wiki: Gradient&lt;/a&gt; &lt;br/&gt;
&lt;a href="https://zhuanlan.zhihu.com/p/24913912"&gt;为什么梯度反方向是函数值局部下降最快的方向&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>旋转矩阵，变化矩阵，旋转向量，欧拉角，四元数</title><link href="/xuan-zhuan-ju-zhen-bian-hua-ju-zhen-xuan-zhuan-xiang-liang-ou-la-jiao-si-yuan-shu.html" rel="alternate"></link><updated>2018-12-19T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-19:xuan-zhuan-ju-zhen-bian-hua-ju-zhen-xuan-zhuan-xiang-liang-ou-la-jiao-si-yuan-shu.html</id><summary type="html">&lt;h2&gt;对比&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;平滑插值&lt;/li&gt;
&lt;li&gt;紧凑&lt;/li&gt;
&lt;li&gt;无奇异性&lt;/li&gt;
&lt;li&gt;内存和运算速度更优。内存上，一个四元数只占四个浮点数；在四元数相乘时可以直接在这四个数上进行加减乘的基本运算，比旋转向量转换成旋转矩阵相乘后再转换回旋转向量要高效得多（Rodrigues 变换还涉及除法和三角函数等高级运算）。这些在嵌入式平台上是不小的优势。何况，浮点数运算总是会有误差的，运算越多，误差累计越多，所以理论上四元数相乘也有精度上的优势。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;transforms axis–angle coordinates to versors (unit quaternions):&lt;/h2&gt;
&lt;p&gt;the following expression transforms axis–angle coordinates to versors (unit quaternions):
&lt;/p&gt;
&lt;div class="math"&gt;$$Q=\left(\cos {\tfrac {\theta }{2}},{\boldsymbol {\omega }}\sin {\tfrac {\theta }{2}}\right)$$&lt;/div&gt;
&lt;h2&gt;Recovering the axis-angle representation&lt;/h2&gt;
&lt;p&gt;Two rotation quaternions can be combined into one equivalent quaternion by the relation:
&lt;span class="math"&gt;\(\mathbf {q} '=\mathbf {q} _{2}\mathbf {q} _{1}\)&lt;/span&gt;,
in which q′ corresponds to the rotation q1 followed by the rotation q2.
(Note that quaternion multiplication is not commutative.)&lt;/p&gt;
&lt;p&gt;The expression &lt;span class="math"&gt;\(\mathbf {q} \mathbf {p} \mathbf {q} ^{-1}\)&lt;/span&gt; rotates any vector
quaternion &lt;span class="math"&gt;\(\mathbf {p}\)&lt;/span&gt; around an axis given by the vector a &lt;span class="math"&gt;\(\mathbf {a}\)&lt;/span&gt; by
the angle &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, where a &lt;span class="math"&gt;\(\mathbf {a}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\theta\)&lt;/span&gt; depends on the
quaternion &lt;span class="math"&gt;\(\mathbf {q} =q_{r}+q_{i}\mathbf {i} +q_{j}\mathbf {j} +q_{k}\mathbf {k}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathbf {a}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\theta\)&lt;/span&gt; can be found from the following equations:
    &lt;/p&gt;
&lt;div class="math"&gt;$$ (a_{x},a_{y},a_{z})\ =\ {\frac {(q_{i},q_{j},q_{k})}{\sqrt {q_{i}^{2}+q_{j}^{2}+q_{k}^{2}}}}$$&lt;/div&gt;
&lt;div class="math"&gt;$$ \theta \ =\ 2\operatorname {atan2} \left({\sqrt {q_{i}^{2}+q_{j}^{2}+q_{k}^{2}}},q_{r}\right)$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(\mathrm {atan2}\)&lt;/span&gt; is the two-argument arctangent. Care should be taken when the quaternion approaches a scalar, since due to degeneracy the axis of an identity rotation is not well-defined&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.csdn.net/EliminatedAcmer/article/details/81407176"&gt;CSDN总结&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;quaternion to axis–angle coordinates&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="n"&gt;Eigen&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Vector3d&lt;/span&gt; &lt;span class="n"&gt;toAngleAxis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Eigen&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Quaterniond&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;quaterd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;angle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;Eigen&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Quaterniond&lt;/span&gt; &lt;span class="n"&gt;unit_quaternion&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;quaterd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normalized&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unit_quaternion&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vec&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unit_quaternion&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;squared_w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="c1"&gt;// Atan-based log thanks to&lt;/span&gt;
    &lt;span class="c1"&gt;//&lt;/span&gt;
    &lt;span class="c1"&gt;// C. Hertzberg et al.:&lt;/span&gt;
    &lt;span class="c1"&gt;// &amp;quot;Integrating Generic Sensor Fusion Algorithms with Sound State&lt;/span&gt;
    &lt;span class="c1"&gt;// Representation through Encapsulation of Manifolds&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;// Information Fusion, 2011&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;SMALL_EPS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="c1"&gt;// If quaternion is normalized and n=1, then w should be 1;&lt;/span&gt;
        &lt;span class="c1"&gt;// w=0 should never happen here!&lt;/span&gt;
        &lt;span class="n"&gt;assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fabs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;SMALL_EPS&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

        &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;squared_w&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fabs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;SMALL_EPS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;M_PI&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;M_PI&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;atan&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;angle&lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;angle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;unit_quaternion&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vec&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="n"&gt;Eigen&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Quaterniond&lt;/span&gt; &lt;span class="n"&gt;toQuaterniond&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;Eigen&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Vector3d&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;v3d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;angle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;v3d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;angle&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;angle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;half_theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;imag_factor&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;real_factor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;half_theta&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;SMALL_EPS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;theta_sq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;theta_po4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theta_sq&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta_sq&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;imag_factor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.0208333&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta_sq&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mf"&gt;0.000260417&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta_po4&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;sin_half_theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;half_theta&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;imag_factor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sin_half_theta&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Eigen&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Quaterniond&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real_factor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;imag_factor&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;v3d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
            &lt;span class="n"&gt;imag_factor&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;v3d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
            &lt;span class="n"&gt;imag_factor&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;v3d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;SOPHUS_FUNC&lt;/span&gt; &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="n"&gt;SO3&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;expAndTheta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Tangent&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;omega&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;SOPHUS_ENSURE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="k"&gt;nullptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;must not be nullptr.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;theta_sq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;omega&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squaredNorm&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;theta_sq&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;half_theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;imag_factor&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;real_factor&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;Constants&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;theta_po4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;theta_sq&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;theta_sq&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;imag_factor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;48.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;theta_sq&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
            &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;3840.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;theta_po4&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;real_factor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;8.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;theta_sq&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
            &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;384.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;theta_po4&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;sin_half_theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;half_theta&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;imag_factor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sin_half_theta&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;real_factor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;half_theta&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="n"&gt;SO3&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unit_quaternion_nonconst&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
        &lt;span class="n"&gt;QuaternionMember&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real_factor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imag_factor&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;omega&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                &lt;span class="n"&gt;imag_factor&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;omega&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;imag_factor&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;omega&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
    &lt;span class="n"&gt;SOPHUS_ENSURE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unit_quaternion&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;squaredNorm&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
            &lt;span class="n"&gt;Sophus&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Constants&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
            &lt;span class="s"&gt;&amp;quot;SO3::exp failed! omega: %, real: %, img: %&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;omega&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;real_factor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imag_factor&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;SOPHUS_FUNC&lt;/span&gt; &lt;span class="n"&gt;TangentAndTheta&lt;/span&gt; &lt;span class="n"&gt;logAndTheta&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;TangentAndTheta&lt;/span&gt; &lt;span class="n"&gt;J&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;atan&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;squared_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unit_quaternion&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;vec&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;squaredNorm&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;squared_n&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unit_quaternion&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

    &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="c1"&gt;// Atan-based log thanks to&lt;/span&gt;
    &lt;span class="c1"&gt;//&lt;/span&gt;
    &lt;span class="c1"&gt;// C. Hertzberg et al.:&lt;/span&gt;
    &lt;span class="c1"&gt;// &amp;quot;Integrating Generic Sensor Fusion Algorithms with Sound State&lt;/span&gt;
    &lt;span class="c1"&gt;// Representation through Encapsulation of Manifolds&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;// Information Fusion, 2011&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;Constants&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="c1"&gt;// If quaternion is normalized and n=0, then w should be 1;&lt;/span&gt;
        &lt;span class="c1"&gt;// w=0 should never happen here!&lt;/span&gt;
        &lt;span class="n"&gt;SOPHUS_ENSURE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;Constants&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                &lt;span class="s"&gt;&amp;quot;Quaternion (%) should be normalized!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="n"&gt;unit_quaternion&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;coeffs&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
        &lt;span class="n"&gt;Scalar&lt;/span&gt; &lt;span class="n"&gt;squared_w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
            &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;squared_n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;squared_w&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;Constants&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Constants&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Constants&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;atan&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="n"&gt;J&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="n"&gt;J&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tangent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;two_atan_nbyw_by_n&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;unit_quaternion&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;vec&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;J&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>Bayes and Kalman Filter</title><link href="/bayes-and-kalman-filter.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:bayes-and-kalman-filter.html</id><summary type="html">&lt;p&gt;SLAM位姿与地图估计问题有两种方式，一种是滤波，一种是优化.&lt;br/&gt;
暂时搜集到的一些信息，没有自己整理&lt;/p&gt;
&lt;p&gt;Bayes Filter推导(&lt;span style="color:red"&gt;基于Bayes公式与Markov assumption&lt;/span&gt;)&lt;br/&gt;
&lt;img src="images/bayes-1.png" alt="Bayes" title="bayes" style="width:50%"/&gt;&lt;/p&gt;
&lt;p&gt;第一步用到的Bayes公式：
&lt;/p&gt;
&lt;div class="math"&gt;$$P(x|y,z) = \frac{P(y|x,z)\cdot p(x|z)}{p(y|z)}$$&lt;/div&gt;
&lt;p&gt;
由此得出，贝叶斯滤波器分为两步：&lt;br/&gt;
1. 状态预测，基于状态转移模型：
&lt;/p&gt;
&lt;div class="math"&gt;$$\overline {bel} ({x_t}) = \int {p({x_t}|{u_t},{x_{t - 1}})} \;bel({x_{t - 1}})\;d{x_{t - 1}}$$&lt;/div&gt;
&lt;p&gt;
2. 状态更新，基于新的观测
&lt;/p&gt;
&lt;div class="math"&gt;$$bel({x_t}) = \;\eta \,p({z_t}|{x_t})\,\overline {bel} ({x_t})$$&lt;/div&gt;
&lt;p&gt;在此式中&lt;span class="math"&gt;\(\eta\)&lt;/span&gt;未进一步说明，概率机器人一书中，被称之为&lt;strong&gt;归一化因子&lt;/strong&gt;，具体表现形式如下：
&lt;/p&gt;
&lt;div class="math"&gt;$$\frac{1}{\eta} = \sum{p(z_t|x_t)\overline{bel}(x_t)dx_t}$$&lt;/div&gt;
&lt;p&gt;
因为最后&lt;span class="math"&gt;\(bel(x_t)\)&lt;/span&gt;是一个概率，其所有&lt;span class="math"&gt;\(x_t\)&lt;/span&gt;可能性概率的总和必须为１.&lt;/p&gt;
&lt;p&gt;伪代码流程如下: &lt;br/&gt;
&lt;img src="images/bayes-2.png" alt="Bayes" title="bayes" style="width:50%"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style="color:red"&gt;
同时，我们注意，我们的目的是计算&lt;span class="math"&gt;\(x_t\)&lt;/span&gt;的后验概率，如果&lt;span class="math"&gt;\(bel(x_t)\)&lt;/span&gt;是任意分布，
我们需要在&lt;span class="math"&gt;\(x_t\)&lt;/span&gt;的所有可能取值点上，计算该取值的概率，这在计算上是难于实现的。
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;相关资料的搜集:&lt;br/&gt;
&lt;a href="/pdfs/slam02-bayes-filter-short.pdf"&gt;Bayes Filter by Cyrill Stachniss&lt;/a&gt;
&lt;br/&gt;
&lt;a href="http://ais.informatik.uni-freiburg.de/teaching/ss10/robotics/slides/10-kalman-filter.pdf"&gt;Introduction to Mobile Robotics - Bayes Filter – Kalman Filter&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://www.cnblogs.com/gaoxiang12/p/5560360.html"&gt;SLAM中的EKF，UKF，PF原理简介&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://blog.csdn.net/qq_30159351/article/details/53395515"&gt;SLAM笔记三——贝叶斯滤波器&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://blog.csdn.net/qinruiyan/article/details/50793114"&gt;SLAM学习笔记2：Kalman Filter(卡尔曼滤波) 与Least Square(最小二乘法) 的比较&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://www.cnblogs.com/ycwang16/p/5995702.html"&gt;细说贝叶斯滤波：Bayes filters&lt;/a&gt;
&lt;br/&gt;
&lt;a href="http://www.cnblogs.com/ycwang16/p/5999034.html"&gt;细说Kalman滤波：The Kalman Filter&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>博客中markdown文本语法与数学符号</title><link href="/bo-ke-zhong-markdownwen-ben-yu-fa-yu-shu-xue-fu-hao.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:bo-ke-zhong-markdownwen-ben-yu-fa-yu-shu-xue-fu-hao.html</id><summary type="html">&lt;p&gt;\mathbb{R}^n --&amp;gt; &lt;span class="math"&gt;\(\mathbb{R}^n\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\boldsymbol{f} --&amp;gt; &lt;span class="math"&gt;\(\boldsymbol{f}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\to --&amp;gt; &lt;span class="math"&gt;\(\to\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\nabla f(x0) --&amp;gt; &lt;span class="math"&gt;\(\nabla f(x0)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\cdot --&amp;gt; &lt;span class="math"&gt;\(\cdot\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\eta --&amp;gt; &lt;span class="math"&gt;\(\eta\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\frac {1} {2} --&amp;gt; &lt;span class="math"&gt;\(\frac{1}{2}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\int --&amp;gt; &lt;span class="math"&gt;\(\int\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;\sum --&amp;gt; &lt;span class="math"&gt;\(\sum\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#html"&gt;Markdown cheatsheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://davidhamann.de/2017/06/12/latex-cheat-sheet/"&gt;LaTex methematics cheatsheet&lt;/a&gt;
&lt;a href="http://www.malinc.se/math/latex/basiccodeen.php"&gt;LaTex&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary></entry><entry><title>非线性优化</title><link href="/fei-xian-xing-you-hua.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:fei-xian-xing-you-hua.html</id><summary type="html">&lt;p&gt;From &lt;a href="https://en.wikipedia.org/wiki/Nonlinear_programming"&gt;wiki&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In mathematics, nonlinear programming is the process of solving an optimization
problem where some of the constraints or the objective function are nonlinear.
An optimization problem is one of calculation of the extrema
(maxima, minima or stationary points) of an objective function over a set of
unknown real variables and conditional to the satisfaction of a system of
equalities and inequalities, collectively termed constraints.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="http://blog.sina.com.cn/s/blog_7445c2940102x3x4.html"&gt;到底什么是非线性优化&lt;/a&gt;&lt;/p&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>MLE &amp; MAP</title><link href="/mle-map.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:mle-map.html</id><summary type="html">&lt;p&gt;MLE：最大似然概率 给定测量结果，系统模型，寻求系统模型参数让结果跟观测结果最贴近。&lt;/p&gt;
&lt;p&gt;似然函数（也称作似然），是一个关于统计模型参数的函数。也就是这个函数中自变量是统计模型的参数。
&lt;br/&gt;
对于观测结果 x ，在参数集合 θ 上的似然，就是在给定这些参数值的基础上，观察到的结果的概率 P(x|θ) 。
也就是说，似然是关于参数的函数，在参数给定的条件下，对于观察到的 x 的值的条件分布。&lt;/p&gt;
&lt;p&gt;MAP:最大后验概率, 考虑到先验概率的存在 prior probability.
Bayes rule
&lt;/p&gt;
&lt;div class="math"&gt;$$P(\theta|x) = \frac{P(x|\theta) * p(\theta)}{p(x)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$P(x|y,z) = \frac{P(y|x,z)\cdot p(x|z)}{p(y|z)}$$&lt;/div&gt;
&lt;div class="math"&gt;$$\hat{\theta} = \mathop{arg\max}_{\theta} P(\theta|x) \propto P(x|\theta) * p(\theta)$$&lt;/div&gt;
&lt;p&gt;
分母可以去掉，与求参数无关&lt;/p&gt;
&lt;p&gt;已知观测结果，寻找参数，使得模型输出最符合观测。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E5%85%A8%E6%A6%82%E7%8E%87%E5%85%AC%E5%BC%8F"&gt;全概率公式&lt;/a&gt;
&lt;br/&gt;
&lt;a href="http://www.cnblogs.com/sylvanas2012/p/5058065.html"&gt;最大似然估计 （MLE） 最大后验概率（MAP）&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://zhuanlan.zhihu.com/p/25768606"&gt;概率与似然&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>数值分析</title><link href="/shu-zhi-fen-xi.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:shu-zhi-fen-xi.html</id><summary type="html">&lt;p&gt;From
&lt;a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90"&gt;Wiki&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;数值分析（英语：numerical analysis），是指在数学分析（区别于离散数学）问题中，对使用数值近似（相对于一般化的符号运算）算法的研究。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;direct method&lt;/p&gt;
&lt;p&gt;iterative method&lt;/p&gt;
&lt;p&gt;Numerical analysis
解析解/闭合解
数值解&lt;/p&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>图片测试</title><link href="/tu-pian-ce-shi.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:tu-pian-ce-shi.html</id><summary type="html">&lt;p&gt;Neko把你拿来做测试了！&lt;br/&gt;
&lt;!--
This won't scale the image
&lt;img alt="Description for people who can't see the image" src="/images/neko.jpg" title="Neko" /&gt;
--&gt;
&lt;figure&gt;
&lt;img src="images/neko.jpg" alt="A cute cat" title="Neko" style="max-width:100%;max-height:100%"/&gt;
&lt;figcaption&gt; Fig. Neko &lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;使用下面的内嵌html代码加载图片。&lt;br/&gt;
markdown自身的语法不支持图片大小的设置。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;img&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;images/neko.jpg&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;A cute cat&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Neko&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;max-width:100%;max-height=100%&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;figcaption&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; Fig. Neko &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;figcaption&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary></entry><entry><title>Variance, gradient, Jacobian and Hessian matrix 记忆</title><link href="/variance-gradient-jacobian-and-hessian-matrix-ji-yi.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:variance-gradient-jacobian-and-hessian-matrix-ji-yi.html</id><summary type="html">&lt;p&gt;Jacobian矩阵　用于一阶梯度下降法&lt;br/&gt;
Hessian矩阵，用于二阶牛顿法&lt;br/&gt;
高斯牛顿法，使用J&lt;sup&gt;T&lt;/sup&gt;J作为牛顿法中二阶Hessian矩阵的近似，　从而省略了计算Ｈ的过程&lt;br/&gt;
&lt;a href="http://jacoxu.com/jacobian%E7%9F%A9%E9%98%B5%E5%92%8Chessian%E7%9F%A9%E9%98%B5/"&gt;下面这个文章介绍了Jacobian与Hessian矩阵的关系用途&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hessian是对称矩阵&lt;br/&gt;
&lt;a href="https://blog.csdn.net/dsbatigol/article/details/12558891"&gt;jacobian, Hassian and gradient关系&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;covariance,协方差：&lt;br/&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$cov(X,Y) = E((X-\mu)(Y-\nu)) = E(X \cdot Y) - \mu\nu$$&lt;/div&gt;
&lt;p&gt;variance, 方差：　二阶矩&lt;br/&gt;
 一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离, &lt;span class="math"&gt;\(\mu=E[X]\)&lt;/span&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$Var(X) = cov(X, X)$$&lt;/div&gt;
&lt;div class="math"&gt;$$Var(X) = E[(X-\mu)^2]$$&lt;/div&gt;
&lt;p&gt;期望：　一阶矩&lt;br/&gt;
&lt;a href="https://zh.wikipedia.org/wiki/%E5%8D%8F%E6%96%B9%E5%B7%AE"&gt;方差Wiki&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry><entry><title>线性规划</title><link href="/xian-xing-gui-hua.html" rel="alternate"></link><updated>2018-12-18T00:00:00+01:00</updated><author><name>Nekoo</name></author><id>tag:,2018-12-18:xian-xing-gui-hua.html</id><summary type="html">&lt;p&gt;线性优化，　线性规划，　linear programming&lt;/p&gt;</summary><category term="Math"></category><category term="SLAM"></category></entry></feed>